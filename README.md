# element_human-action-recognition

## Responsible
|                Kourosh Darvish                              |
:------------------------------------------------------------:|
<img src="https://github.com/kouroshD.png" width="180"> |

## Background
The problem of human action & intention recgonition (HAIR) rises several challenges and opportunity to the robotic community. We define the human action and intention recognition at _symbolic level_ and _motion level_ as "the process of classification of the human motion among the existing ones (i.e. modeled ones) in a library of actions, the starting point and ending point of an action, predicting the human motion in future reasoning according to incomplete temporal data, and the belief degree of the action recognition and prediction".
The effectiveness of the human action recognition (high precision, recall, accuracy, and f1 scores) for a given objective and application depends on the methods and sensory information we use. For our use case in this element, we learn or model the actions offline, whereas the human action recognition is performed online.
HAIR can be performed by using following sensory data comming from the human:

-  human limb and joint kinematic and dynamic or a mixture of them (technologies: data coming from the mocap, RGBd data, raw imu werables sensors, shoes,  etc)
- human gaze (technologies)
- human physiological measures, heart rate, ecg data ()

## Objectives



## Outcomes
