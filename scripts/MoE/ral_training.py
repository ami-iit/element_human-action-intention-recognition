import os
import numpy as np
from pandas import DataFrame
from pandas import Grouper
from matplotlib import pyplot as plt
from pandas import concat


samples = 10
# GMoE
loss = [0]*samples
val_loss =[0]*samples
gate_output_loss =[0]*samples
val_gate_output_loss =[0]*samples
reduced_sum_loss =[0]*samples
val_reduced_sum_loss =[0]*samples
gate_output_accuracy =[0]*samples
val_gate_output_accuracy =[0]*samples
reduced_sum_mae =[0]*samples
val_reduced_sum_mae =[0]*samples

# LSTM
loss_lstm = [0]*samples
val_loss_lstm =[0]*samples
gate_output_loss_lstm =[0]*samples
val_gate_output_loss_lstm =[0]*samples
reduced_sum_loss_lstm =[0]*samples
val_reduced_sum_loss_lstm =[0]*samples
gate_output_accuracy_lstm =[0]*samples
val_gate_output_accuracy_lstm =[0]*samples
reduced_sum_mae_lstm =[0]*samples
val_reduced_sum_mae_lstm =[0]*samples

#############################################################################################
#############################################################################################
#############################################################################################

###############################
###############################
###############################
############ LSTM #############
###############################
###############################
###############################


################# 1
# Epoch 00030: val_loss did not improve from 1.93879
# Epoch 31/100
# Epoch 00031: LearningRateScheduler reducing learning rate to 0.000531441.
# 261/261 [==============================] - 13s 52ms/step - loss: 1.5762 - gate_output_loss: 0.1214 - reduced_sum_loss: 0.4199 - gate_output_accuracy: 0.9573 - reduced_sum_mae: 0.4420 - val_loss: 1.9556 - val_gate_output_loss: 0.5392 - val_reduced_sum_loss: 0.4914 - val_gate_output_accuracy: 0.8509 - val_reduced_sum_mae: 0.4769
# [on_epoch_end] epoch: 30 , loss: 1.5535305738449097 , val_loss : 1.9556498527526855
# Epoch 00031: val_loss did not improve from 1.93879
loss_lstm[0] = [64.22608947753906, 3.150412082672119, 2.921154499053955, 2.818722724914551, 2.7731120586395264, 2.5205116271972656, 2.519573450088501, 2.514843702316284, 2.4940695762634277, 2.51721453666687, 2.2735471725463867, 2.2957799434661865, 2.268447160720825, 2.2554967403411865, 2.283709764480591, 2.066696882247925, 2.0645267963409424, 2.047910213470459, 2.088991403579712, 2.056380271911621, 1.873759388923645, 1.8853436708450317, 1.8748925924301147, 1.8754355907440186, 1.8557285070419312, 1.7134557962417603, 1.7090009450912476, 1.699030876159668, 1.7032989263534546, 1.7203338146209717, 1.5535305738449097]
val_loss_lstm[0] = [3.617088794708252, 3.3251402378082275, 2.8449153900146484, 2.9939732551574707, 3.014724016189575, 2.753714084625244, 2.576326608657837, 2.6663060188293457, 2.651019334793091, 2.881519317626953, 2.4837357997894287, 2.560648202896118, 2.4814937114715576, 2.932257652282715, 2.524998188018799, 2.2583186626434326, 2.190025568008423, 2.162724733352661, 2.519451379776001, 2.385690689086914, 2.095020055770874, 2.044153928756714, 2.186675548553467, 2.0756638050079346, 2.0995776653289795, 1.9399182796478271, 2.144946575164795, 1.9387876987457275, 2.076617479324341, 2.0323235988616943, 1.9556498527526855]
gate_output_loss_lstm[0] = [0.7092279195785522, 0.33050334453582764, 0.2506847381591797, 0.22712492942810059, 0.21075691282749176, 0.19111372530460358, 0.1947379857301712, 0.19484004378318787, 0.17867732048034668, 0.18362097442150116, 0.16842122375965118, 0.17507848143577576, 0.1622934639453888, 0.16132165491580963, 0.16011331975460052, 0.1521773636341095, 0.15078283846378326, 0.1431068629026413, 0.1531374454498291, 0.1441812664270401, 0.13133934140205383, 0.1359812170267105, 0.13527923822402954, 0.13540711998939514, 0.13109973073005676, 0.13040781021118164, 0.1258016675710678, 0.1245577484369278, 0.12818706035614014, 0.13042591512203217, 0.11798383295536041]
val_gate_output_loss_lstm[0] = [0.8146403431892395, 0.5289239883422852, 0.25529491901397705, 0.381971150636673, 0.48155519366264343, 0.3939369320869446, 0.27152329683303833, 0.31468522548675537, 0.365486741065979, 0.5506481528282166, 0.3858579695224762, 0.43536844849586487, 0.4004862606525421, 0.8216972947120667, 0.3850410282611847, 0.3589070439338684, 0.27647078037261963, 0.27637338638305664, 0.5664755702018738, 0.4467836916446686, 0.37234893441200256, 0.3178689181804657, 0.45216986536979675, 0.3346146047115326, 0.36735981702804565, 0.3813060522079468, 0.5489228963851929, 0.3325723707675934, 0.46449607610702515, 0.41835328936576843, 0.5392103791236877]
reduced_sum_loss_lstm[0] = [0.7060670256614685, 0.6171424984931946, 0.5902047753334045, 0.5759338736534119, 0.5582910776138306, 0.5516170859336853, 0.5388055443763733, 0.5260306596755981, 0.5221866965293884, 0.5158407092094421, 0.506743848323822, 0.5040457248687744, 0.49996405839920044, 0.49848684668540955, 0.4935537576675415, 0.4862416684627533, 0.4818158745765686, 0.4838472306728363, 0.480265349149704, 0.47117307782173157, 0.4496612250804901, 0.4491824507713318, 0.44605931639671326, 0.4389107823371887, 0.4319216012954712, 0.4305723309516907, 0.4232163727283478, 0.4223109483718872, 0.4218437075614929, 0.41953736543655396, 0.4164161682128906]
val_reduced_sum_loss_lstm[0] = [0.9310175180435181, 0.9057835340499878, 0.6335089802742004, 0.6194992661476135, 0.6053681969642639, 0.6088821887969971, 0.5781987905502319, 0.5520816445350647, 0.5756196975708008, 0.5395740270614624, 0.5512829422950745, 0.543786883354187, 0.5347723364830017, 0.5344176292419434, 0.5444738268852234, 0.5448470711708069, 0.5415928363800049, 0.5349416136741638, 0.625319242477417, 0.5777018070220947, 0.49549755454063416, 0.5020998120307922, 0.49629083275794983, 0.514280378818512, 0.48222944140434265, 0.48828956484794617, 0.4822842478752136, 0.5046388506889343, 0.5270159244537354, 0.48697856068611145, 0.49137309193611145]
gate_output_accuracy_lstm[0] = [0.7803332805633545, 0.9033880829811096, 0.9183119535446167, 0.923601508140564, 0.9297974109649658, 0.9345498085021973, 0.9348135590553284, 0.9314614534378052, 0.9388226866722107, 0.9362906217575073, 0.9412732124328613, 0.9387891292572021, 0.9439635276794434, 0.9428605437278748, 0.9428653717041016, 0.9452775716781616, 0.9467257857322693, 0.9495407938957214, 0.9465723633766174, 0.9487063884735107, 0.9532430171966553, 0.9520105719566345, 0.952116072177887, 0.950974702835083, 0.9533964991569519, 0.9533485174179077, 0.9547104835510254, 0.9559189677238464, 0.9553530812263489, 0.9540870189666748, 0.9574727416038513]
val_gate_output_accuracy_lstm[0] = [0.7575116157531738, 0.7724079489707947, 0.910266637802124, 0.910266637802124, 0.8541007041931152, 0.8874312043190002, 0.9102835655212402, 0.8973339200019836, 0.87659752368927, 0.8341261148452759, 0.8711299300193787, 0.8634955286979675, 0.8778163194656372, 0.7170376777648926, 0.8814219236373901, 0.8942192196846008, 0.9169022440910339, 0.9092001914978027, 0.8408463597297668, 0.8811849355697632, 0.8980787396430969, 0.902801513671875, 0.8806432485580444, 0.9078798294067383, 0.8952179551124573, 0.8952010273933411, 0.8812695741653442, 0.8980448842048645, 0.8863817453384399, 0.8971646428108215, 0.8509183526039124]
reduced_sum_mae_lstm[0] = [0.5947498679161072, 0.5506696701049805, 0.5377292633056641, 0.5307366251945496, 0.5229705572128296, 0.5179911255836487, 0.5092166662216187, 0.5014445781707764, 0.4987156391143799, 0.4948742985725403, 0.4898620843887329, 0.48861441016197205, 0.4850550889968872, 0.4844503700733185, 0.4809921979904175, 0.4776681065559387, 0.47467392683029175, 0.47428756952285767, 0.4733462631702423, 0.46897876262664795, 0.458992063999176, 0.45804235339164734, 0.4563475549221039, 0.45295804738998413, 0.4495205283164978, 0.44713422656059265, 0.44391632080078125, 0.4433767795562744, 0.44249868392944336, 0.44148561358451843, 0.43988147377967834]
val_reduced_sum_mae_lstm[0] = [0.7261689305305481, 0.7075688242912292, 0.5611968636512756, 0.5492426156997681, 0.5408667922019958, 0.5464819669723511, 0.5215699672698975, 0.5067773461341858, 0.5223004221916199, 0.49810677766799927, 0.5032544136047363, 0.5025273561477661, 0.495419442653656, 0.4953959286212921, 0.4997043013572693, 0.5018150210380554, 0.5000625848770142, 0.49769824743270874, 0.552648663520813, 0.5222489237785339, 0.4761309027671814, 0.48121482133865356, 0.4769441783428192, 0.48954859375953674, 0.4667607843875885, 0.4715552031993866, 0.46970054507255554, 0.48383018374443054, 0.49786120653152466, 0.4739653170108795, 0.47687870264053345]
# 74/74 [==============================] - 1s 15ms/step - loss: 1.9557 - gate_output_loss: 0.5392 - reduced_sum_loss: 0.4914 - gate_output_accuracy: 0.8509 - reduced_sum_mae: 0.4769
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================

# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-24_11:00:19/model_LSTM.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-24_11:00:19/model_LSTM.png

################# 2
#
# Epoch 20/100
# Epoch 00020: LearningRateScheduler reducing learning rate to 0.0007290000000000002.
# 261/261 [==============================] - 14s 55ms/step - loss: 2.0881 - gate_output_loss: 0.1610 - reduced_sum_loss: 0.4621 - gate_output_accuracy: 0.9447 - reduced_sum_mae: 0.4618 - val_loss: 2.3930 - val_gate_output_loss: 0.4150 - val_reduced_sum_loss: 0.5478 - val_gate_output_accuracy: 0.8801 - val_reduced_sum_mae: 0.5086
# [on_epoch_end] epoch: 19 , loss: 2.0975770950317383 , val_loss : 2.3929717540740967
# Epoch 00020: val_loss did not improve from 2.15745
# Epoch 21/100
# Epoch 00021: LearningRateScheduler reducing learning rate to 0.0006561000000000001.
# 261/261 [==============================] - 16s 60ms/step - loss: 1.8926 - gate_output_loss: 0.1353 - reduced_sum_loss: 0.4481 - gate_output_accuracy: 0.9522 - reduced_sum_mae: 0.4578 - val_loss: 2.2406 - val_gate_output_loss: 0.4590 - val_reduced_sum_loss: 0.5489 - val_gate_output_accuracy: 0.8761 - val_reduced_sum_mae: 0.5091
# [on_epoch_end] epoch: 20 , loss: 1.8873295783996582 , val_loss : 2.240583896636963
# Epoch 00021: val_loss did not improve from 2.15745
loss_lstm[1] = [64.22341918945312, 3.06899094581604, 2.975680112838745, 2.882051467895508, 2.786129951477051, 2.5486443042755127, 2.5594358444213867, 2.5163726806640625, 2.52754545211792, 2.5032808780670166, 2.2759339809417725, 2.293780565261841, 2.272803783416748, 2.285003900527954, 2.264078378677368, 2.080174207687378, 2.0590035915374756, 2.0584826469421387, 2.050989866256714, 2.0975770950317383, 1.8873295783996582]
val_loss_lstm[1] = [3.6744260787963867, 3.4076294898986816, 3.0760576725006104, 2.8107903003692627, 3.0274386405944824, 2.8721237182617188, 2.808912992477417, 2.680602788925171, 2.6169426441192627, 2.6857669353485107, 2.4790127277374268, 2.3450701236724854, 3.1090259552001953, 2.3016655445098877, 2.6449668407440186, 2.1617395877838135, 2.441709041595459, 2.1574511528015137, 2.2229905128479004, 2.3929717540740967, 2.240583896636963]
gate_output_loss_lstm[1] = [0.720911979675293, 0.32188302278518677, 0.2723853290081024, 0.2345859855413437, 0.21280677616596222, 0.1979023665189743, 0.19179320335388184, 0.18557053804397583, 0.18339179456233978, 0.16895650327205658, 0.16353492438793182, 0.1625692993402481, 0.1638021320104599, 0.15995848178863525, 0.1583888977766037, 0.15188172459602356, 0.14994773268699646, 0.1449269950389862, 0.1395339071750641, 0.1534581333398819, 0.1376977264881134]
val_gate_output_loss_lstm[1] = [0.8296627998352051, 0.4795435965061188, 0.3649483025074005, 0.22996880114078522, 0.40866851806640625, 0.49241507053375244, 0.48830217123031616, 0.3305508494377136, 0.26335611939430237, 0.34365788102149963, 0.35630321502685547, 0.21929660439491272, 0.8912103772163391, 0.20150652527809143, 0.4731009304523468, 0.2557542324066162, 0.4871714115142822, 0.25784698128700256, 0.30229172110557556, 0.41497519612312317, 0.4590454399585724]
reduced_sum_loss_lstm[1] = [0.7075566053390503, 0.6206969618797302, 0.5804248452186584, 0.5695957541465759, 0.5551706552505493, 0.5424519777297974, 0.5323197245597839, 0.5177491307258606, 0.5132381319999695, 0.5144104957580566, 0.49815335869789124, 0.49821558594703674, 0.4911676049232483, 0.4848751723766327, 0.48221537470817566, 0.4772454500198364, 0.4764321446418762, 0.4708064794540405, 0.46622636914253235, 0.45804163813591003, 0.4494878649711609]
val_reduced_sum_loss_lstm[1] = [0.9289768934249878, 0.8992304801940918, 0.6416146755218506, 0.6292462348937988, 0.6249440312385559, 0.7017365097999573, 0.5873215794563293, 0.5940383672714233, 0.6534034013748169, 0.5640100240707397, 0.5976986289024353, 0.5698203444480896, 0.7235453128814697, 0.5666828751564026, 0.5485473275184631, 0.575078547000885, 0.5947679281234741, 0.5644935965538025, 0.5359209775924683, 0.5477776527404785, 0.5489032864570618]
gate_output_accuracy_lstm[1] = [0.7780649662017822, 0.90720534324646, 0.9132429957389832, 0.9225368499755859, 0.9276825189590454, 0.9308092594146729, 0.9339072108268738, 0.9361323714256287, 0.9359596967697144, 0.9415801167488098, 0.9431387186050415, 0.9427022933959961, 0.9421796202659607, 0.9453686475753784, 0.944793164730072, 0.9476705193519592, 0.9484522342681885, 0.9491283893585205, 0.9488790035247803, 0.9463373422622681, 0.9514686465263367]
val_gate_output_accuracy_lstm[1] = [0.7575116157531738, 0.7732543349266052, 0.9114007353782654, 0.9250274896621704, 0.8785780668258667, 0.844553530216217, 0.7901819944381714, 0.9024291038513184, 0.9159542918205261, 0.8908675312995911, 0.8935251832008362, 0.9205417037010193, 0.7887262105941772, 0.9314092397689819, 0.8454168438911438, 0.9205755591392517, 0.832687258720398, 0.9244858026504517, 0.9058146476745605, 0.8800677061080933, 0.8760896921157837]
reduced_sum_mae_lstm[1] = [0.597175121307373, 0.5543959736824036, 0.5330982208251953, 0.528296947479248, 0.5201374292373657, 0.5111351013183594, 0.5041407942771912, 0.4969196617603302, 0.4932692348957062, 0.4931475520133972, 0.48468756675720215, 0.4847070276737213, 0.48023509979248047, 0.47609278559684753, 0.4738355576992035, 0.47155842185020447, 0.47081494331359863, 0.4680059850215912, 0.4646148085594177, 0.461494117975235, 0.45753517746925354]
val_reduced_sum_mae_lstm[1] = [0.7256277799606323, 0.7070249319076538, 0.5639073848724365, 0.552947998046875, 0.552203357219696, 0.5995463728904724, 0.5269564986228943, 0.5324033498764038, 0.5683043003082275, 0.515510618686676, 0.5356744527816772, 0.5203122496604919, 0.6005562543869019, 0.5144112706184387, 0.5052013397216797, 0.5217799544334412, 0.5357799530029297, 0.5167620182037354, 0.49974608421325684, 0.5086480975151062, 0.5090917348861694]
# 74/74 [==============================] - 1s 19ms/step - loss: 2.2406 - gate_output_loss: 0.4590 - reduced_sum_loss: 0.5489 - gate_output_accuracy: 0.8761 - reduced_sum_mae: 0.5091
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== LSTM ===========
# loss                : 2.9507
# gate_output_loss    : 1.1682
# reduced_sum_loss     : 0.5538
# gate_output_accuracy: 0.7417
# reduced_sum_mae      : 0.5385
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-24_11:11:38/model_LSTM.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-24_11:11:38/model_LSTM.png

################# 3

# Epoch 45/100
# Epoch 00045: LearningRateScheduler reducing learning rate to 0.0004304672100000001.
# 261/261 [==============================] - 37s 141ms/step - loss: 1.2995 - gate_output_loss: 0.1033 - reduced_sum_loss: 0.3866 - gate_output_accuracy: 0.9643 - reduced_sum_mae: 0.4247 - val_loss: 1.6486 - val_gate_output_loss: 0.4061 - val_reduced_sum_loss: 0.4591 - val_gate_output_accuracy: 0.8932 - val_reduced_sum_mae: 0.4596
# [on_epoch_end] epoch: 44 , loss: 1.3018101453781128 , val_loss : 1.648568034172058
# Epoch 00045: val_loss did not improve from 1.43197
# Epoch 46/100
# Epoch 00046: LearningRateScheduler reducing learning rate to 0.0003874204890000001.
# 261/261 [==============================] - 36s 138ms/step - loss: 1.2155 - gate_output_loss: 0.1095 - reduced_sum_loss: 0.3839 - gate_output_accuracy: 0.9618 - reduced_sum_mae: 0.4215 - val_loss: 1.5016 - val_gate_output_loss: 0.3949 - val_reduced_sum_loss: 0.4619 - val_gate_output_accuracy: 0.9126 - val_reduced_sum_mae: 0.4592
# [on_epoch_end] epoch: 45 , loss: 1.2003568410873413 , val_loss : 1.5016390085220337
# Epoch 00046: val_loss did not improve from 1.43197
loss_lstm[2] = [64.31385040283203, 3.082988739013672, 2.9111077785491943, 2.863663911819458, 2.811826705932617, 2.56992244720459, 2.5193724632263184, 2.5613746643066406, 2.5333011150360107, 2.508484363555908, 2.3008694648742676, 2.2848141193389893, 2.336301326751709, 2.3059096336364746, 2.2677788734436035, 2.0604896545410156, 2.0835866928100586, 2.0741891860961914, 2.061365842819214, 2.0823545455932617, 1.8768950700759888, 1.8885784149169922, 1.8760489225387573, 1.8941277265548706, 1.880576252937317, 1.7120825052261353, 1.7182464599609375, 1.7164719104766846, 1.7110496759414673, 1.7250385284423828, 1.5600672960281372, 1.5560908317565918, 1.5635943412780762, 1.5687317848205566, 1.5635533332824707, 1.4318453073501587, 1.4257386922836304, 1.4282094240188599, 1.412307858467102, 1.438387155532837, 1.3034272193908691, 1.3114856481552124, 1.296189308166504, 1.309927225112915, 1.3018101453781128, 1.2003568410873413]
val_loss_lstm[2] = [3.640850305557251, 3.238792657852173, 3.0024566650390625, 2.9325315952301025, 2.9344847202301025, 2.6926283836364746, 2.5446560382843018, 2.5959408283233643, 2.541241407394409, 2.6970882415771484, 2.3174288272857666, 2.4716298580169678, 2.5058541297912598, 2.3847029209136963, 2.5664150714874268, 2.2077832221984863, 2.151653289794922, 2.246406078338623, 2.2434890270233154, 2.4604849815368652, 2.032592535018921, 2.0140998363494873, 2.045463800430298, 2.024732828140259, 2.1614084243774414, 1.8692009449005127, 1.9020172357559204, 1.817026138305664, 1.8685566186904907, 2.113523244857788, 1.725757360458374, 1.7054365873336792, 1.76286780834198, 1.835591435432434, 1.8451489210128784, 1.6760560274124146, 1.803020715713501, 1.5589832067489624, 1.6595126390457153, 1.7590787410736084, 1.4319744110107422, 1.5646978616714478, 1.5259132385253906, 1.526893973350525, 1.648568034172058, 1.5016390085220337]
gate_output_loss_lstm[2] = [0.7067498564720154, 0.32081079483032227, 0.2555731534957886, 0.23382586240768433, 0.21474666893482208, 0.20044130086898804, 0.1911923736333847, 0.18519191443920135, 0.18239684402942657, 0.1717097908258438, 0.1685250997543335, 0.16526880860328674, 0.17389826476573944, 0.16352087259292603, 0.15821781754493713, 0.14390379190444946, 0.15546181797981262, 0.14798788726329803, 0.141388937830925, 0.1509607434272766, 0.1345340460538864, 0.13778188824653625, 0.13674771785736084, 0.1398676037788391, 0.13605207204818726, 0.12389040738344193, 0.13053372502326965, 0.12503716349601746, 0.12427877634763718, 0.13122713565826416, 0.11807548254728317, 0.11929364502429962, 0.11958108842372894, 0.12095212936401367, 0.1188073456287384, 0.1141868457198143, 0.11199618130922318, 0.11256496608257294, 0.104192353785038, 0.11522631347179413, 0.10455251485109329, 0.11087815463542938, 0.10313493758440018, 0.10444696247577667, 0.10381411761045456, 0.10505956411361694]
val_gate_output_loss_lstm[2] = [0.8042401075363159, 0.5125473737716675, 0.3444051742553711, 0.29466021060943604, 0.2329888790845871, 0.33430901169776917, 0.2036665976047516, 0.23344886302947998, 0.23995113372802734, 0.3222713768482208, 0.21302609145641327, 0.32997506856918335, 0.3470872938632965, 0.27930134534835815, 0.441534161567688, 0.31695276498794556, 0.2361408919095993, 0.32480761408805847, 0.2641424536705017, 0.5027883052825928, 0.29090890288352966, 0.28101199865341187, 0.28261008858680725, 0.2944276034832001, 0.39990803599357605, 0.2825995981693268, 0.3064391613006592, 0.24755704402923584, 0.2629273235797882, 0.4825035333633423, 0.30917611718177795, 0.2761119604110718, 0.31165727972984314, 0.391218364238739, 0.3717667758464813, 0.3669399917125702, 0.48240822553634644, 0.24581362307071686, 0.3594076335430145, 0.39805665612220764, 0.25596481561660767, 0.361795574426651, 0.3154868185520172, 0.3422478437423706, 0.40606316924095154, 0.3949415683746338]
reduced_sum_loss_lstm[2] = [0.7075616121292114, 0.6114231944084167, 0.5844512581825256, 0.5571268200874329, 0.5312352776527405, 0.5238047242164612, 0.5103427767753601, 0.49728134274482727, 0.4862806499004364, 0.48141178488731384, 0.4746405780315399, 0.47498688101768494, 0.46961086988449097, 0.4653191566467285, 0.45621147751808167, 0.45912691950798035, 0.44796985387802124, 0.44399216771125793, 0.44591793417930603, 0.43941253423690796, 0.43324825167655945, 0.4351220428943634, 0.430447518825531, 0.42742058634757996, 0.42241573333740234, 0.418255090713501, 0.4173198342323303, 0.41966328024864197, 0.4165942966938019, 0.41419681906700134, 0.4055022895336151, 0.4063987731933594, 0.4099489748477936, 0.40098342299461365, 0.4014277458190918, 0.3977656364440918, 0.39587050676345825, 0.39524954557418823, 0.3981245160102844, 0.3939880132675171, 0.3890261948108673, 0.3899485170841217, 0.38431021571159363, 0.38862618803977966, 0.3853984475135803, 0.38265910744667053]
val_reduced_sum_loss_lstm[2] = [0.9288467168807983, 0.9020850658416748, 0.6405582427978516, 0.578157901763916, 0.6106175780296326, 0.5557435750961304, 0.6084721684455872, 0.555454432964325, 0.5456423759460449, 0.559256374835968, 0.5053513646125793, 0.52558434009552, 0.5221937894821167, 0.5157161951065063, 0.5096533298492432, 0.5037901997566223, 0.4999139904975891, 0.5005859732627869, 0.5533166527748108, 0.5058578252792358, 0.4794883131980896, 0.5015907883644104, 0.4895213842391968, 0.457054078578949, 0.47374698519706726, 0.49288731813430786, 0.4660826325416565, 0.4611048698425293, 0.48429617285728455, 0.4822510778903961, 0.4746217131614685, 0.45033055543899536, 0.4638693630695343, 0.46426066756248474, 0.4898829460144043, 0.47828203439712524, 0.46375328302383423, 0.45712992548942566, 0.4588804244995117, 0.46774822473526, 0.4449818432331085, 0.4633338153362274, 0.4718509912490845, 0.4427984058856964, 0.45912468433380127, 0.4618607461452484]
gate_output_accuracy_lstm[2] = [0.7808752059936523, 0.9085001945495605, 0.9181920886039734, 0.922738254070282, 0.9266226887702942, 0.9308332204818726, 0.9335187673568726, 0.9341182112693787, 0.9354513883590698, 0.9395947456359863, 0.9401702284812927, 0.9418007135391235, 0.9395372271537781, 0.9416520595550537, 0.9458961486816406, 0.9478767514228821, 0.9463229775428772, 0.9465771317481995, 0.9501115083694458, 0.9466347098350525, 0.9524853229522705, 0.9512768387794495, 0.9522455334663391, 0.9508931636810303, 0.9512288570404053, 0.9564704298973083, 0.9537801146507263, 0.9563697576522827, 0.9561156034469604, 0.9543891549110413, 0.9577412605285645, 0.9579139351844788, 0.95802903175354, 0.9578036069869995, 0.9580482244491577, 0.9596691131591797, 0.959649920463562, 0.959309458732605, 0.9622827172279358, 0.9584270715713501, 0.9624601602554321, 0.9605562686920166, 0.9632465839385986, 0.96241694688797, 0.9639227986335754, 0.9627382755279541]
val_gate_output_accuracy_lstm[2] = [0.7575116157531738, 0.7637579441070557, 0.8895471692085266, 0.9082353115081787, 0.9166314005851746, 0.8889039158821106, 0.9263309240341187, 0.9219974875450134, 0.9273296594619751, 0.894794762134552, 0.9304274320602417, 0.8869064450263977, 0.8893440365791321, 0.9170207381248474, 0.8661531805992126, 0.9010071754455566, 0.9251798391342163, 0.902716875076294, 0.913855254650116, 0.8339060544967651, 0.9074904918670654, 0.9186965823173523, 0.9234532117843628, 0.9138213992118835, 0.8774439096450806, 0.9205924868583679, 0.9186965823173523, 0.9234532117843628, 0.9219297766685486, 0.8590943813323975, 0.9056622982025146, 0.9139906764030457, 0.9145492911338806, 0.9075751304626465, 0.8987558484077454, 0.9072365760803223, 0.887329638004303, 0.9208464026451111, 0.904731273651123, 0.8904951214790344, 0.9217435717582703, 0.915226399898529, 0.9237240552902222, 0.9025475978851318, 0.8931527733802795, 0.9126195311546326]
reduced_sum_mae_lstm[2] = [0.5939357280731201, 0.5494011044502258, 0.5373159050941467, 0.5261341333389282, 0.514036238193512, 0.5083672404289246, 0.49950912594795227, 0.49086111783981323, 0.4852162003517151, 0.4818955957889557, 0.477900892496109, 0.47700414061546326, 0.473341166973114, 0.4703655242919922, 0.4666278660297394, 0.465709924697876, 0.4607992172241211, 0.45894211530685425, 0.4580574035644531, 0.4567960500717163, 0.4512978196144104, 0.4521883726119995, 0.4498249292373657, 0.4476300776004791, 0.44537636637687683, 0.442882776260376, 0.4424705505371094, 0.44211462140083313, 0.4411277770996094, 0.4400624930858612, 0.43533846735954285, 0.4353700876235962, 0.4370858669281006, 0.43256068229675293, 0.43196338415145874, 0.4300675094127655, 0.42933449149131775, 0.42906320095062256, 0.43098437786102295, 0.42756178975105286, 0.4251239597797394, 0.42581161856651306, 0.4229145050048828, 0.42474550008773804, 0.4236963987350464, 0.4208955764770508]
val_reduced_sum_mae_lstm[2] = [0.7260617017745972, 0.7068625092506409, 0.5729045271873474, 0.5321168899536133, 0.5511903166770935, 0.5175175070762634, 0.5479709506034851, 0.5196275115013123, 0.5100069046020508, 0.5165887475013733, 0.48496925830841064, 0.4974420368671417, 0.4962189197540283, 0.49127256870269775, 0.4947463572025299, 0.4891756474971771, 0.48446986079216003, 0.4847978353500366, 0.515650749206543, 0.4862855076789856, 0.46953800320625305, 0.48643818497657776, 0.4784482717514038, 0.45704030990600586, 0.4657202363014221, 0.4792315661907196, 0.46436139941215515, 0.4576855003833771, 0.4744374752044678, 0.47385135293006897, 0.46460649371147156, 0.45272570848464966, 0.45976486802101135, 0.4658556282520294, 0.47919076681137085, 0.4700106382369995, 0.4628339111804962, 0.4584006369113922, 0.4588777720928192, 0.46470025181770325, 0.450077086687088, 0.4609377682209015, 0.4658569097518921, 0.44876527786254883, 0.4595690071582794, 0.4592123031616211]
# 74/74 [==============================] - 3s 44ms/step - loss: 1.5016 - gate_output_loss: 0.3949 - reduced_sum_loss: 0.4619 - gate_output_accuracy: 0.9126 - reduced_sum_mae: 0.4592
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== LSTM ===========
# loss                : 2.1637
# gate_output_loss    : 1.0539
# reduced_sum_loss     : 0.4774
# gate_output_accuracy: 0.7944
# reduced_sum_mae      : 0.4983
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-24_11:18:46/model_LSTM.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-24_11:18:46/model_LSTM.png


################# 4
# Epoch 54/100
# Epoch 00054: LearningRateScheduler reducing learning rate to 0.0003486784401000001.
# 261/261 [==============================] - 37s 143ms/step - loss: 1.0889 - gate_output_loss: 0.1030 - reduced_sum_loss: 0.3870 - gate_output_accuracy: 0.9637 - reduced_sum_mae: 0.4230 - val_loss: 1.3398 - val_gate_output_loss: 0.3360 - val_reduced_sum_loss: 0.4567 - val_gate_output_accuracy: 0.8981 - val_reduced_sum_mae: 0.4543
# [on_epoch_end] epoch: 53 , loss: 1.0878181457519531 , val_loss : 1.339830994606018
# Epoch 00054: val_loss did not improve from 1.32912
# Epoch 55/100
# Epoch 00055: LearningRateScheduler reducing learning rate to 0.0003486784401000001.
# 261/261 [==============================] - 37s 142ms/step - loss: 1.0943 - gate_output_loss: 0.1009 - reduced_sum_loss: 0.3844 - gate_output_accuracy: 0.9641 - reduced_sum_mae: 0.4221 - val_loss: 1.4522 - val_gate_output_loss: 0.4604 - val_reduced_sum_loss: 0.4543 - val_gate_output_accuracy: 0.8704 - val_reduced_sum_mae: 0.4535
# [on_epoch_end] epoch: 54 , loss: 1.0952659845352173 , val_loss : 1.452240228652954
# Epoch 00055: val_loss did not improve from 1.32912
# Epoch 56/100
# Epoch 00056: LearningRateScheduler reducing learning rate to 0.0003138105960900001.
# 261/261 [==============================] - 38s 146ms/step - loss: 1.0130 - gate_output_loss: 0.1008 - reduced_sum_loss: 0.3798 - gate_output_accuracy: 0.9645 - reduced_sum_mae: 0.4190 - val_loss: 1.3555 - val_gate_output_loss: 0.4224 - val_reduced_sum_loss: 0.4766 - val_gate_output_accuracy: 0.8754 - val_reduced_sum_mae: 0.4675
# [on_epoch_end] epoch: 55 , loss: 1.0090903043746948 , val_loss : 1.3554658889770508
# Epoch 00056: val_loss did not improve from 1.32912
loss_lstm[3] = [64.35928344726562, 3.0533573627471924, 2.9086804389953613, 2.8367652893066406, 2.809084177017212, 2.5288267135620117, 2.4929733276367188, 2.5318703651428223, 2.5045998096466064, 2.5032894611358643, 2.30753493309021, 2.281902313232422, 2.2744393348693848, 2.270613193511963, 2.289236307144165, 2.0674562454223633, 2.0582573413848877, 2.073958396911621, 2.0700771808624268, 2.1685590744018555, 1.8675094842910767, 1.8658145666122437, 1.8735690116882324, 1.872797966003418, 1.893425464630127, 1.698110580444336, 1.71323823928833, 1.7071914672851562, 1.7071563005447388, 1.7018824815750122, 1.5739115476608276, 1.5570136308670044, 1.5499906539916992, 1.6134967803955078, 1.56391179561615, 1.4217863082885742, 1.4252601861953735, 1.4196497201919556, 1.4254181385040283, 1.4209954738616943, 1.3007185459136963, 1.3126933574676514, 1.3040707111358643, 1.2997972965240479, 1.3032594919204712, 1.188706398010254, 1.1880656480789185, 1.196315050125122, 1.1979120969772339, 1.1953327655792236, 1.0889333486557007, 1.084840178489685, 1.1013559103012085, 1.0878181457519531, 1.0952659845352173, 1.0090903043746948]
val_loss_lstm[3] = [3.563382863998413, 3.3165042400360107, 2.9559359550476074, 2.9855926036834717, 3.0930428504943848, 2.603092670440674, 2.900588035583496, 2.603191375732422, 2.5527422428131104, 2.76645827293396, 2.3131837844848633, 2.543896436691284, 2.5977327823638916, 2.519052743911743, 2.3989386558532715, 2.242535352706909, 2.206134557723999, 2.3992578983306885, 2.444790840148926, 2.286884307861328, 1.9455105066299438, 2.3144664764404297, 2.084442377090454, 2.082814931869507, 2.0777649879455566, 1.8652794361114502, 2.10404109954834, 1.8652197122573853, 2.003316879272461, 2.0841915607452393, 1.7722644805908203, 1.7506959438323975, 1.74766206741333, 1.8705486059188843, 1.7757714986801147, 1.6958616971969604, 1.8333377838134766, 1.8178322315216064, 1.9078221321105957, 1.6511008739471436, 1.512690782546997, 1.911585807800293, 1.5541291236877441, 1.5584312677383423, 1.5108962059020996, 1.4793310165405273, 1.3734737634658813, 1.5572631359100342, 1.5603737831115723, 1.55582594871521, 1.329118251800537, 1.3806248903274536, 1.3678522109985352, 1.339830994606018, 1.452240228652954, 1.3554658889770508]
gate_output_loss_lstm[3] = [0.7140033841133118, 0.30770739912986755, 0.24946707487106323, 0.2329593300819397, 0.21421962976455688, 0.19462835788726807, 0.18700766563415527, 0.19434958696365356, 0.18922334909439087, 0.17616114020347595, 0.17574623227119446, 0.17415566742420197, 0.16792210936546326, 0.16782884299755096, 0.16546489298343658, 0.15923990309238434, 0.15534961223602295, 0.15512752532958984, 0.15840131044387817, 0.16683420538902283, 0.14500391483306885, 0.14575441181659698, 0.143588587641716, 0.14777228236198425, 0.15204869210720062, 0.13061493635177612, 0.14138947427272797, 0.14118213951587677, 0.13796564936637878, 0.1334460973739624, 0.13319967687129974, 0.13268660008907318, 0.12621554732322693, 0.1394806206226349, 0.1296631395816803, 0.12176714837551117, 0.12129230797290802, 0.12039744108915329, 0.12330888211727142, 0.12119802832603455, 0.1145016998052597, 0.11986719071865082, 0.11704710870981216, 0.11277533322572708, 0.11499354243278503, 0.10843998193740845, 0.10789920389652252, 0.11141035705804825, 0.11163772642612457, 0.11016387492418289, 0.10084507614374161, 0.10175605118274689, 0.10830114036798477, 0.1019640862941742, 0.10406290739774704, 0.10054244101047516]
val_gate_output_loss_lstm[3] = [0.7961151599884033, 0.5177305936813354, 0.37261325120925903, 0.41618603467941284, 0.5332376956939697, 0.28863510489463806, 0.5684488415718079, 0.3149045705795288, 0.27955716848373413, 0.40243208408355713, 0.22708068788051605, 0.4340056777000427, 0.47873568534851074, 0.4166257977485657, 0.28295430541038513, 0.34259673953056335, 0.31494346261024475, 0.505260169506073, 0.48051369190216064, 0.34705445170402527, 0.23990626633167267, 0.5718650221824646, 0.3300795257091522, 0.3223037123680115, 0.3242742121219635, 0.3208824396133423, 0.5272694230079651, 0.2757469415664673, 0.42098647356033325, 0.5022662878036499, 0.3608083128929138, 0.31595292687416077, 0.3048709034919739, 0.4036036431789398, 0.34595510363578796, 0.416551411151886, 0.5191145539283752, 0.5153173804283142, 0.6170052886009216, 0.3497052788734436, 0.342276930809021, 0.7112698554992676, 0.35300323367118835, 0.3510729670524597, 0.32986992597579956, 0.4162008464336395, 0.29457810521125793, 0.4725860059261322, 0.4768032431602478, 0.4678105413913727, 0.36139100790023804, 0.37178412079811096, 0.36283496022224426, 0.3359774351119995, 0.4604158401489258, 0.4223719835281372]
reduced_sum_loss_lstm[3] = [0.7581322193145752, 0.6852399706840515, 0.6090801954269409, 0.5841244459152222, 0.5667550563812256, 0.5583113431930542, 0.5424270629882812, 0.5379964113235474, 0.5271596908569336, 0.5198831558227539, 0.5110822319984436, 0.521089494228363, 0.5064923167228699, 0.5056278705596924, 0.4991692006587982, 0.49363115429878235, 0.4897594749927521, 0.4860519468784332, 0.4854537546634674, 0.473220556974411, 0.458227276802063, 0.45261064171791077, 0.4576506018638611, 0.4406076967716217, 0.4378846287727356, 0.4398871660232544, 0.4350214898586273, 0.42626121640205383, 0.4247215688228607, 0.4288627803325653, 0.4207474887371063, 0.4152902364730835, 0.4160211980342865, 0.4131639897823334, 0.41229647397994995, 0.4084152281284332, 0.41456928849220276, 0.4093053936958313, 0.4057386517524719, 0.4001755714416504, 0.3983045220375061, 0.40214040875434875, 0.3972274363040924, 0.3971681296825409, 0.39702752232551575, 0.3950095474720001, 0.39174342155456543, 0.39419296383857727, 0.3919803202152252, 0.39277926087379456, 0.38991984724998474, 0.3850862979888916, 0.38573628664016724, 0.38521867990493774, 0.3853996992111206, 0.3819008469581604]
val_reduced_sum_loss_lstm[3] = [0.9322535991668701, 0.9101935625076294, 0.6406050324440002, 0.6214185357093811, 0.6211458444595337, 0.6358749866485596, 0.5927534699440002, 0.5866906642913818, 0.567400336265564, 0.5731459856033325, 0.608244001865387, 0.6202502846717834, 0.5647757649421692, 0.5483750700950623, 0.5471689105033875, 0.5306406021118164, 0.5376029014587402, 0.5355412364006042, 0.5509223341941833, 0.5518587231636047, 0.5111258625984192, 0.5403868556022644, 0.4990902245044708, 0.5075210332870483, 0.5147387981414795, 0.5034795999526978, 0.49300438165664673, 0.47408854961395264, 0.47970983386039734, 0.4808136820793152, 0.4735681414604187, 0.46922066807746887, 0.4910796582698822, 0.4736725389957428, 0.48356086015701294, 0.4754326045513153, 0.4666619300842285, 0.4650469124317169, 0.45964545011520386, 0.4575028419494629, 0.45673683285713196, 0.4693288803100586, 0.46450817584991455, 0.4518507122993469, 0.45499682426452637, 0.4658011496067047, 0.45293137431144714, 0.47182443737983704, 0.4576495587825775, 0.4642394483089447, 0.457129567861557, 0.44866010546684265, 0.4657524824142456, 0.4567257761955261, 0.4543178081512451, 0.47663018107414246]
gate_output_accuracy_lstm[3] = [0.7812924385070801, 0.9110034704208374, 0.9194053411483765, 0.921587347984314, 0.9259849190711975, 0.9319937825202942, 0.935638427734375, 0.9333413243293762, 0.9345066547393799, 0.9407169222831726, 0.9384438395500183, 0.9406498074531555, 0.9407073259353638, 0.9413787126541138, 0.942496120929718, 0.9449946284294128, 0.9448699355125427, 0.9458529949188232, 0.9436614513397217, 0.9415178298950195, 0.9487975239753723, 0.9487639665603638, 0.9495407938957214, 0.9475794434547424, 0.9450761079788208, 0.9539191722869873, 0.950499951839447, 0.949430525302887, 0.9517899751663208, 0.9529169201850891, 0.9522167444229126, 0.9528833627700806, 0.9561635255813599, 0.9511569142341614, 0.954336404800415, 0.9570938944816589, 0.9576405882835388, 0.9572617411613464, 0.9567390084266663, 0.956825315952301, 0.959251880645752, 0.9572473168373108, 0.9577892422676086, 0.95870041847229, 0.9593477845191956, 0.9616209268569946, 0.9615537524223328, 0.9604795575141907, 0.960321307182312, 0.9608344435691833, 0.9637885093688965, 0.9637501239776611, 0.961803138256073, 0.9639371633529663, 0.962810218334198, 0.9639659523963928]
val_gate_output_accuracy_lstm[3] = [0.7575116157531738, 0.7681760191917419, 0.8712992072105408, 0.8737198710441589, 0.8336690664291382, 0.9027338027954102, 0.820194661617279, 0.8959458470344543, 0.9067118167877197, 0.8854676485061646, 0.9288023710250854, 0.85801100730896, 0.8597884178161621, 0.8683030009269714, 0.9150909781455994, 0.8921201825141907, 0.9009225368499756, 0.8490224480628967, 0.85801100730896, 0.8962844014167786, 0.924993634223938, 0.8221752047538757, 0.9088277816772461, 0.8993990421295166, 0.9094202518463135, 0.9021751880645752, 0.8397968411445618, 0.9171900153160095, 0.8713838458061218, 0.8637155890464783, 0.8899534344673157, 0.9028353691101074, 0.9096741676330566, 0.8849259614944458, 0.8987050652503967, 0.8816081285476685, 0.8418112397193909, 0.8551671504974365, 0.8338552713394165, 0.8926618695259094, 0.9060347080230713, 0.808091402053833, 0.895438015460968, 0.8898349404335022, 0.8980787396430969, 0.8852475881576538, 0.9126195311546326, 0.8716885447502136, 0.8635463118553162, 0.8799999952316284, 0.8846381902694702, 0.888853132724762, 0.8951502442359924, 0.8980618119239807, 0.8704020380973816, 0.8754125833511353]
reduced_sum_mae_lstm[3] = [0.6083449721336365, 0.5751553773880005, 0.5479393005371094, 0.5369787216186523, 0.5274494886398315, 0.5224355459213257, 0.5115383863449097, 0.5057944059371948, 0.5012244582176208, 0.4981500506401062, 0.49355173110961914, 0.4953776001930237, 0.4891037046909332, 0.48809510469436646, 0.4853035509586334, 0.4818194508552551, 0.4799501299858093, 0.47678208351135254, 0.47650718688964844, 0.4704773724079132, 0.46342915296554565, 0.46070948243141174, 0.4621643126010895, 0.4531390070915222, 0.4526691138744354, 0.45097723603248596, 0.44898074865341187, 0.44438469409942627, 0.4439897835254669, 0.44564810395240784, 0.44145655632019043, 0.4380705654621124, 0.4388183057308197, 0.43753400444984436, 0.43702489137649536, 0.4347221553325653, 0.4371354579925537, 0.4351681172847748, 0.4330177307128906, 0.4306688606739044, 0.4292072653770447, 0.4303334951400757, 0.4285714626312256, 0.42870965600013733, 0.4286695718765259, 0.42759349942207336, 0.42525750398635864, 0.4273403584957123, 0.4253734052181244, 0.4264042377471924, 0.4238615036010742, 0.42217472195625305, 0.42175015807151794, 0.4218672811985016, 0.42288750410079956, 0.4203207790851593]
val_reduced_sum_mae_lstm[3] = [0.7255893349647522, 0.7095352411270142, 0.5626445412635803, 0.5496556162834167, 0.5475517511367798, 0.5561976432800293, 0.527910053730011, 0.5247060060501099, 0.5154417157173157, 0.518235445022583, 0.5352411866188049, 0.5441675186157227, 0.5107830166816711, 0.5006471276283264, 0.5011931657791138, 0.4926776885986328, 0.497873455286026, 0.4947974979877472, 0.5014423727989197, 0.5053107738494873, 0.485384464263916, 0.5012829899787903, 0.4760987460613251, 0.4830256402492523, 0.48704299330711365, 0.47848042845726013, 0.4721370339393616, 0.4623718559741974, 0.46513956785202026, 0.4676610231399536, 0.46198344230651855, 0.4612973630428314, 0.4724093973636627, 0.463849812746048, 0.46994414925575256, 0.4655134081840515, 0.4600975513458252, 0.4614813029766083, 0.4563097655773163, 0.4536442458629608, 0.4545271694660187, 0.4635207951068878, 0.45887279510498047, 0.4508105516433716, 0.4546847641468048, 0.45861557126045227, 0.45246562361717224, 0.46431300044059753, 0.4551870822906494, 0.4597128927707672, 0.4549393355846405, 0.4494657516479492, 0.46370893716812134, 0.45433247089385986, 0.45349594950675964, 0.4674552083015442]
# 74/74 [==============================] - 3s 39ms/step - loss: 1.3555 - gate_output_loss: 0.4224 - reduced_sum_loss: 0.4766 - gate_output_accuracy: 0.8754 - reduced_sum_mae: 0.4675
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== LSTM ===========
# loss                : 2.8482
# gate_output_loss    : 1.9115
# reduced_sum_loss     : 0.4950
# gate_output_accuracy: 0.6603
# reduced_sum_mae      : 0.5072
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-24_11:19:06/model_LSTM.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-24_11:19:06/model_LSTM.png

################# 5
# Epoch 59/100
# Epoch 00059: LearningRateScheduler reducing learning rate to 0.0003138105960900001.
# 261/261 [==============================] - 26s 100ms/step - loss: 0.9931 - gate_output_loss: 0.0928 - reduced_sum_loss: 0.3577 - gate_output_accuracy: 0.9661 - reduced_sum_mae: 0.4083 - val_loss: 1.2987 - val_gate_output_loss: 0.3514 - val_reduced_sum_loss: 0.5567 - val_gate_output_accuracy: 0.9067 - val_reduced_sum_mae: 0.5157
# [on_epoch_end] epoch: 58 , loss: 0.995093047618866 , val_loss : 1.29871666431427
# Epoch 00059: val_loss did not improve from 1.29600
loss_lstm[4] = [64.36224365234375, 3.1145009994506836, 2.923790216445923, 2.871480703353882, 2.8277688026428223, 2.54606556892395, 2.508704662322998, 2.5382115840911865, 2.4987149238586426, 2.510873317718506, 2.274545431137085, 2.2667086124420166, 2.2610983848571777, 2.2764344215393066, 2.2553651332855225, 2.0570883750915527, 2.040031671524048, 2.0495688915252686, 2.0555620193481445, 2.283987283706665, 1.8811683654785156, 1.851341724395752, 1.8415863513946533, 1.86350417137146, 1.8609164953231812, 1.6911826133728027, 1.694462537765503, 1.6968640089035034, 1.6989667415618896, 1.6868751049041748, 1.534053921699524, 1.551112174987793, 1.538917899131775, 1.5720945596694946, 1.5407971143722534, 1.4212493896484375, 1.4222559928894043, 1.4032303094863892, 1.4133448600769043, 1.4136548042297363, 1.2927323579788208, 1.2858854532241821, 1.3065454959869385, 1.2968300580978394, 1.2949883937835693, 1.1806708574295044, 1.1827284097671509, 1.1801968812942505, 1.1955933570861816, 1.192299246788025, 1.085085391998291, 1.0863502025604248, 1.087034821510315, 1.0860377550125122, 1.081119418144226, 0.9967519640922546, 0.9934939742088318, 0.9994956254959106, 0.995093047618866]
val_loss_lstm[4] = [3.6979451179504395, 3.3429887294769287, 2.8654985427856445, 2.9951164722442627, 2.9348981380462646, 2.658163547515869, 2.6237049102783203, 2.7634077072143555, 2.7147669792175293, 2.7270283699035645, 2.4800121784210205, 2.3190338611602783, 2.545383930206299, 2.428074598312378, 2.5215249061584473, 2.2692203521728516, 2.3106892108917236, 2.286118745803833, 2.237600088119507, 2.684134006500244, 2.036154270172119, 2.0394747257232666, 2.043032169342041, 2.1015279293060303, 2.158127546310425, 1.8858124017715454, 1.867720603942871, 2.0320820808410645, 1.9474629163742065, 1.8398460149765015, 1.8385770320892334, 1.8395947217941284, 1.7120726108551025, 1.736520767211914, 1.8021917343139648, 1.6587285995483398, 1.6323250532150269, 1.7153927087783813, 1.8658968210220337, 1.8038886785507202, 1.538190484046936, 1.6223397254943848, 1.5811951160430908, 1.5977574586868286, 1.559708833694458, 1.5248974561691284, 1.5271430015563965, 1.5847822427749634, 1.4331567287445068, 1.592223048210144, 1.4229072332382202, 1.4694746732711792, 1.3713960647583008, 1.29599928855896, 1.3281478881835938, 1.336679458618164, 1.3674250841140747, 1.4812370538711548, 1.29871666431427]
gate_output_loss_lstm[4] = [0.7012587785720825, 0.32145097851753235, 0.25396284461021423, 0.2368098795413971, 0.21589291095733643, 0.20294605195522308, 0.19056417047977448, 0.19054600596427917, 0.18006427586078644, 0.18102939426898956, 0.16473078727722168, 0.1604326218366623, 0.1616087406873703, 0.15925996005535126, 0.15399038791656494, 0.14752279222011566, 0.14312045276165009, 0.14843915402889252, 0.1470654010772705, 0.16170884668827057, 0.1400817334651947, 0.13785827159881592, 0.13073968887329102, 0.14465977251529694, 0.13620899617671967, 0.13012941181659698, 0.1282203495502472, 0.13058342039585114, 0.1316778063774109, 0.12383534759283066, 0.11475518345832825, 0.12446453422307968, 0.11943352967500687, 0.1330113410949707, 0.11752137541770935, 0.1159299835562706, 0.12074300646781921, 0.11339902132749557, 0.1151314228773117, 0.11279398947954178, 0.10955404490232468, 0.10830176621675491, 0.1165652722120285, 0.11062335222959518, 0.11175967007875443, 0.10207299888134003, 0.10433991998434067, 0.1017088070511818, 0.10908406227827072, 0.10720720142126083, 0.10061873495578766, 0.10071395337581635, 0.10064022243022919, 0.09984835982322693, 0.09763392060995102, 0.09324492514133453, 0.09321645647287369, 0.09702833741903305, 0.09294221550226212]
val_gate_output_loss_lstm[4] = [0.8583911061286926, 0.5355876088142395, 0.2682928740978241, 0.30276167392730713, 0.3168993890285492, 0.2982953190803528, 0.2910788059234619, 0.411150723695755, 0.3351235091686249, 0.342423677444458, 0.39020976424217224, 0.21550850570201874, 0.42700669169425964, 0.30888304114341736, 0.41646409034729004, 0.34703776240348816, 0.41175025701522827, 0.3563340902328491, 0.3253195285797119, 0.291617751121521, 0.3435208797454834, 0.31082260608673096, 0.322111576795578, 0.3825184106826782, 0.3331673741340637, 0.3147371709346771, 0.29675179719924927, 0.4299212098121643, 0.3714945316314697, 0.27543964982032776, 0.4222105145454407, 0.36820188164711, 0.28952455520629883, 0.30774885416030884, 0.374125212430954, 0.36988043785095215, 0.3253868520259857, 0.4105718433856964, 0.5818806886672974, 0.5043405890464783, 0.3731914758682251, 0.41900354623794556, 0.38409531116485596, 0.411895215511322, 0.35165899991989136, 0.44876331090927124, 0.43840181827545166, 0.48593056201934814, 0.34286168217658997, 0.4833308756351471, 0.44722098112106323, 0.4804682433605194, 0.36622071266174316, 0.3076730966567993, 0.3337145745754242, 0.43291300535202026, 0.4570828676223755, 0.5655364394187927, 0.35136985778808594]
reduced_sum_loss_lstm[4] = [0.7054595351219177, 0.6104239821434021, 0.5688767433166504, 0.545759379863739, 0.5349301695823669, 0.5098819136619568, 0.4984413683414459, 0.49170151352882385, 0.48606860637664795, 0.47526976466178894, 0.46837565302848816, 0.4618626832962036, 0.45538270473480225, 0.4564235806465149, 0.4454764425754547, 0.4405699670314789, 0.43873047828674316, 0.4325436055660248, 0.43217799067497253, 0.4352123737335205, 0.4336422383785248, 0.42161062359809875, 0.4148719310760498, 0.4153638184070587, 0.42310863733291626, 0.403208464384079, 0.4047280251979828, 0.4025239646434784, 0.40024471282958984, 0.40193405747413635, 0.3938480615615845, 0.39260929822921753, 0.39322787523269653, 0.3913068473339081, 0.39062178134918213, 0.3926115334033966, 0.38884642720222473, 0.3815392553806305, 0.38631629943847656, 0.3818446695804596, 0.3781391680240631, 0.3764326870441437, 0.38241541385650635, 0.3766380250453949, 0.3740575611591339, 0.37098315358161926, 0.3736230134963989, 0.3693239986896515, 0.3730722963809967, 0.3713839650154114, 0.36500510573387146, 0.3640425205230713, 0.3668859004974365, 0.36410051584243774, 0.36177393794059753, 0.36753758788108826, 0.3632242679595947, 0.3590581715106964, 0.3616456389427185]
val_reduced_sum_loss_lstm[4] = [0.9295036196708679, 0.9131284952163696, 0.6388693451881409, 0.7035452127456665, 0.7511457204818726, 0.5414754152297974, 0.6455284357070923, 0.6692743897438049, 0.7200005054473877, 0.5907205939292908, 0.5534725785255432, 0.5262678861618042, 0.569632351398468, 0.4951399564743042, 0.5005776286125183, 0.5279542803764343, 0.48024243116378784, 0.5168817639350891, 0.479432612657547, 2.3680672645568848, 0.48693791031837463, 0.4670200049877167, 0.49265724420547485, 0.46850958466529846, 0.8136679530143738, 0.4656825363636017, 0.4548889398574829, 0.4800325036048889, 0.5136632323265076, 0.47504088282585144, 0.5055409669876099, 0.4776747226715088, 0.4615202248096466, 0.45960918068885803, 0.45161062479019165, 0.4601273834705353, 0.4655713737010956, 0.44309234619140625, 0.44204574823379517, 0.45970770716667175, 0.4691028892993927, 0.4526202380657196, 0.44094064831733704, 0.4435421824455261, 0.451638400554657, 0.4585326313972473, 0.4486105144023895, 0.4605656564235687, 0.47463101148605347, 0.4677056670188904, 0.4330902397632599, 0.4314661920070648, 0.444521963596344, 0.44620445370674133, 0.44471678137779236, 0.44137904047966003, 0.43783801794052124, 0.4508783519268036, 0.5567232966423035]
gate_output_accuracy_lstm[4] = [0.7956647872924805, 0.9075362682342529, 0.9174103736877441, 0.9236398339271545, 0.9266179203987122, 0.9311881065368652, 0.9340558648109436, 0.9350437521934509, 0.9369428157806396, 0.9364104866981506, 0.9425632357597351, 0.9448219537734985, 0.9436182975769043, 0.9451624751091003, 0.9462798237800598, 0.9485529065132141, 0.9495840072631836, 0.9463805556297302, 0.9492674469947815, 0.9442656636238098, 0.950974702835083, 0.9515501856803894, 0.9535499215126038, 0.9485961198806763, 0.9523510336875916, 0.9535451531410217, 0.9546289443969727, 0.9531183242797852, 0.9541254043579102, 0.9567198157310486, 0.9600767493247986, 0.9563121795654297, 0.9584989547729492, 0.9530367851257324, 0.9587147831916809, 0.9595348238945007, 0.9572137594223022, 0.9593909382820129, 0.9594869017601013, 0.9596691131591797, 0.9603500962257385, 0.9620860815048218, 0.9589593410491943, 0.9605371356010437, 0.9601870179176331, 0.9633137583732605, 0.9629828333854675, 0.9630547761917114, 0.9614434838294983, 0.9613044261932373, 0.9646661281585693, 0.9638892412185669, 0.9640378952026367, 0.9633808732032776, 0.9651696681976318, 0.9660089015960693, 0.9674283862113953, 0.9650977253913879, 0.9663493633270264]
val_gate_output_accuracy_lstm[4] = [0.7575116157531738, 0.7691916823387146, 0.9120778441429138, 0.9092340469360352, 0.8953703045845032, 0.9015319347381592, 0.9043080806732178, 0.8709606528282166, 0.8895471692085266, 0.883334755897522, 0.8758357763290405, 0.9212018847465515, 0.8687261939048767, 0.9175962805747986, 0.8916292786598206, 0.9010071754455566, 0.8896487355232239, 0.8961997628211975, 0.9019889831542969, 0.9109944701194763, 0.8963690400123596, 0.9094033241271973, 0.9001438617706299, 0.8978586792945862, 0.8982987999916077, 0.910892903804779, 0.921963632106781, 0.8839949369430542, 0.8917308449745178, 0.9148032069206238, 0.8910368084907532, 0.901193380355835, 0.9182395339012146, 0.9121455550193787, 0.8969276547431946, 0.9010918140411377, 0.9057469367980957, 0.888531506061554, 0.8578586578369141, 0.8794583082199097, 0.9010918140411377, 0.8999745845794678, 0.9040541648864746, 0.899669885635376, 0.9084384441375732, 0.8970969319343567, 0.8867202997207642, 0.87932288646698, 0.9064579010009766, 0.8793059587478638, 0.8887007832527161, 0.8860939741134644, 0.9066271781921387, 0.9097588062286377, 0.9096064567565918, 0.8847566843032837, 0.8896656632423401, 0.8832670450210571, 0.9066610336303711]
reduced_sum_mae_lstm[4] = [0.5944838523864746, 0.5507469177246094, 0.5326926708221436, 0.5214833617210388, 0.5153170228004456, 0.5005861520767212, 0.49397000670433044, 0.4884500205516815, 0.48565673828125, 0.4792045056819916, 0.4746539294719696, 0.47092205286026, 0.46703478693962097, 0.4667910039424896, 0.4597460925579071, 0.4571334719657898, 0.45569881796836853, 0.4532998502254486, 0.45201200246810913, 0.45232120156288147, 0.45091718435287476, 0.4451746642589569, 0.44186994433403015, 0.44144099950790405, 0.4449474811553955, 0.4344629943370819, 0.4356715679168701, 0.4342523515224457, 0.4333537220954895, 0.4331353008747101, 0.42934319376945496, 0.4282807409763336, 0.42854440212249756, 0.4274786114692688, 0.42739030718803406, 0.4274420142173767, 0.42607128620147705, 0.4222680926322937, 0.42462968826293945, 0.4225015640258789, 0.4201233386993408, 0.4192102551460266, 0.4215359687805176, 0.41880765557289124, 0.41785457730293274, 0.4157562851905823, 0.4170852601528168, 0.4148925840854645, 0.4169849157333374, 0.41511639952659607, 0.41200488805770874, 0.4115946888923645, 0.4131743311882019, 0.41145655512809753, 0.41065117716789246, 0.4127509295940399, 0.4106886088848114, 0.40875425934791565, 0.4097123146057129]
val_reduced_sum_mae_lstm[4] = [0.7251095771789551, 0.7120109796524048, 0.5690203309059143, 0.6081573367118835, 0.6259061098098755, 0.508706271648407, 0.5721592903137207, 0.5882813930511475, 0.6102023124694824, 0.5332694053649902, 0.5158043503761292, 0.49847832322120667, 0.5263696312904358, 0.4811594486236572, 0.48628830909729004, 0.500091016292572, 0.4706394672393799, 0.49540242552757263, 0.4691177010536194, 1.1876144409179688, 0.4751380383968353, 0.46092379093170166, 0.47606727480888367, 0.46280598640441895, 0.6502184271812439, 0.46107804775238037, 0.4573186933994293, 0.4724498689174652, 0.4903891086578369, 0.4692296087741852, 0.48628005385398865, 0.4703502953052521, 0.458572655916214, 0.45773500204086304, 0.45514100790023804, 0.46108105778694153, 0.46074816584587097, 0.44511982798576355, 0.44771167635917664, 0.4584033489227295, 0.4639851450920105, 0.45768624544143677, 0.44550299644470215, 0.44667673110961914, 0.45218557119369507, 0.45769941806793213, 0.4488373100757599, 0.4594617187976837, 0.4697278141975403, 0.4652971029281616, 0.44091805815696716, 0.4406284689903259, 0.4496672451496124, 0.4496617317199707, 0.44912269711494446, 0.4450971484184265, 0.4436488449573517, 0.4555800259113312, 0.515661895275116]
# 74/74 [==============================] - 2s 26ms/step - loss: 1.2987 - gate_output_loss: 0.3514 - reduced_sum_loss: 0.5567 - gate_output_accuracy: 0.9067 - reduced_sum_mae: 0.5157
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== LSTM ===========
# loss                : 2.5394
# gate_output_loss    : 1.5918
# reduced_sum_loss     : 0.5580
# gate_output_accuracy: 0.7806
# reduced_sum_mae      : 0.5417
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-24_11:18:50/model_LSTM.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-24_11:18:50/model_LSTM.png

################# 6
# Epoch 11/40
# Epoch 00011: LearningRateScheduler reducing learning rate to 0.0008100000000000001.
# 261/261 [==============================] - 40s 153ms/step - loss: 2.3226 - gate_output_loss: 0.1760 - reduced_sum_loss: 0.5091 - gate_output_accuracy: 0.9379 - reduced_sum_mae: 0.4917 - val_loss: 2.6714 - val_gate_output_loss: 0.5754 - val_reduced_sum_loss: 0.5699 - val_gate_output_accuracy: 0.8237 - val_reduced_sum_mae: 0.5181
# [on_epoch_end] epoch: 10 , loss: 2.3171987533569336 , val_loss : 2.6713526248931885
# Epoch 00011: val_loss did not improve from 2.56531
loss_lstm[5] = [64.39288330078125, 3.0464353561401367, 2.966362714767456, 2.8662526607513428, 2.79567289352417, 2.559617280960083, 2.5239977836608887, 2.554243564605713, 2.503356695175171, 2.4931087493896484, 2.3171987533569336]
val_loss_lstm[5] = [3.5507564544677734, 3.3013265132904053, 3.0788164138793945, 2.9368698596954346, 3.416118621826172, 2.5653076171875, 2.676724672317505, 2.5808229446411133, 2.650847911834717, 2.595586061477661, 2.6713526248931885]
gate_output_loss_lstm[5] = [0.6994835138320923, 0.31243664026260376, 0.2644263207912445, 0.23302261531352997, 0.2115446776151657, 0.1985441893339157, 0.1897273063659668, 0.18285305798053741, 0.17919647693634033, 0.1683865487575531, 0.1743122786283493]
val_gate_output_loss_lstm[5] = [0.7873616218566895, 0.5268937349319458, 0.2933752238750458, 0.27073970437049866, 0.7828259468078613, 0.22051459550857544, 0.35677769780158997, 0.256486177444458, 0.32752418518066406, 0.2567986845970154, 0.5754125118255615]
reduced_sum_loss_lstm[5] = [0.716590166091919, 0.6178787350654602, 0.5910767912864685, 0.5750118494033813, 0.5594329833984375, 0.5505140423774719, 0.5343846082687378, 0.5263456106185913, 0.5150219202041626, 0.5153102278709412, 0.5025115013122559]
val_reduced_sum_loss_lstm[5] = [0.9274576902389526, 0.9105604290962219, 0.941354513168335, 0.6822370886802673, 0.6067270040512085, 0.5722044706344604, 0.568244457244873, 0.5857676267623901, 0.6267564296722412, 0.589560866355896, 0.5699048638343811]
gate_output_accuracy_lstm[5] = [0.7967869639396667, 0.9079294800758362, 0.9126819372177124, 0.9218990802764893, 0.9278935194015503, 0.9318307042121887, 0.9337058067321777, 0.9354657530784607, 0.9373840093612671, 0.9409855008125305, 0.9384198784828186]
val_gate_output_accuracy_lstm[5] = [0.7575116157531738, 0.7579686641693115, 0.9088954925537109, 0.9060516357421875, 0.761218786239624, 0.9183411002159119, 0.8877020478248596, 0.9142445921897888, 0.8854845762252808, 0.91754549741745, 0.8237494826316833]
reduced_sum_mae_lstm[5] = [0.5981577038764954, 0.5516984462738037, 0.5390921235084534, 0.5313807725906372, 0.5232959985733032, 0.5164053440093994, 0.5084038972854614, 0.5014725923538208, 0.4961753785610199, 0.4948897361755371, 0.48786765336990356]
val_reduced_sum_mae_lstm[5] = [0.7245822548866272, 0.7082358598709106, 0.7252569794654846, 0.5890674591064453, 0.5414757132530212, 0.5233216285705566, 0.515150785446167, 0.529689610004425, 0.5475677251815796, 0.5283381938934326, 0.5181390643119812]
# 74/74 [==============================] - 3s 42ms/step - loss: 2.6714 - gate_output_loss: 0.5754 - reduced_sum_loss: 0.5699 - gate_output_accuracy: 0.8237 - reduced_sum_mae: 0.5181
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== LSTM ===========
# loss                : 3.5152
# gate_output_loss    : 1.4211
# reduced_sum_loss     : 0.5608
# gate_output_accuracy: 0.6501
# reduced_sum_mae      : 0.5419
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-24_11:55:27/model_LSTM.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-24_11:55:27/model_LSTM.png

################# 7
# Epoch 00040: LearningRateScheduler reducing learning rate to 0.0004782969000000001.
# 261/261 [==============================] - 37s 141ms/step - loss: 1.4100 - gate_output_loss: 0.1129 - reduced_sum_loss: 0.4112 - gate_output_accuracy: 0.9591 - reduced_sum_mae: 0.4363 - val_loss: 1.7130 - val_gate_output_loss: 0.4041 - val_reduced_sum_loss: 0.4844 - val_gate_output_accuracy: 0.8970 - val_reduced_sum_mae: 0.4685
# [on_epoch_end] epoch: 39 , loss: 1.418114423751831 , val_loss : 1.7129905223846436
# Epoch 00040: val_loss did not improve from 1.55678
loss_lstm[6] = [64.27564239501953, 3.0874080657958984, 2.9167160987854004, 2.84141206741333, 2.786806583404541, 2.5284807682037354, 2.512136936187744, 2.5209314823150635, 2.510584831237793, 2.488389730453491, 2.273174524307251, 2.2610650062561035, 2.2635419368743896, 2.2595250606536865, 2.26912522315979, 2.047775983810425, 2.043750047683716, 2.070598840713501, 2.055995464324951, 2.0563745498657227, 1.8881529569625854, 1.8826614618301392, 1.8730034828186035, 1.8680261373519897, 1.9171372652053833, 1.7249094247817993, 1.711079716682434, 1.710343837738037, 1.706620693206787, 1.7090668678283691, 1.5579314231872559, 1.5718668699264526, 1.5703412294387817, 1.5575731992721558, 1.5848617553710938, 1.4169832468032837, 1.4246891736984253, 1.4410319328308105, 1.438670039176941, 1.418114423751831]
val_loss_lstm[6] = [3.6806280612945557, 3.46443772315979, 3.3271491527557373, 3.4264919757843018, 2.973256826400757, 2.626852035522461, 2.7143373489379883, 2.6672794818878174, 2.6038455963134766, 2.6791911125183105, 2.3831095695495605, 2.420353651046753, 2.506124258041382, 2.499082565307617, 2.5091207027435303, 2.278127431869507, 2.2261452674865723, 2.3114724159240723, 2.258286237716675, 2.279514789581299, 2.0994222164154053, 2.067387819290161, 2.0161707401275635, 2.3234009742736816, 2.106177806854248, 1.8941150903701782, 1.9044989347457886, 2.0289270877838135, 1.9542672634124756, 1.8779937028884888, 1.6649402379989624, 1.8231557607650757, 1.7120935916900635, 2.1327083110809326, 1.8078014850616455, 1.5962661504745483, 1.614326000213623, 1.6861494779586792, 1.5567758083343506, 1.7129905223846436]
gate_output_loss_lstm[6] = [0.7274336814880371, 0.317889004945755, 0.26061511039733887, 0.22729919850826263, 0.2083006650209427, 0.19431856274604797, 0.19020122289657593, 0.17463397979736328, 0.18019168078899384, 0.17428191006183624, 0.16542942821979523, 0.15880028903484344, 0.16517122089862823, 0.15497353672981262, 0.15947943925857544, 0.14683276414871216, 0.14471639692783356, 0.1528073102235794, 0.14374077320098877, 0.14762276411056519, 0.1411523073911667, 0.14126169681549072, 0.1375749558210373, 0.1401783674955368, 0.1423470377922058, 0.13947780430316925, 0.13355402648448944, 0.13619013130664825, 0.12744878232479095, 0.1333630383014679, 0.12284087389707565, 0.12949366867542267, 0.12847432494163513, 0.1235676035284996, 0.13290220499038696, 0.11422597616910934, 0.11739753186702728, 0.12224698066711426, 0.12576839327812195, 0.11572780460119247]
val_gate_output_loss_lstm[6] = [0.7956132292747498, 0.4365781545639038, 0.6297173500061035, 0.7348871231079102, 0.3819868862628937, 0.3129903972148895, 0.4105933606624603, 0.35381385684013367, 0.3321302831172943, 0.33263978362083435, 0.3189709186553955, 0.33059149980545044, 0.41712066531181335, 0.4019429385662079, 0.3900114595890045, 0.38114744424819946, 0.3169814944267273, 0.39592882990837097, 0.34345948696136475, 0.35983899235725403, 0.3639313876628876, 0.3263690769672394, 0.2946820855140686, 0.5605571269989014, 0.35521200299263, 0.31523507833480835, 0.3360041081905365, 0.4257264733314514, 0.3943946659564972, 0.2837443947792053, 0.26235872507095337, 0.35748159885406494, 0.2606617510318756, 0.6870543956756592, 0.3514227271080017, 0.3039252758026123, 0.3112313449382782, 0.3779197037220001, 0.25845715403556824, 0.40405166149139404]
reduced_sum_loss_lstm[6] = [0.7040979862213135, 0.6210800409317017, 0.5886960029602051, 0.5788785219192505, 0.5636022090911865, 0.5433610677719116, 0.5351232290267944, 0.5487353801727295, 0.5258944630622864, 0.520980179309845, 0.5124986171722412, 0.5147453546524048, 0.5100863575935364, 0.5002814531326294, 0.498590886592865, 0.48869839310646057, 0.4862726032733917, 0.48349785804748535, 0.48694202303886414, 0.4826100766658783, 0.4765297770500183, 0.4686985909938812, 0.4757064878940582, 0.4676532447338104, 0.4692775011062622, 0.45595046877861023, 0.4598388969898224, 0.4590236246585846, 0.4534941017627716, 0.45929595828056335, 0.4485621154308319, 0.44882211089134216, 0.4473230540752411, 0.4410303235054016, 0.44482430815696716, 0.43460455536842346, 0.4374362826347351, 0.42896759510040283, 0.41913214325904846, 0.4148502051830292]
val_reduced_sum_loss_lstm[6] = [0.927312433719635, 0.9033324122428894, 0.7121056914329529, 0.6452847123146057, 0.617266833782196, 0.5732041001319885, 0.5892642140388489, 0.6090958118438721, 0.575179934501648, 0.6599522829055786, 0.5431256294250488, 0.5635470747947693, 0.5603256821632385, 0.5434727072715759, 0.559800386428833, 0.5506449937820435, 0.5349457859992981, 0.5653084516525269, 0.5606878399848938, 0.5503862500190735, 0.5688808560371399, 0.5363837480545044, 0.5452460050582886, 0.5189614295959473, 0.5335233807563782, 0.5461667776107788, 0.5302929878234863, 0.5165082216262817, 0.5235694646835327, 0.5126970410346985, 0.520273745059967, 0.554627537727356, 0.5237738490104675, 0.5240048766136169, 0.5145081281661987, 0.5085239410400391, 0.49289482831954956, 0.49201536178588867, 0.47240936756134033, 0.48444873094558716]
gate_output_accuracy_lstm[6] = [0.7702193856239319, 0.9073013067245483, 0.9161107540130615, 0.9252128005027771, 0.9301474690437317, 0.9349574446678162, 0.9332789778709412, 0.9406306147575378, 0.939076840877533, 0.9398633241653442, 0.9432250261306763, 0.9441362023353577, 0.9426735639572144, 0.9452775716781616, 0.9446397423744202, 0.9474307894706726, 0.9490660429000854, 0.9465004205703735, 0.9493681788444519, 0.9480589628219604, 0.9499484300613403, 0.9492770433425903, 0.9512864351272583, 0.9499484300613403, 0.9487735033035278, 0.9503848552703857, 0.9531375169754028, 0.9522023797035217, 0.9554058313369751, 0.9518043398857117, 0.9563984870910645, 0.95332932472229, 0.9537609219551086, 0.9569068551063538, 0.9522311687469482, 0.9590600728988647, 0.9568061232566833, 0.9568876624107361, 0.955084502696991, 0.9572329521179199]
val_gate_output_accuracy_lstm[6] = [0.7575116157531738, 0.8063478469848633, 0.8379687070846558, 0.7991874814033508, 0.8807617425918579, 0.8957934975624084, 0.8766821622848511, 0.8943546414375305, 0.9001269340515137, 0.8887515664100647, 0.9012272357940674, 0.9036986827850342, 0.8752940893173218, 0.8934066891670227, 0.8789335489273071, 0.893829882144928, 0.9089462757110596, 0.8842657804489136, 0.8966906666755676, 0.8870757222175598, 0.8990097045898438, 0.896961510181427, 0.9097080230712891, 0.8364113569259644, 0.9009394645690918, 0.9083030223846436, 0.8943884968757629, 0.8806263208389282, 0.8930173516273499, 0.9106051921844482, 0.9228776693344116, 0.9025814533233643, 0.9211511015892029, 0.8196868300437927, 0.9139906764030457, 0.9050021171569824, 0.9140076041221619, 0.8964536786079407, 0.9258230924606323, 0.896961510181427]
reduced_sum_mae_lstm[6] = [0.5940095782279968, 0.5543386340141296, 0.5378364324569702, 0.5313416123390198, 0.5233004689216614, 0.5117635726928711, 0.5062586665153503, 0.508582353591919, 0.5003846883773804, 0.49613243341445923, 0.4915323853492737, 0.4902796745300293, 0.48777279257774353, 0.48386886715888977, 0.481201708316803, 0.4760552942752838, 0.4753150939941406, 0.47327274084091187, 0.47463804483413696, 0.47175079584121704, 0.4694962799549103, 0.464283287525177, 0.4680606424808502, 0.46435508131980896, 0.46377474069595337, 0.4567469656467438, 0.4590064287185669, 0.4585728645324707, 0.4554738402366638, 0.4588605463504791, 0.4530085325241089, 0.4522864818572998, 0.45172804594039917, 0.4494992792606354, 0.4511739909648895, 0.4456190764904022, 0.4474479854106903, 0.44282886385917664, 0.43949976563453674, 0.4375579357147217]
val_reduced_sum_mae_lstm[6] = [0.723397433757782, 0.7072929739952087, 0.6010704040527344, 0.5703604817390442, 0.5449138879776001, 0.5187538266181946, 0.5303460955619812, 0.5411445498466492, 0.5193098783493042, 0.5701257586479187, 0.4978935420513153, 0.5125344395637512, 0.5083698034286499, 0.5005568861961365, 0.5087351202964783, 0.506108283996582, 0.4911385774612427, 0.5132668018341064, 0.5125702619552612, 0.5021207332611084, 0.515134334564209, 0.49721816182136536, 0.500394344329834, 0.48271697759628296, 0.49095433950424194, 0.5016400218009949, 0.4933299422264099, 0.4813069701194763, 0.48532623052597046, 0.4806848168373108, 0.4864310026168823, 0.5039972066879272, 0.48691898584365845, 0.4887051582336426, 0.48225170373916626, 0.4757225513458252, 0.47148948907852173, 0.469516396522522, 0.45902419090270996, 0.4685150682926178]
# 74/74 [==============================] - 3s 44ms/step - loss: 1.7130 - gate_output_loss: 0.4041 - reduced_sum_loss: 0.4844 - gate_output_accuracy: 0.8970 - reduced_sum_mae: 0.4685
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== LSTM ===========
# loss                : 3.0675
# gate_output_loss    : 1.7529
# reduced_sum_loss     : 0.5130
# gate_output_accuracy: 0.7335
# reduced_sum_mae      : 0.5158
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-24_11:58:06/model_LSTM.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-24_11:58:06/model_LSTM.png


################# 8
# Epoch 40/40
# Epoch 00040: LearningRateScheduler reducing learning rate to 0.0004782969000000001.
# 261/261 [==============================] - 38s 143ms/step - loss: 1.4106 - gate_output_loss: 0.1134 - reduced_sum_loss: 0.4051 - gate_output_accuracy: 0.9605 - reduced_sum_mae: 0.4322 - val_loss: 1.7208 - val_gate_output_loss: 0.3954 - val_reduced_sum_loss: 0.4650 - val_gate_output_accuracy: 0.8970 - val_reduced_sum_mae: 0.4597
# [on_epoch_end] epoch: 39 , loss: 1.4076476097106934 , val_loss : 1.7208086252212524
# Epoch 00040: val_loss did not improve from 1.62112
loss_lstm[7] = [64.49317932128906, 3.0850491523742676, 2.9606595039367676, 2.8568713665008545, 2.824719190597534, 2.5204946994781494, 2.5304408073425293, 2.517108917236328, 2.509814739227295, 2.537083387374878, 2.302351236343384, 2.281219482421875, 2.2611184120178223, 2.268411636352539, 2.2680063247680664, 2.0934526920318604, 2.0466878414154053, 2.05468487739563, 2.0566940307617188, 2.0334372520446777, 1.8824859857559204, 1.870692491531372, 1.874988317489624, 1.8564460277557373, 1.8510104417800903, 1.7013521194458008, 1.6968541145324707, 1.6937555074691772, 1.7037320137023926, 1.70221745967865, 1.5467075109481812, 1.5625722408294678, 1.5953705310821533, 1.5285000801086426, 1.53827965259552, 1.4159728288650513, 1.4229315519332886, 1.4116079807281494, 1.4006999731063843, 1.4076476097106934]
val_loss_lstm[7] = [3.5904810428619385, 3.3801889419555664, 3.1263787746429443, 2.9064738750457764, 2.9831857681274414, 2.574814796447754, 2.6587483882904053, 2.6241259574890137, 2.6443347930908203, 2.57332444190979, 2.348628044128418, 2.5617969036102295, 2.457022190093994, 2.4493408203125, 2.5435755252838135, 2.142456293106079, 2.2307262420654297, 2.1955888271331787, 2.306248188018799, 2.2377045154571533, 2.0534279346466064, 2.21012544631958, 2.0701282024383545, 2.0543506145477295, 2.074317216873169, 1.8300296068191528, 2.1735329627990723, 1.8895162343978882, 1.884867548942566, 1.968830943107605, 1.7491998672485352, 1.7282919883728027, 1.7458616495132446, 1.7406914234161377, 1.761061191558838, 1.6211220026016235, 1.6320807933807373, 1.6443138122558594, 1.6364820003509521, 1.7208086252212524]
gate_output_loss_lstm[7] = [0.7029245495796204, 0.32038167119026184, 0.2691287100315094, 0.23580865561962128, 0.2216445356607437, 0.19579438865184784, 0.20195721089839935, 0.1888200044631958, 0.1791895478963852, 0.18480339646339417, 0.17400522530078888, 0.17041610181331635, 0.16210781037807465, 0.15898531675338745, 0.15935055911540985, 0.1538572460412979, 0.1506204456090927, 0.15127795934677124, 0.14888931810855865, 0.1424989253282547, 0.14413172006607056, 0.14090299606323242, 0.13885818421840668, 0.13576991856098175, 0.13474906980991364, 0.13120603561401367, 0.132470965385437, 0.13091813027858734, 0.1301032155752182, 0.1285550892353058, 0.12073975801467896, 0.131202831864357, 0.12842610478401184, 0.11536146700382233, 0.12007198482751846, 0.11950106173753738, 0.11933144927024841, 0.11678071320056915, 0.10991374403238297, 0.11346126347780228]
val_gate_output_loss_lstm[7] = [0.8271933794021606, 0.5674856305122375, 0.36053264141082764, 0.2858162224292755, 0.37227946519851685, 0.2568747103214264, 0.3572731614112854, 0.32019105553627014, 0.31914395093917847, 0.2416190207004547, 0.2644347548484802, 0.4307885766029358, 0.37914466857910156, 0.3481796085834503, 0.4443546235561371, 0.2379751205444336, 0.3111405670642853, 0.30168330669403076, 0.4079483449459076, 0.27277839183807373, 0.34051620960235596, 0.4421529769897461, 0.3481071889400482, 0.31525152921676636, 0.32258638739585876, 0.2871558666229248, 0.6130821108818054, 0.2767869830131531, 0.31891611218452454, 0.3842354714870453, 0.33711597323417664, 0.2571602463722229, 0.3300131559371948, 0.3175893723964691, 0.3284209072589874, 0.322122722864151, 0.32763639092445374, 0.33603957295417786, 0.35029885172843933, 0.3954329192638397]
reduced_sum_loss_lstm[7] = [0.7096929550170898, 0.6172717213630676, 0.5926406979560852, 0.5766276121139526, 0.5702108144760132, 0.5500891208648682, 0.5449492931365967, 0.5401660203933716, 0.5249942541122437, 0.5331544280052185, 0.512797474861145, 0.514372706413269, 0.501471757888794, 0.5026828646659851, 0.4965165853500366, 0.4929942488670349, 0.48338741064071655, 0.47986188530921936, 0.48353078961372375, 0.46871718764305115, 0.4535655081272125, 0.4543946087360382, 0.44817090034484863, 0.44052305817604065, 0.4354986846446991, 0.42638078331947327, 0.4334646761417389, 0.42416146397590637, 0.4290819764137268, 0.42557665705680847, 0.4149695336818695, 0.4159378707408905, 0.41592395305633545, 0.4058704078197479, 0.41020530462265015, 0.4081853926181793, 0.40768522024154663, 0.40247803926467896, 0.4046953320503235, 0.3999881446361542]
val_reduced_sum_loss_lstm[7] = [0.9321656823158264, 0.9076861143112183, 0.6324732303619385, 0.6249942779541016, 0.6450498104095459, 0.6031876802444458, 0.5739613175392151, 0.5525017976760864, 0.6037956476211548, 0.6056238412857056, 0.5615259408950806, 0.5726808309555054, 0.5585001111030579, 0.5548828840255737, 0.5561894774436951, 0.5482184886932373, 0.5577297806739807, 0.5641952157020569, 0.5338469743728638, 0.5630278587341309, 0.5176177024841309, 0.5544946789741516, 0.5136019587516785, 0.49603471159935, 0.48377084732055664, 0.48596304655075073, 0.47460034489631653, 0.5063398480415344, 0.4715832769870758, 0.485430508852005, 0.5123850703239441, 0.5552722215652466, 0.4779723882675171, 0.46866604685783386, 0.4706987738609314, 0.4640747904777527, 0.45940157771110535, 0.4660038948059082, 0.4608723521232605, 0.4650030732154846]
gate_output_accuracy_lstm[7] = [0.7885241508483887, 0.9063038229942322, 0.9140822291374207, 0.9205226898193359, 0.9242584705352783, 0.9324253797531128, 0.9292219281196594, 0.9345690011978149, 0.9378635883331299, 0.9355856776237488, 0.9390336871147156, 0.9399880170822144, 0.9436805844306946, 0.9441601634025574, 0.94613116979599, 0.9456132650375366, 0.9473012685775757, 0.9463133811950684, 0.9478719830513, 0.9499484300613403, 0.9488118886947632, 0.9497950077056885, 0.9516125321388245, 0.9527059197425842, 0.9522359371185303, 0.9535211324691772, 0.9532814025878906, 0.9534924030303955, 0.9540295004844666, 0.9557990431785583, 0.9574439525604248, 0.9527059197425842, 0.9543076157569885, 0.958978533744812, 0.9569787979125977, 0.9578419923782349, 0.9581632614135742, 0.9590408802032471, 0.9605371356010437, 0.9593238234519958]
val_gate_output_accuracy_lstm[7] = [0.7575116157531738, 0.75752854347229, 0.8848243951797485, 0.9143630862236023, 0.8814219236373901, 0.9024460315704346, 0.8795598745346069, 0.8974016308784485, 0.8969784379005432, 0.921405017375946, 0.9149217009544373, 0.8652560114860535, 0.8851968050003052, 0.8930173516273499, 0.8709267973899841, 0.9130257964134216, 0.9036648273468018, 0.9101481437683105, 0.8857384920120239, 0.9161574244499207, 0.9057807922363281, 0.8914600014686584, 0.8949809670448303, 0.9020736217498779, 0.9101650714874268, 0.9136013388633728, 0.8519678115844727, 0.9206432700157166, 0.9072535037994385, 0.903766393661499, 0.9097080230712891, 0.9266694784164429, 0.9109606146812439, 0.9122979044914246, 0.9161743521690369, 0.9056284427642822, 0.9121963381767273, 0.9093017578125, 0.8998730182647705, 0.8970292210578918]
reduced_sum_mae_lstm[7] = [0.5952683687210083, 0.5506434440612793, 0.5388151407241821, 0.5316528677940369, 0.5273144841194153, 0.5176526308059692, 0.5123386979103088, 0.5080572366714478, 0.4992518126964569, 0.5031300187110901, 0.49282944202423096, 0.49246248602867126, 0.48680561780929565, 0.4862361252307892, 0.48373520374298096, 0.4804845154285431, 0.4752851128578186, 0.473798930644989, 0.47478413581848145, 0.4682449400424957, 0.46122151613235474, 0.46189752221107483, 0.4570440351963043, 0.45384681224823, 0.4518130421638489, 0.44580933451652527, 0.4496678411960602, 0.44401922821998596, 0.446817010641098, 0.4447152316570282, 0.4392417371273041, 0.4399283230304718, 0.4396071434020996, 0.434501975774765, 0.4368121027946472, 0.4353208839893341, 0.435200035572052, 0.4320951998233795, 0.4327943027019501, 0.43069761991500854]
val_reduced_sum_mae_lstm[7] = [0.7277092933654785, 0.7087240815162659, 0.5572200417518616, 0.5513068437576294, 0.5633067488670349, 0.5363349318504333, 0.5185868144035339, 0.504946768283844, 0.536087155342102, 0.5377514362335205, 0.5119621753692627, 0.5196112990379333, 0.5123881697654724, 0.5073235034942627, 0.5078648328781128, 0.5051352977752686, 0.510599672794342, 0.5144076347351074, 0.4957791566848755, 0.5185892581939697, 0.49033859372138977, 0.5129154324531555, 0.48727336525917053, 0.47655239701271057, 0.47221994400024414, 0.46990150213241577, 0.46825161576271057, 0.48732998967170715, 0.4642043709754944, 0.47175779938697815, 0.49060606956481934, 0.5166340470314026, 0.4665621221065521, 0.4622739255428314, 0.4656580686569214, 0.4577183127403259, 0.4550844132900238, 0.461128294467926, 0.45584794878959656, 0.4596700072288513]
# 74/74 [==============================] - 3s 39ms/step - loss: 1.7208 - gate_output_loss: 0.3954 - reduced_sum_loss: 0.4650 - gate_output_accuracy: 0.8970 - reduced_sum_mae: 0.4597
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== LSTM ===========
# loss                : 2.9655
# gate_output_loss    : 1.6359
# reduced_sum_loss     : 0.4859
# gate_output_accuracy: 0.6845
# reduced_sum_mae      : 0.5014
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-24_12:03:26/model_LSTM.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-24_12:03:26/model_LSTM.png


################# 9
# Epoch 80/100
# Epoch 00080: LearningRateScheduler reducing learning rate to 0.0002058911320946491.
# 261/261 [==============================] - 26s 101ms/step - loss: 0.7027 - gate_output_loss: 0.0757 - reduced_sum_loss: 0.3460 - gate_output_accuracy: 0.9724 - reduced_sum_mae: 0.4016 - val_loss: 0.9871 - val_gate_output_loss: 0.3433 - val_reduced_sum_loss: 0.4458 - val_gate_output_accuracy: 0.9162 - val_reduced_sum_mae: 0.4518
# [on_epoch_end] epoch: 79 , loss: 0.7061343193054199 , val_loss : 0.9871425032615662
# Epoch 00080: val_loss did not improve from 0.97443
# Epoch 81/100
# Epoch 00081: LearningRateScheduler reducing learning rate to 0.00018530201888518417.
# 261/261 [==============================] - 27s 103ms/step - loss: 0.6694 - gate_output_loss: 0.0807 - reduced_sum_loss: 0.3494 - gate_output_accuracy: 0.9703 - reduced_sum_mae: 0.4035 - val_loss: 1.0947 - val_gate_output_loss: 0.4986 - val_reduced_sum_loss: 0.4267 - val_gate_output_accuracy: 0.8938 - val_reduced_sum_mae: 0.4408
# [on_epoch_end] epoch: 80 , loss: 0.6631035804748535 , val_loss : 1.094740390777588
# Epoch 00081: val_loss did not improve from 0.97443
loss_lstm[8] = [64.20481872558594, 3.136420726776123, 2.9588992595672607, 2.815227508544922, 2.8120319843292236, 2.5011260509490967, 2.5380687713623047, 2.516099214553833, 2.4872853755950928, 2.5145010948181152, 2.2680959701538086, 2.250460624694824, 2.252692461013794, 2.2513303756713867, 2.259260892868042, 2.047163248062134, 2.0394721031188965, 2.045297861099243, 2.057349920272827, 2.0501091480255127, 1.8626325130462646, 1.8634358644485474, 1.9214361906051636, 1.855847716331482, 1.8505643606185913, 1.6940977573394775, 1.6951302289962769, 1.6970802545547485, 1.685922622680664, 1.6926023960113525, 1.5537348985671997, 1.5507255792617798, 1.54792058467865, 1.5694406032562256, 1.5467201471328735, 1.4139976501464844, 1.4195513725280762, 1.4131009578704834, 1.413880467414856, 1.4256550073623657, 1.2957298755645752, 1.2956764698028564, 1.2823253870010376, 1.2986899614334106, 1.3081976175308228, 1.173703908920288, 1.1853671073913574, 1.1724958419799805, 1.1774582862854004, 1.1857285499572754, 1.0835058689117432, 1.0886104106903076, 1.0748485326766968, 1.083268642425537, 1.0806763172149658, 0.9990586638450623, 0.9954910278320312, 0.9960264563560486, 0.99410480260849, 0.9903602600097656, 0.9164506196975708, 0.9227493405342102, 0.9096604585647583, 0.9169550538063049, 0.9128280878067017, 0.8431507349014282, 0.8443079590797424, 0.8406936526298523, 0.8363988399505615, 0.8427777290344238, 0.7787611484527588, 0.7734326720237732, 0.7676551342010498, 0.7716246843338013, 0.7698238492012024, 0.7142432332038879, 0.716447651386261, 0.7134509086608887, 0.7164352536201477, 0.7061343193054199, 0.6631035804748535]
val_loss_lstm[8] = [3.6967697143554688, 3.4359078407287598, 2.9745404720306396, 3.191659688949585, 2.961954116821289, 2.7446136474609375, 3.72441029548645, 2.730003595352173, 2.649341106414795, 2.885923147201538, 2.529597520828247, 2.7731239795684814, 2.773244619369507, 2.7719662189483643, 2.7130510807037354, 2.352527618408203, 2.266435384750366, 2.2365880012512207, 2.798912286758423, 2.3654654026031494, 1.9951107501983643, 2.1117992401123047, 2.0657691955566406, 2.1303603649139404, 2.1884477138519287, 1.9602785110473633, 2.0310611724853516, 2.113039255142212, 2.004481792449951, 2.147813081741333, 1.8263452053070068, 1.8430349826812744, 2.103193521499634, 1.840168833732605, 1.7806310653686523, 1.7374801635742188, 2.1500346660614014, 1.674821376800537, 1.875639796257019, 1.7590138912200928, 1.745396375656128, 1.5339829921722412, 1.793931245803833, 1.537516713142395, 1.510382890701294, 1.451599359512329, 1.4592580795288086, 1.5772984027862549, 1.4393962621688843, 1.4741722345352173, 1.3609302043914795, 1.379533052444458, 1.552368402481079, 1.4315426349639893, 1.4519258737564087, 1.2927333116531372, 1.3044251203536987, 1.2738734483718872, 1.3188238143920898, 1.2520570755004883, 1.2243691682815552, 1.2846946716308594, 1.1788344383239746, 1.1834689378738403, 1.224609613418579, 1.4194211959838867, 1.1327059268951416, 1.113266944885254, 1.2051180601119995, 1.1089328527450562, 1.0671041011810303, 1.1495492458343506, 1.1266485452651978, 1.117612361907959, 1.079805612564087, 0.9744305610656738, 1.2022846937179565, 1.0750623941421509, 1.0473862886428833, 0.9871425032615662, 1.094740390777588]
gate_output_loss_lstm[8] = [0.7089212536811829, 0.3257783055305481, 0.2580743432044983, 0.23306293785572052, 0.2162395864725113, 0.1888517290353775, 0.19768962264060974, 0.1867101639509201, 0.17903773486614227, 0.18130874633789062, 0.17195864021778107, 0.16331423819065094, 0.16545362770557404, 0.15955492854118347, 0.15740197896957397, 0.14585424959659576, 0.14340931177139282, 0.14824983477592468, 0.1465800553560257, 0.14725884795188904, 0.1348697394132614, 0.14035600423812866, 0.14850571751594543, 0.13774718344211578, 0.13185705244541168, 0.12973006069660187, 0.1295444518327713, 0.13391165435314178, 0.12497436255216599, 0.1255568116903305, 0.12528303265571594, 0.12489612400531769, 0.12202005833387375, 0.1197517141699791, 0.11973530799150467, 0.1150631308555603, 0.1174653172492981, 0.11453932523727417, 0.1153603047132492, 0.11751165241003036, 0.10836437344551086, 0.11250844597816467, 0.10419291257858276, 0.11200036853551865, 0.10988903045654297, 0.09962789714336395, 0.10496363043785095, 0.09820495545864105, 0.10115080326795578, 0.10291298478841782, 0.09899459034204483, 0.09984748065471649, 0.09567312896251678, 0.09961238503456116, 0.09582248330116272, 0.09461957216262817, 0.09565751254558563, 0.09662715345621109, 0.09452544897794724, 0.09225761145353317, 0.09266887605190277, 0.09161434322595596, 0.0895916074514389, 0.09079770743846893, 0.08951357007026672, 0.08891918510198593, 0.08560391515493393, 0.08715515583753586, 0.08591163903474808, 0.08587270975112915, 0.08532530814409256, 0.08379875868558884, 0.08285237103700638, 0.08216521888971329, 0.08166319876909256, 0.08086217194795609, 0.08155160397291183, 0.07932515442371368, 0.08063755184412003, 0.07649868726730347, 0.07946193963289261]
val_gate_output_loss_lstm[8] = [0.7972076535224915, 0.46907275915145874, 0.292070209980011, 0.5793863534927368, 0.36415767669677734, 0.42750293016433716, 1.3841395378112793, 0.37787920236587524, 0.3729321360588074, 0.47227948904037476, 0.45573264360427856, 0.6681153178215027, 0.6585524678230286, 0.6655512452125549, 0.5993591547012329, 0.45127296447753906, 0.3427966833114624, 0.3411087393760681, 0.8552713394165039, 0.3738812506198883, 0.27325356006622314, 0.328011691570282, 0.3425065875053406, 0.40462255477905273, 0.4572296738624573, 0.3979558050632477, 0.4321556091308594, 0.5017525553703308, 0.4341864287853241, 0.5465348958969116, 0.4103539288043976, 0.39745187759399414, 0.6359818577766418, 0.3708776533603668, 0.3435482084751129, 0.4400869905948639, 0.8227872848510742, 0.34832456707954407, 0.5015477538108826, 0.422018826007843, 0.5546233654022217, 0.3363834321498871, 0.5887418389320374, 0.3380904197692871, 0.3158133924007416, 0.3766469657421112, 0.36098507046699524, 0.4740105867385864, 0.36414188146591187, 0.406056672334671, 0.37932997941970825, 0.37857115268707275, 0.550143837928772, 0.428905189037323, 0.4302002787590027, 0.4031681716442108, 0.37775906920433044, 0.356072336435318, 0.41075313091278076, 0.3335101306438446, 0.3973049521446228, 0.4419153928756714, 0.34521934390068054, 0.33722275495529175, 0.39102306962013245, 0.5962520241737366, 0.36922702193260193, 0.34045225381851196, 0.4463488757610321, 0.34908321499824524, 0.37284448742866516, 0.45187702775001526, 0.40451186895370483, 0.419941246509552, 0.38236966729164124, 0.34072014689445496, 0.5434084534645081, 0.397369384765625, 0.4148055613040924, 0.3433230519294739, 0.49858325719833374]
reduced_sum_loss_lstm[8] = [0.6978708505630493, 0.6237086057662964, 0.5803946852684021, 0.5463940501213074, 0.5355246067047119, 0.5175505876541138, 0.5065958499908447, 0.49846625328063965, 0.49032917618751526, 0.49034175276756287, 0.473770409822464, 0.4730902314186096, 0.4636145830154419, 0.45634880661964417, 0.4594738483428955, 0.4471811056137085, 0.44273778796195984, 0.4412998557090759, 0.43569427728652954, 0.4439016580581665, 0.43068796396255493, 0.424608439207077, 0.4230775535106659, 0.424003005027771, 0.42108169198036194, 0.41559258103370667, 0.4103618860244751, 0.4104226529598236, 0.40758612751960754, 0.416452020406723, 0.40302759408950806, 0.40126779675483704, 0.4036470055580139, 0.42870858311653137, 0.4025943875312805, 0.3930468261241913, 0.4007897973060608, 0.39147821068763733, 0.3900913596153259, 0.3895096778869629, 0.38806524872779846, 0.3853970766067505, 0.3867102563381195, 0.38379257917404175, 0.38443106412887573, 0.3767126500606537, 0.3824132978916168, 0.37643763422966003, 0.3769882023334503, 0.37721338868141174, 0.37538421154022217, 0.37896186113357544, 0.3701152205467224, 0.37195318937301636, 0.3716481029987335, 0.37190377712249756, 0.36734989285469055, 0.36769214272499084, 0.36489397287368774, 0.3667003810405731, 0.36294567584991455, 0.3805127441883087, 0.36067497730255127, 0.3601527512073517, 0.36158958077430725, 0.3590421974658966, 0.3617840111255646, 0.35665878653526306, 0.36027204990386963, 0.3570055365562439, 0.35544779896736145, 0.3549939692020416, 0.35316693782806396, 0.35503068566322327, 0.35318100452423096, 0.3501169681549072, 0.35197168588638306, 0.35213610529899597, 0.3507045805454254, 0.3494921028614044, 0.34838297963142395]
val_reduced_sum_loss_lstm[8] = [0.9297652840614319, 0.915888249874115, 0.6833370923995972, 0.5726701021194458, 0.5797142386436462, 0.5574674010276794, 0.5539792776107788, 0.5433701276779175, 0.5207262635231018, 0.706914484500885, 0.5472387075424194, 0.516472339630127, 0.49434322118759155, 0.5552932024002075, 0.498701810836792, 0.5464655160903931, 0.5032669901847839, 0.4916485846042633, 0.4867287278175354, 0.5500171184539795, 0.5176171064376831, 0.4859980344772339, 0.4856538772583008, 0.4826672673225403, 0.4747070074081421, 0.4859018921852112, 0.4805169999599457, 0.48407769203186035, 0.480418860912323, 0.4720730185508728, 0.47155994176864624, 0.466185063123703, 0.481301486492157, 0.5587365031242371, 0.4798462986946106, 0.4724232256412506, 0.4924662411212921, 0.45740795135498047, 0.46555188298225403, 0.46956750750541687, 0.4688287675380707, 0.4605797231197357, 0.45612743496894836, 0.4486823081970215, 0.47084400057792664, 0.452126681804657, 0.45503556728363037, 0.4631330072879791, 0.45674118399620056, 0.44278207421302795, 0.45318692922592163, 0.4523519277572632, 0.45426011085510254, 0.45641201734542847, 0.5362926721572876, 0.43697643280029297, 0.4396894574165344, 0.45261290669441223, 0.44634246826171875, 0.4513642489910126, 0.4346473217010498, 0.4392153322696686, 0.43218764662742615, 0.4411637485027313, 0.44421154260635376, 0.44928812980651855, 0.4423539936542511, 0.44390201568603516, 0.4343070983886719, 0.4363020658493042, 0.44201526045799255, 0.43641144037246704, 0.4297628402709961, 0.43831315636634827, 0.4429331421852112, 0.4306114614009857, 0.42865434288978577, 0.44124656915664673, 0.43649914860725403, 0.44577738642692566, 0.42672595381736755]
gate_output_accuracy_lstm[8] = [0.7776333689689636, 0.902289867401123, 0.914461076259613, 0.919434130191803, 0.9252751469612122, 0.9359645247459412, 0.9304112195968628, 0.9364920258522034, 0.939278244972229, 0.9379978179931641, 0.938937783241272, 0.9434599876403809, 0.9413403868675232, 0.94478839635849, 0.9450137615203857, 0.948226809501648, 0.9499148726463318, 0.948682427406311, 0.9478575587272644, 0.9476657509803772, 0.9524421691894531, 0.9504567980766296, 0.9472533464431763, 0.9518523216247559, 0.952854573726654, 0.9549790024757385, 0.9543651938438416, 0.9532814025878906, 0.955621600151062, 0.955084502696991, 0.9557703137397766, 0.9558038711547852, 0.9573096632957458, 0.9570507407188416, 0.9571514129638672, 0.9587147831916809, 0.9581441283226013, 0.9601582288742065, 0.9592662453651428, 0.9577940106391907, 0.9620333313941956, 0.9604843258857727, 0.9630308151245117, 0.9601678252220154, 0.9608775973320007, 0.9643447995185852, 0.9620189666748047, 0.9648435711860657, 0.9635487198829651, 0.963284969329834, 0.9644023776054382, 0.9641194343566895, 0.9651169180870056, 0.9646421074867249, 0.9654046297073364, 0.9652079939842224, 0.9652655720710754, 0.9653710722923279, 0.9650401473045349, 0.9668960571289062, 0.9666178822517395, 0.9667186141014099, 0.9671022891998291, 0.9669440388679504, 0.9673900008201599, 0.9678455591201782, 0.9691067934036255, 0.9686368703842163, 0.9686224460601807, 0.9678551554679871, 0.9684066772460938, 0.9695048332214355, 0.9700132012367249, 0.9695479869842529, 0.9707277417182922, 0.97087162733078, 0.9703344702720642, 0.9708476066589355, 0.9697158336639404, 0.9720081686973572, 0.9706557989120483]
val_gate_output_accuracy_lstm[8] = [0.7575116157531738, 0.8038933277130127, 0.909945011138916, 0.7825814485549927, 0.8889716267585754, 0.878121018409729, 0.5952264070510864, 0.8922386765480042, 0.8878374695777893, 0.8534574508666992, 0.8631231188774109, 0.8212780356407166, 0.8138298988342285, 0.8302327394485474, 0.8230893015861511, 0.876191258430481, 0.8858739137649536, 0.9014134407043457, 0.786136269569397, 0.8949471116065979, 0.9110113978385925, 0.9103682041168213, 0.8984342217445374, 0.885823130607605, 0.8929157853126526, 0.8900042176246643, 0.8922217488288879, 0.8642742037773132, 0.8891070485115051, 0.8779517412185669, 0.9007871150970459, 0.8936944603919983, 0.8400676846504211, 0.8996360301971436, 0.9083030223846436, 0.8796783685684204, 0.7688869833946228, 0.906254768371582, 0.8748878836631775, 0.8982649445533752, 0.8806263208389282, 0.9045450687408447, 0.8759711980819702, 0.9132120013237, 0.9146508574485779, 0.9069826602935791, 0.9118070006370544, 0.8867372274398804, 0.9045112133026123, 0.9034786224365234, 0.9112145304679871, 0.9101989269256592, 0.8773592710494995, 0.8924248814582825, 0.8991789817810059, 0.903444766998291, 0.9033770561218262, 0.9079306125640869, 0.89784175157547, 0.9121963381767273, 0.9102835655212402, 0.888531506061554, 0.910892903804779, 0.9173423647880554, 0.9040710926055908, 0.8767329454421997, 0.9063055515289307, 0.9193229079246521, 0.8979771733283997, 0.9127549529075623, 0.9134828448295593, 0.8920524716377258, 0.9026491641998291, 0.9065256118774414, 0.9070334434509277, 0.9156834483146667, 0.8472111821174622, 0.9009902477264404, 0.8979941010475159, 0.9161912798881531, 0.8938129544258118]
reduced_sum_mae_lstm[8] = [0.5934018492698669, 0.5549287796020508, 0.5365515351295471, 0.5225512981414795, 0.5160393714904785, 0.5060792565345764, 0.4977857768535614, 0.49171626567840576, 0.48819753527641296, 0.48717960715293884, 0.47867053747177124, 0.477449506521225, 0.47247663140296936, 0.46855196356773376, 0.4681874215602875, 0.4632701277732849, 0.4593016505241394, 0.45942577719688416, 0.45572158694267273, 0.4586985111236572, 0.45345166325569153, 0.44897401332855225, 0.4480486214160919, 0.4483575224876404, 0.446438193321228, 0.4437761604785919, 0.4407275915145874, 0.4404900074005127, 0.43911775946617126, 0.44382864236831665, 0.43619975447654724, 0.43498295545578003, 0.4362419843673706, 0.44771602749824524, 0.4359516501426697, 0.4306865632534027, 0.4339320957660675, 0.42943134903907776, 0.428151398897171, 0.4275031089782715, 0.42631620168685913, 0.42609575390815735, 0.42628973722457886, 0.4247888922691345, 0.4249264895915985, 0.4203333258628845, 0.42384153604507446, 0.42034757137298584, 0.4206418991088867, 0.4205392003059387, 0.4191310703754425, 0.42044001817703247, 0.41630297899246216, 0.4175558090209961, 0.4172312319278717, 0.41737279295921326, 0.41441282629966736, 0.41458407044410706, 0.4132862389087677, 0.4140792191028595, 0.4120652973651886, 0.4206256866455078, 0.4104994535446167, 0.4101351499557495, 0.4110860228538513, 0.4097161591053009, 0.4110644459724426, 0.40822234749794006, 0.4096425771713257, 0.4078296720981598, 0.4067436754703522, 0.40735316276550293, 0.40607258677482605, 0.40678876638412476, 0.4057379961013794, 0.4040595293045044, 0.40498650074005127, 0.40513402223587036, 0.4045654833316803, 0.4036520719528198, 0.4029061496257782]
val_reduced_sum_mae_lstm[8] = [0.7263387441635132, 0.71361243724823, 0.589554488658905, 0.5262559056282043, 0.5339504480361938, 0.5166895985603333, 0.5178568959236145, 0.5116339325904846, 0.4948877692222595, 0.5958738923072815, 0.5126263499259949, 0.49591341614723206, 0.4804774522781372, 0.517267644405365, 0.485324501991272, 0.5129359364509583, 0.4853304922580719, 0.4795609414577484, 0.47823065519332886, 0.5166994333267212, 0.4931785464286804, 0.47566351294517517, 0.4744267761707306, 0.4750952124595642, 0.46993935108184814, 0.47441527247428894, 0.47258734703063965, 0.47279542684555054, 0.47249412536621094, 0.46792954206466675, 0.47080522775650024, 0.4648764729499817, 0.4756486713886261, 0.5192555785179138, 0.47119253873825073, 0.4694126546382904, 0.4826950132846832, 0.4574058949947357, 0.4630751311779022, 0.4650017321109772, 0.4660474956035614, 0.45940646529197693, 0.45921802520751953, 0.4532996714115143, 0.4668208658695221, 0.4542683959007263, 0.45702865719795227, 0.4633883833885193, 0.45830294489860535, 0.4497089982032776, 0.4561331272125244, 0.45530766248703003, 0.4590218663215637, 0.45818030834198, 0.507180392742157, 0.44443777203559875, 0.4485011696815491, 0.45774126052856445, 0.4514429569244385, 0.455136239528656, 0.44453904032707214, 0.448668897151947, 0.44382375478744507, 0.4476607143878937, 0.45006686449050903, 0.4548737108707428, 0.45011115074157715, 0.4516478180885315, 0.44608765840530396, 0.4465404748916626, 0.44668853282928467, 0.4460296034812927, 0.44138965010643005, 0.4483707845211029, 0.449614018201828, 0.4440072178840637, 0.4419381022453308, 0.44892218708992004, 0.44550734758377075, 0.4517586827278137, 0.4408143162727356]
# 74/74 [==============================] - 3s 36ms/step - loss: 1.0947 - gate_output_loss: 0.4986 - reduced_sum_loss: 0.4267 - gate_output_accuracy: 0.8938 - reduced_sum_mae: 0.4408
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== LSTM ===========
# loss                : 2.0914
# gate_output_loss    : 1.4881
# reduced_sum_loss     : 0.4623
# gate_output_accuracy: 0.7331
# reduced_sum_mae      : 0.4905
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-24_11:50:47/model_LSTM.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-24_11:50:47/model_LSTM.png

################# 10
# Epoch 40/40
# Epoch 00040: LearningRateScheduler reducing learning rate to 0.0004782969000000001.
# 261/261 [==============================] - 14s 52ms/step - loss: 1.4138 - gate_output_loss: 0.1102 - reduced_sum_loss: 0.4159 - gate_output_accuracy: 0.9610 - reduced_sum_mae: 0.4375 - val_loss: 1.5560 - val_gate_output_loss: 0.2590 - val_reduced_sum_loss: 0.4624 - val_gate_output_accuracy: 0.9210 - val_reduced_sum_mae: 0.4553
# [on_epoch_end] epoch: 39 , loss: 1.4096769094467163 , val_loss : 1.556016206741333
# Epoch 00040: val_loss improved from 1.55941 to 1.55602, saving model to __untrack/models/RAL/2022-02-24_12:26:37/model_LSTM_Best.h5
loss_lstm[9] = [64.30107879638672, 3.0631964206695557, 2.959916114807129, 2.800846576690674, 2.8596787452697754, 2.4985063076019287, 2.4929375648498535, 2.5282297134399414, 2.514457941055298, 2.4918580055236816, 2.274660348892212, 2.2632992267608643, 2.28090238571167, 2.288731336593628, 2.2453107833862305, 2.0632925033569336, 2.08017897605896, 2.0690877437591553, 2.049762725830078, 2.0562474727630615, 1.881403923034668, 1.8875428438186646, 1.868891954421997, 1.8907822370529175, 1.8642160892486572, 1.7247700691223145, 1.7116563320159912, 1.7120344638824463, 1.7532628774642944, 1.7332265377044678, 1.5518484115600586, 1.5541179180145264, 1.5629671812057495, 1.569568395614624, 1.540116548538208, 1.4404457807540894, 1.4148173332214355, 1.421906590461731, 1.4348063468933105, 1.4096769094467163]
val_loss_lstm[9] = [3.6910364627838135, 3.35067081451416, 2.8805577754974365, 2.9594039916992188, 2.8206372261047363, 2.6297590732574463, 2.678940534591675, 2.602057456970215, 2.751218318939209, 2.5988869667053223, 2.380650043487549, 2.4855635166168213, 2.42484450340271, 2.779268741607666, 2.578834056854248, 2.361738681793213, 2.343888759613037, 2.6487531661987305, 2.411376714706421, 3.2046194076538086, 2.159668207168579, 2.2857043743133545, 2.077115058898926, 2.0711379051208496, 2.2379825115203857, 2.007791757583618, 1.9932971000671387, 2.1746349334716797, 1.7598273754119873, 1.835030198097229, 1.733845591545105, 1.911698818206787, 1.8013701438903809, 1.916262149810791, 1.7733371257781982, 1.5802942514419556, 1.6696205139160156, 1.5594109296798706, 1.575487494468689, 1.556016206741333]
gate_output_loss_lstm[9] = [0.70542311668396, 0.3132712244987488, 0.25357934832572937, 0.22135306894779205, 0.21873918175697327, 0.18921524286270142, 0.18078595399856567, 0.1856648176908493, 0.17207388579845428, 0.16355212032794952, 0.16273775696754456, 0.155991792678833, 0.15950307250022888, 0.1623801738023758, 0.14940300583839417, 0.1483134925365448, 0.15004587173461914, 0.1465717852115631, 0.14104275405406952, 0.14349505305290222, 0.13853628933429718, 0.1430533230304718, 0.13307593762874603, 0.14418764412403107, 0.13159112632274628, 0.13059867918491364, 0.13247299194335938, 0.12941154837608337, 0.13231125473976135, 0.13545207679271698, 0.11946111917495728, 0.12321370095014572, 0.12316711246967316, 0.12466529756784439, 0.11267856508493423, 0.12374337017536163, 0.11273205280303955, 0.11452196538448334, 0.11775173991918564, 0.11019933968782425]
val_gate_output_loss_lstm[9] = [0.8365932703018188, 0.4924136698246002, 0.2501886188983917, 0.2503903806209564, 0.2520167827606201, 0.31432583928108215, 0.34395772218704224, 0.2598027288913727, 0.42037421464920044, 0.2717367708683014, 0.2762371599674225, 0.28929680585861206, 0.3344566822052002, 0.6683585047721863, 0.4431920647621155, 0.43814921379089355, 0.39078009128570557, 0.7055402398109436, 0.4763471186161041, 1.2488136291503906, 0.42752596735954285, 0.5115578174591064, 0.3458978235721588, 0.3193303942680359, 0.47510313987731934, 0.44072186946868896, 0.38119253516197205, 0.5335028171539307, 0.18760769069194794, 0.24488691985607147, 0.33345142006874084, 0.41687700152397156, 0.36190298199653625, 0.4741390645503998, 0.32792147994041443, 0.27850642800331116, 0.32661888003349304, 0.219771146774292, 0.26214125752449036, 0.25902822613716125]
reduced_sum_loss_lstm[9] = [0.7026710510253906, 0.6189752817153931, 0.5868601202964783, 0.5739842653274536, 0.5738670825958252, 0.5536481142044067, 0.5447484850883484, 0.5331939458847046, 0.529168963432312, 0.5196087956428528, 0.5212593674659729, 0.5115134119987488, 0.5067676901817322, 0.5026631951332092, 0.4987504780292511, 0.4941132366657257, 0.4960549473762512, 0.4995880424976349, 0.48054981231689453, 0.4821373224258423, 0.47537848353385925, 0.47660019993782043, 0.4751660227775574, 0.48081204295158386, 0.46503010392189026, 0.45717450976371765, 0.44351571798324585, 0.4370277225971222, 0.4364580810070038, 0.4316534101963043, 0.4273758828639984, 0.42649194598197937, 0.42351093888282776, 0.42044708132743835, 0.4214980900287628, 0.4142124056816101, 0.40933066606521606, 0.40986010432243347, 0.42502573132514954, 0.41008153557777405]
val_reduced_sum_loss_lstm[9] = [0.9267875552177429, 0.9202719926834106, 0.6516352891921997, 0.616971492767334, 0.632144033908844, 0.587660014629364, 0.6767509579658508, 0.5690294504165649, 0.5731292963027954, 0.5685033798217773, 0.6044034957885742, 0.5990756154060364, 0.5467225313186646, 0.5510114431381226, 0.5942776203155518, 0.5655761957168579, 0.5555139183998108, 0.585946261882782, 0.5422802567481995, 0.5612019300460815, 0.5327924489974976, 0.5301249623298645, 0.5224406123161316, 0.5366820693016052, 0.5105380415916443, 0.518483579158783, 0.5095340609550476, 0.5262274742126465, 0.4989846348762512, 0.5022963285446167, 0.4886449873447418, 0.521151602268219, 0.49915608763694763, 0.4968857765197754, 0.4802533686161041, 0.47709041833877563, 0.4686131179332733, 0.5337920784950256, 0.47116148471832275, 0.4623771905899048]
gate_output_accuracy_lstm[9] = [0.7908883690834045, 0.9077137112617493, 0.9178467988967896, 0.9273852109909058, 0.9246948957443237, 0.9346984624862671, 0.9393309950828552, 0.9383143782615662, 0.940678596496582, 0.9427022933959961, 0.9444910883903503, 0.9460448622703552, 0.9431771039962769, 0.9430332183837891, 0.9473492503166199, 0.9472485184669495, 0.9458961486816406, 0.9485145807266235, 0.9511233568191528, 0.9488406777381897, 0.9514350891113281, 0.9496367573738098, 0.9523653984069824, 0.949569582939148, 0.9530608057975769, 0.953190267086029, 0.9522503018379211, 0.9547919631004333, 0.9532190561294556, 0.9517084360122681, 0.95695960521698, 0.95668625831604, 0.9560196399688721, 0.9551036953926086, 0.9606042504310608, 0.9562402367591858, 0.9590600728988647, 0.958978533744812, 0.9577988386154175, 0.9608775973320007]
val_gate_output_accuracy_lstm[9] = [0.7575116157531738, 0.7881168127059937, 0.9183411002159119, 0.9161235690116882, 0.9167837500572205, 0.892543375492096, 0.8828269243240356, 0.9147185683250427, 0.8709437251091003, 0.8985865712165833, 0.9015657901763916, 0.9079983234405518, 0.8964198231697083, 0.8057553768157959, 0.8574862480163574, 0.8683030009269714, 0.8771392107009888, 0.8054337501525879, 0.8737367987632751, 0.689987301826477, 0.8516461849212646, 0.8328057527542114, 0.9005162715911865, 0.9082183837890625, 0.8631569743156433, 0.8688108325004578, 0.8948624730110168, 0.8468218445777893, 0.9307998418807983, 0.9186627268791199, 0.8992297649383545, 0.8809987306594849, 0.8694540858268738, 0.8687092661857605, 0.8981803059577942, 0.9060008525848389, 0.8996021747589111, 0.9236901998519897, 0.9209479689598083, 0.9210156798362732]
reduced_sum_mae_lstm[9] = [0.5928505659103394, 0.551896333694458, 0.5371570587158203, 0.5303910374641418, 0.5286179780960083, 0.5185242891311646, 0.5111802816390991, 0.5054906010627747, 0.501361608505249, 0.49670255184173584, 0.4958289563655853, 0.49141424894332886, 0.4883301258087158, 0.4866425693035126, 0.4847080409526825, 0.48074546456336975, 0.4824155569076538, 0.48058098554611206, 0.473010390996933, 0.474284291267395, 0.4701949656009674, 0.470455139875412, 0.4693312644958496, 0.4699060022830963, 0.46386030316352844, 0.46038198471069336, 0.4544300138950348, 0.4501763880252838, 0.44930994510650635, 0.4477962851524353, 0.44474488496780396, 0.4441790282726288, 0.4421323835849762, 0.44038841128349304, 0.4407370090484619, 0.43660789728164673, 0.4341232180595398, 0.4347892999649048, 0.44278162717819214, 0.43436098098754883]
val_reduced_sum_mae_lstm[9] = [0.7234119772911072, 0.7150328159332275, 0.5707195997238159, 0.5519358515739441, 0.5535474419593811, 0.531980037689209, 0.5823400616645813, 0.5154335498809814, 0.5167784094810486, 0.5153911113739014, 0.5361151099205017, 0.5338979959487915, 0.5018761157989502, 0.5045220851898193, 0.5308572053909302, 0.510218620300293, 0.5069970488548279, 0.5227683782577515, 0.503142774105072, 0.5094743967056274, 0.4946679174900055, 0.49122706055641174, 0.4853106737136841, 0.49323758482933044, 0.47880980372428894, 0.4883984327316284, 0.4821408689022064, 0.4930381774902344, 0.47420600056648254, 0.47996869683265686, 0.46943381428718567, 0.49106091260910034, 0.4768903851509094, 0.4783448278903961, 0.4668355882167816, 0.4631444811820984, 0.4590426981449127, 0.49993643164634705, 0.4610596299171448, 0.4553087651729584]
# 74/74 [==============================] - 1s 16ms/step - loss: 1.5560 - gate_output_loss: 0.2590 - reduced_sum_loss: 0.4624 - gate_output_accuracy: 0.9210 - reduced_sum_mae: 0.4553
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== LSTM ===========
# loss                : 2.3449
# gate_output_loss    : 1.0443
# reduced_sum_loss     : 0.4801
# gate_output_accuracy: 0.7593
# reduced_sum_mae      : 0.4962
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-24_12:26:37/model_LSTM.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-24_12:26:37/model_LSTM.png

#############################################################################################
#############################################################################################
#############################################################################################

###############################
###############################
###############################
############ GMoE #############
###############################
###############################
###############################

####################################
# Epoch 00036: LearningRateScheduler reducing learning rate to 0.0004782969000000001.
# 261/261 [==============================] - 4s 14ms/step - loss: 1.4707 - gate_output_loss: 0.1979 - reduced_sum_loss: 0.3341 - gate_output_accuracy: 0.9305 - reduced_sum_mae: 0.3946 - val_loss: 1.4976 - val_gate_output_loss: 0.2641 - val_reduced_sum_loss: 0.4311 - val_gate_output_accuracy: 0.8978 - val_reduced_sum_mae: 0.4440
# [on_epoch_end] epoch: 35 , loss: 1.448967695236206 , val_loss : 1.4975836277008057
# Epoch 00036: val_loss did not improve from 1.48885
loss[0] = [37.9107666015625, 4.753046035766602, 4.279513835906982, 3.921905994415283, 3.6737561225891113, 3.2726354598999023, 3.101224660873413, 3.165086030960083, 3.072077751159668, 2.989074945449829, 2.690164566040039, 2.6775505542755127, 2.609830856323242, 2.592973232269287, 2.5730793476104736, 2.383106231689453, 2.40327525138855, 2.3625142574310303, 2.2904305458068848, 2.231693983078003, 2.000183582305908, 2.049673557281494, 2.0325591564178467, 1.9864342212677002, 1.9828470945358276, 1.9077765941619873, 1.8049464225769043, 1.7654393911361694, 1.8653708696365356, 1.7244867086410522, 1.6002938747406006, 1.6392852067947388, 1.6532390117645264, 1.5800763368606567, 1.6822071075439453, 1.448967695236206]
val_loss[0] = [4.901750087738037, 4.2658867835998535, 3.7170121669769287, 4.152709484100342, 3.3786537647247314, 3.107400417327881, 3.316215753555298, 3.0736429691314697, 3.267298460006714, 2.745783567428589, 3.0600390434265137, 2.7607614994049072, 2.7348902225494385, 2.664921998977661, 2.7203731536865234, 2.383401870727539, 2.37160587310791, 2.3210744857788086, 2.143646478652954, 2.1560399532318115, 1.9957075119018555, 1.863887071609497, 2.102869987487793, 2.1775665283203125, 1.9062060117721558, 2.0396347045898438, 1.8168021440505981, 1.7455897331237793, 1.7019708156585693, 1.69781494140625, 1.4888513088226318, 1.5873719453811646, 1.5985379219055176, 1.6523637771606445, 1.7200241088867188, 1.4975836277008057]
gate_output_loss[0] = [0.6088994145393372, 0.38608190417289734, 0.34760794043540955, 0.32792094349861145, 0.31898829340934753, 0.3010057806968689, 0.28595370054244995, 0.2950306832790375, 0.29066377878189087, 0.2824115455150604, 0.27555641531944275, 0.2700931429862976, 0.26194503903388977, 0.2672507166862488, 0.26873308420181274, 0.25714626908302307, 0.2588902413845062, 0.2586926519870758, 0.24771659076213837, 0.24930062890052795, 0.2360444813966751, 0.2434501349925995, 0.2413104623556137, 0.23051275312900543, 0.23731370270252228, 0.22902514040470123, 0.22430433332920074, 0.21952903270721436, 0.233220174908638, 0.21554842591285706, 0.2157982736825943, 0.21332597732543945, 0.21836254000663757, 0.21563708782196045, 0.21036870777606964, 0.20383769273757935]
val_gate_output_loss[0] = [0.34172767400741577, 0.23293209075927734, 0.22563986480236053, 0.3623764216899872, 0.24477119743824005, 0.24291057884693146, 0.36214515566825867, 0.2227388471364975, 0.26089224219322205, 0.2750757932662964, 0.2886215150356293, 0.24823254346847534, 0.20884181559085846, 0.2689466178417206, 0.22505497932434082, 0.23324470221996307, 0.21417219936847687, 0.20134729146957397, 0.220413476228714, 0.2373569905757904, 0.18992730975151062, 0.21428881585597992, 0.2222478836774826, 0.27113667130470276, 0.20738016068935394, 0.23299992084503174, 0.20908689498901367, 0.21030683815479279, 0.21385183930397034, 0.2148210108280182, 0.1894931197166443, 0.22127710282802582, 0.22800993919372559, 0.22066810727119446, 0.23934371769428253, 0.2640525996685028]
reduced_sum_loss[0] = [0.5738832950592041, 0.4790264666080475, 0.4505937099456787, 0.4335782527923584, 0.41859620809555054, 0.4100753664970398, 0.39713165163993835, 0.3974323868751526, 0.3943891227245331, 0.38979145884513855, 0.38547804951667786, 0.3792097270488739, 0.3787890076637268, 0.3761743903160095, 0.37781423330307007, 0.3696358799934387, 0.3693053126335144, 0.3701743483543396, 0.3650285601615906, 0.3635418713092804, 0.356082946062088, 0.358304888010025, 0.35550370812416077, 0.35210880637168884, 0.3529757857322693, 0.34882521629333496, 0.3444395065307617, 0.3447006046772003, 0.3534832000732422, 0.34051963686943054, 0.3390977680683136, 0.3387230336666107, 0.339761346578598, 0.33472567796707153, 0.3435017764568329, 0.33280718326568604]
val_reduced_sum_loss[0] = [0.8201944231987, 0.6256130337715149, 0.5485917925834656, 0.5638042688369751, 0.5696852803230286, 0.4747107923030853, 0.5539207458496094, 0.5306277275085449, 0.5128024220466614, 0.4917122423648834, 0.48517194390296936, 0.4997413456439972, 0.5268401503562927, 0.45529571175575256, 0.5186190605163574, 0.4286534786224365, 0.44636034965515137, 0.4744848310947418, 0.4510338008403778, 0.43135684728622437, 0.4296914041042328, 0.44169601798057556, 0.45933178067207336, 0.4342164993286133, 0.4292396605014801, 0.4251214861869812, 0.42430588603019714, 0.41161075234413147, 0.42663711309432983, 0.4345836341381073, 0.41801437735557556, 0.4280075132846832, 0.4503994286060333, 0.41732487082481384, 0.42871201038360596, 0.43110111355781555]
gate_output_accuracy[0] = [0.8059753179550171, 0.877942681312561, 0.8862342834472656, 0.889442503452301, 0.8900707364082336, 0.8961755037307739, 0.8993310332298279, 0.8965447545051575, 0.8993549942970276, 0.9047596454620361, 0.90309077501297, 0.9083898663520813, 0.9095887541770935, 0.9060783982276917, 0.9053590893745422, 0.9114494919776917, 0.909277081489563, 0.9105910658836365, 0.9139096140861511, 0.9147632122039795, 0.9203212857246399, 0.9147584438323975, 0.9190600514411926, 0.9187003970146179, 0.917621374130249, 0.9200671315193176, 0.9230211973190308, 0.9238317012786865, 0.9183263182640076, 0.9245702028274536, 0.9247812032699585, 0.9254429936408997, 0.924675703048706, 0.9239515662193298, 0.9272893071174622, 0.9281045198440552]
val_gate_output_accuracy[0] = [0.8738722205162048, 0.9245535135269165, 0.9242826700210571, 0.8717054724693298, 0.9155649542808533, 0.9132458567619324, 0.8799492120742798, 0.9235209226608276, 0.9106221199035645, 0.9071180820465088, 0.8969276547431946, 0.9161574244499207, 0.9266186952590942, 0.9102835655212402, 0.925958514213562, 0.9227761030197144, 0.9249259233474731, 0.9266356229782104, 0.9209141135215759, 0.9126703143119812, 0.9339991807937622, 0.9251290559768677, 0.925552248954773, 0.918273389339447, 0.9228607416152954, 0.9194075465202332, 0.9330343008041382, 0.9297503232955933, 0.9246889352798462, 0.9247058629989624, 0.9331697225570679, 0.9249428510665894, 0.9173254370689392, 0.9227930307388306, 0.9151756167411804, 0.8978078961372375]
reduced_sum_mae[0] = [0.5283156633377075, 0.4776441156864166, 0.46061500906944275, 0.45082801580429077, 0.4430493116378784, 0.4372040629386902, 0.43128588795661926, 0.43075433373451233, 0.42882031202316284, 0.4260249733924866, 0.4225521981716156, 0.42071664333343506, 0.4189595878124237, 0.4171735644340515, 0.4181159436702728, 0.41377636790275574, 0.4144098460674286, 0.41320621967315674, 0.4110809564590454, 0.41012269258499146, 0.4056966006755829, 0.4081006348133087, 0.40541574358940125, 0.4047287106513977, 0.4049008786678314, 0.4015616476535797, 0.39984384179115295, 0.4004947245121002, 0.40234267711639404, 0.3984030783176422, 0.39592352509498596, 0.3962704837322235, 0.39654451608657837, 0.39397841691970825, 0.39707210659980774, 0.39376479387283325]
val_reduced_sum_mae[0] = [0.6783374547958374, 0.5718190670013428, 0.521709680557251, 0.5306531190872192, 0.524161696434021, 0.47235116362571716, 0.5200274586677551, 0.4870093762874603, 0.4888310730457306, 0.47902488708496094, 0.4755575656890869, 0.4792773127555847, 0.4958743453025818, 0.45736274123191833, 0.48718327283859253, 0.44191211462020874, 0.4559638798236847, 0.4719361960887909, 0.45721349120140076, 0.44371145963668823, 0.4430523216724396, 0.45238497853279114, 0.4569839835166931, 0.4415694773197174, 0.44085443019866943, 0.4404957890510559, 0.436480849981308, 0.4298967719078064, 0.43962234258651733, 0.44290393590927124, 0.4357745945453644, 0.4433930516242981, 0.4598926603794098, 0.43378886580467224, 0.4413708746433258, 0.4439582824707031]
# 74/74 [==============================] - 1s 8ms/step - loss: 1.4976 - gate_output_loss: 0.2641 - reduced_sum_loss: 0.4311 - gate_output_accuracy: 0.8978 - reduced_sum_mae: 0.4440
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== MoE ===========
# loss                : 2.2587
# gate_output_loss    : 1.0074
# reduced_sum_loss     : 0.5199
# gate_output_accuracy: 0.7848
# reduced_sum_mae      : 0.5132
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-23_15:52:41/model_MoE.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-23_15:52:41/model_MoE.png

####################################
#################################### 2
####################################
# Epoch 00056: LearningRateScheduler reducing learning rate to 0.0003138105960900001.
# 261/261 [==============================] - 4s 14ms/step - loss: 0.9912 - gate_output_loss: 0.1796 - reduced_sum_loss: 0.2934 - gate_output_accuracy: 0.9376 - reduced_sum_mae: 0.3695 - val_loss: 1.0885 - val_gate_output_loss: 0.2127 - val_reduced_sum_loss: 0.4279 - val_gate_output_accuracy: 0.9231 - val_reduced_sum_mae: 0.4313
# [on_epoch_end] epoch: 55 , loss: 0.9521195888519287 , val_loss : 1.0885437726974487
# Epoch 00056: val_loss did not improve from 1.03689
loss[1] = [37.87171173095703, 4.872687816619873, 4.3042826652526855, 3.955307722091675, 3.682392120361328, 3.3792521953582764, 3.2282867431640625, 3.2155637741088867, 3.0374319553375244, 2.999239683151245, 2.697350263595581, 2.6984848976135254, 2.6017065048217773, 2.657193899154663, 2.6326165199279785, 2.3273117542266846, 2.4477782249450684, 2.334506034851074, 2.2922470569610596, 2.20548677444458, 2.163587808609009, 2.111250638961792, 2.0296454429626465, 2.002392292022705, 1.9830877780914307, 1.888697624206543, 1.7934443950653076, 1.7706425189971924, 1.7662115097045898, 1.8159605264663696, 1.617814540863037, 1.644203782081604, 1.6790056228637695, 1.580911636352539, 1.629339337348938, 1.46542227268219, 1.4486452341079712, 1.4205536842346191, 1.414481520652771, 1.4121202230453491, 1.2819565534591675, 1.2844852209091187, 1.3312585353851318, 1.268758773803711, 1.2421369552612305, 1.138350248336792, 1.2207543849945068, 1.1573731899261475, 1.126973271369934, 1.1731507778167725, 1.0489197969436646, 1.0763304233551025, 1.0321177244186401, 1.0571106672286987, 1.0153923034667969, 0.9521195888519287]
val_loss[1] = [4.90349006652832, 4.218684196472168, 4.045893669128418, 3.862774133682251, 3.4658141136169434, 3.2023561000823975, 3.235452175140381, 2.9411087036132812, 2.7264018058776855, 2.8517098426818848, 2.6161105632781982, 2.4432222843170166, 2.7634871006011963, 2.4730119705200195, 2.4757044315338135, 2.241941452026367, 2.1882121562957764, 2.3331480026245117, 2.1632771492004395, 2.2238659858703613, 1.9631315469741821, 1.9688210487365723, 1.81622314453125, 1.8565682172775269, 2.0584752559661865, 1.8372879028320312, 1.8100372552871704, 1.6643983125686646, 1.685956597328186, 1.838553547859192, 1.6813479661941528, 1.6333873271942139, 1.872188925743103, 1.5234700441360474, 1.649162769317627, 1.4380162954330444, 1.3657896518707275, 1.372009038925171, 1.3775954246520996, 1.510764718055725, 1.2512186765670776, 1.3824654817581177, 1.2811923027038574, 1.2706787586212158, 1.1706929206848145, 1.0949344635009766, 1.2263444662094116, 1.199090838432312, 1.3413562774658203, 1.1255221366882324, 1.0368949174880981, 1.1252468824386597, 1.0522555112838745, 1.1016486883163452, 1.1517982482910156, 1.0885437726974487]
gate_output_loss[1] = [0.609398603439331, 0.39393219351768494, 0.3461550176143646, 0.3256683051586151, 0.32116806507110596, 0.3032901883125305, 0.2957605719566345, 0.3006857633590698, 0.2890086770057678, 0.290703147649765, 0.2770260274410248, 0.28165292739868164, 0.27400273084640503, 0.2728486955165863, 0.26962077617645264, 0.25960996747016907, 0.26797735691070557, 0.25436314940452576, 0.2511868476867676, 0.24388821423053741, 0.25198134779930115, 0.24049369990825653, 0.22966530919075012, 0.23893652856349945, 0.23299597203731537, 0.23184475302696228, 0.2292383313179016, 0.22365957498550415, 0.22767792642116547, 0.2234717309474945, 0.213721364736557, 0.21174712479114532, 0.21922537684440613, 0.21305085718631744, 0.22012276947498322, 0.21364080905914307, 0.202885702252388, 0.21013948321342468, 0.1978829801082611, 0.2048400342464447, 0.19914932548999786, 0.19248855113983154, 0.20140212774276733, 0.1929589956998825, 0.19017250835895538, 0.186534121632576, 0.19270209968090057, 0.18472221493721008, 0.18277662992477417, 0.1873936504125595, 0.18096210062503815, 0.18167223036289215, 0.17901787161827087, 0.17617648839950562, 0.17630083858966827, 0.17281997203826904]
val_gate_output_loss[1] = [0.32941558957099915, 0.2496318519115448, 0.28418388962745667, 0.24522440135478973, 0.2706869840621948, 0.2901855707168579, 0.2573016285896301, 0.21261166036128998, 0.23940908908843994, 0.24502988159656525, 0.1961948126554489, 0.22101840376853943, 0.23784266412258148, 0.22167320549488068, 0.2172682136297226, 0.25650903582572937, 0.2073526829481125, 0.2565633952617645, 0.22075419127941132, 0.21492034196853638, 0.22734320163726807, 0.21731281280517578, 0.23876647651195526, 0.2021675705909729, 0.19667808711528778, 0.19896721839904785, 0.2200959026813507, 0.21119458973407745, 0.2215084433555603, 0.22949081659317017, 0.24817363917827606, 0.2088087499141693, 0.18834884464740753, 0.22060225903987885, 0.21152237057685852, 0.17724746465682983, 0.21951211988925934, 0.23695576190948486, 0.2226967215538025, 0.2172706425189972, 0.22619663178920746, 0.21841010451316833, 0.20063231885433197, 0.22782036662101746, 0.20045192539691925, 0.18985246121883392, 0.2035428285598755, 0.23981939256191254, 0.22471612691879272, 0.23248291015625, 0.21479511260986328, 0.2164972871541977, 0.21755938231945038, 0.270009309053421, 0.2230861335992813, 0.21269164979457855]
reduced_sum_loss[1] = [0.5752573013305664, 0.4857693910598755, 0.4582536816596985, 0.43525460362434387, 0.4184418320655823, 0.40990927815437317, 0.4017549455165863, 0.39538079500198364, 0.3894466459751129, 0.38721132278442383, 0.38139185309410095, 0.37572166323661804, 0.37711411714553833, 0.3751188814640045, 0.37372490763664246, 0.3615587055683136, 0.36688852310180664, 0.3577384054660797, 0.36014029383659363, 0.35547375679016113, 0.3527977168560028, 0.35541945695877075, 0.35047414898872375, 0.3465588092803955, 0.3444727063179016, 0.34316450357437134, 0.33837541937828064, 0.3434520959854126, 0.3385085165500641, 0.3366982042789459, 0.33135634660720825, 0.3379468023777008, 0.3366072475910187, 0.3288688063621521, 0.3328624665737152, 0.3282654881477356, 0.32502231001853943, 0.32425472140312195, 0.32238805294036865, 0.3208675682544708, 0.31759485602378845, 0.31650128960609436, 0.3170391619205475, 0.3167833685874939, 0.31350332498550415, 0.31247633695602417, 0.31319329142570496, 0.3073989450931549, 0.30931344628334045, 0.30763089656829834, 0.30232688784599304, 0.3048703670501709, 0.3030170202255249, 0.30247893929481506, 0.3006603717803955, 0.2962237000465393]
val_reduced_sum_loss[1] = [0.7975266575813293, 0.6045630574226379, 0.5408929586410522, 0.51857590675354, 0.5186155438423157, 0.48151886463165283, 0.47437432408332825, 0.4870208203792572, 0.483989417552948, 0.4736129343509674, 0.4552338719367981, 0.45233219861984253, 0.46037736535072327, 0.4325089752674103, 0.4505174160003662, 0.4635082483291626, 0.44213810563087463, 0.4322039783000946, 0.43365713953971863, 0.45720481872558594, 0.4375346004962921, 0.4327881932258606, 0.4294925332069397, 0.4325217604637146, 0.4277437627315521, 0.4315551221370697, 0.4252732992172241, 0.45562148094177246, 0.4178336262702942, 0.4151480495929718, 0.41987353563308716, 0.4333217740058899, 0.4329974353313446, 0.43802186846733093, 0.45571044087409973, 0.41101616621017456, 0.42271706461906433, 0.4238604009151459, 0.418878436088562, 0.4344520568847656, 0.4162544906139374, 0.40985435247421265, 0.4265102744102478, 0.4131971001625061, 0.4139617085456848, 0.42882901430130005, 0.4164719879627228, 0.4089209735393524, 0.4292924106121063, 0.4028770923614502, 0.4041326940059662, 0.3955877721309662, 0.4025736153125763, 0.41719457507133484, 0.43020176887512207, 0.4279364049434662]
gate_output_accuracy[1] = [0.8055724501609802, 0.8745474219322205, 0.8846133351325989, 0.8898309469223022, 0.891399085521698, 0.8959405422210693, 0.8975278735160828, 0.8959740996360779, 0.9011293649673462, 0.9020261168479919, 0.9041314125061035, 0.9018343091011047, 0.906059205532074, 0.9075602293014526, 0.9065771698951721, 0.9126483798027039, 0.9052535891532898, 0.9116173386573792, 0.9111042022705078, 0.9152044057846069, 0.9112192988395691, 0.915065348148346, 0.9217120409011841, 0.9175446629524231, 0.9180002212524414, 0.9185709357261658, 0.9208056330680847, 0.9225176572799683, 0.9217983484268188, 0.9222059845924377, 0.9261191487312317, 0.9265939593315125, 0.923937201499939, 0.9251025319099426, 0.9239899516105652, 0.9252751469612122, 0.9282196164131165, 0.9264788627624512, 0.9307661056518555, 0.9285697340965271, 0.9302241802215576, 0.9317156076431274, 0.9294472932815552, 0.9320561289787292, 0.9325452446937561, 0.934765636920929, 0.9333077669143677, 0.9345162510871887, 0.9372065663337708, 0.9331446886062622, 0.9365159869194031, 0.9352787733078003, 0.9371394515037537, 0.9380026459693909, 0.9365496039390564, 0.9389617443084717]
val_gate_output_accuracy[1] = [0.8804570436477661, 0.910808265209198, 0.9077444076538086, 0.9163267016410828, 0.9088954925537109, 0.8973000645637512, 0.9102327823638916, 0.9263647794723511, 0.9178840517997742, 0.9100973606109619, 0.9301396608352661, 0.9115361571311951, 0.9136690497398376, 0.9222175478935242, 0.9263817071914673, 0.9109098315238953, 0.9322048425674438, 0.9130088686943054, 0.9274312257766724, 0.929648756980896, 0.9180194735527039, 0.9279052019119263, 0.913939893245697, 0.9327126741409302, 0.9328650236129761, 0.9303766489028931, 0.9242995977401733, 0.9270080327987671, 0.9216081500053406, 0.9242826700210571, 0.9118408560752869, 0.9252983331680298, 0.9311045408248901, 0.9236732721328735, 0.9255014657974243, 0.9418705105781555, 0.9304105043411255, 0.9147016406059265, 0.9243334531784058, 0.9185442328453064, 0.9223191142082214, 0.9276512861251831, 0.9274650812149048, 0.9179348349571228, 0.9278882741928101, 0.9304105043411255, 0.9288362264633179, 0.9169699549674988, 0.9195260405540466, 0.9195091128349304, 0.9262293577194214, 0.9229623079299927, 0.9229623079299927, 0.9030046463012695, 0.9211341738700867, 0.9231146574020386]
reduced_sum_mae[1] = [0.5294817090034485, 0.47944480180740356, 0.46362850069999695, 0.45130592584609985, 0.4416995048522949, 0.4363667368888855, 0.43231815099716187, 0.42931032180786133, 0.4260399043560028, 0.423737108707428, 0.41968533396720886, 0.41904181241989136, 0.418381005525589, 0.4164136052131653, 0.4162057042121887, 0.4105598032474518, 0.41307827830314636, 0.4078441560268402, 0.4089057147502899, 0.40673407912254333, 0.4042556583881378, 0.4054415822029114, 0.40334218740463257, 0.4016312062740326, 0.3998025059700012, 0.3984405994415283, 0.39734983444213867, 0.3989067077636719, 0.3971189856529236, 0.3953016996383667, 0.3927946984767914, 0.39434003829956055, 0.3945232033729553, 0.3916129171848297, 0.3927640914916992, 0.3904663622379303, 0.3887833058834076, 0.3880901634693146, 0.3869225084781647, 0.38586023449897766, 0.38420161604881287, 0.38230273127555847, 0.382834255695343, 0.3820563852787018, 0.381137490272522, 0.38089412450790405, 0.38052859902381897, 0.3782323896884918, 0.37919068336486816, 0.3776123821735382, 0.37429386377334595, 0.3755173683166504, 0.37527522444725037, 0.37534070014953613, 0.3743637204170227, 0.3702365458011627]
val_reduced_sum_mae[1] = [0.6658807396888733, 0.5626370310783386, 0.5158288478851318, 0.49969595670700073, 0.49623924493789673, 0.47778403759002686, 0.4720882177352905, 0.47685006260871887, 0.4771125018596649, 0.46661028265953064, 0.460630863904953, 0.4558519721031189, 0.46101054549217224, 0.45040127635002136, 0.4578368365764618, 0.46469083428382874, 0.45663005113601685, 0.4440273642539978, 0.4460039436817169, 0.4602198600769043, 0.4506300389766693, 0.44787466526031494, 0.4431115984916687, 0.44663968682289124, 0.43909791111946106, 0.4427194893360138, 0.4375423192977905, 0.45317721366882324, 0.43268659710884094, 0.4279061257839203, 0.43486350774765015, 0.44156119227409363, 0.439729779958725, 0.44207626581192017, 0.4474818706512451, 0.42372024059295654, 0.4326205551624298, 0.4352418780326843, 0.4286830425262451, 0.43585705757141113, 0.42510583996772766, 0.4311071038246155, 0.43199726939201355, 0.4258117973804474, 0.42832469940185547, 0.43046677112579346, 0.42596635222435, 0.4230470061302185, 0.43313154578208923, 0.4165274202823639, 0.4154456853866577, 0.4168562889099121, 0.41713374853134155, 0.4258311688899994, 0.437130331993103, 0.43129244446754456]
# 74/74 [==============================] - 1s 8ms/step - loss: 1.0885 - gate_output_loss: 0.2127 - reduced_sum_loss: 0.4279 - gate_output_accuracy: 0.9231 - reduced_sum_mae: 0.4313
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== MoE ===========
# loss                : 1.9825
# gate_output_loss    : 1.1002
# reduced_sum_loss     : 0.4602
# gate_output_accuracy: 0.8023
# reduced_sum_mae      : 0.4810
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-23_16:09:21/model_MoE.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-23_16:09:21/model_MoE.png

####################################
#################################### 3
####################################

# Epoch 00038: LearningRateScheduler reducing learning rate to 0.0004782969000000001.
# 261/261 [==============================] - 4s 14ms/step - loss: 1.4393 - gate_output_loss: 0.2025 - reduced_sum_loss: 0.3204 - gate_output_accuracy: 0.9276 - reduced_sum_mae: 0.3857 - val_loss: 1.6132 - val_gate_output_loss: 0.2077 - val_reduced_sum_loss: 0.4033 - val_gate_output_accuracy: 0.9224 - val_reduced_sum_mae: 0.4280
# [on_epoch_end] epoch: 37 , loss: 1.4479705095291138 , val_loss : 1.6132344007492065
# Epoch 00038: val_loss did not improve from 1.45957
loss[2] = [38.011417388916016, 4.816633224487305, 4.230391025543213, 3.972240924835205, 3.7248144149780273, 3.3176822662353516, 3.2695531845092773, 3.212568521499634, 3.0678277015686035, 3.0517866611480713, 2.7022202014923096, 2.6957895755767822, 2.6465437412261963, 2.63037371635437, 2.674138307571411, 2.4502668380737305, 2.319896697998047, 2.33882999420166, 2.3621115684509277, 2.2681896686553955, 2.087221622467041, 2.112107992172241, 2.1092031002044678, 1.993797779083252, 2.008193016052246, 1.9060758352279663, 1.8423818349838257, 1.7866735458374023, 1.8236061334609985, 1.801813006401062, 1.6331887245178223, 1.659873127937317, 1.6037719249725342, 1.6176990270614624, 1.5709649324417114, 1.548445224761963, 1.4869484901428223, 1.4479705095291138]
val_loss[2] = [5.072115421295166, 4.506909370422363, 3.607830286026001, 4.089181900024414, 3.4355661869049072, 3.0920441150665283, 3.387073040008545, 3.269848585128784, 2.7997329235076904, 2.813023805618286, 2.59498929977417, 2.4677069187164307, 2.52473783493042, 2.5121140480041504, 2.4980993270874023, 2.3294806480407715, 2.4261395931243896, 2.274763584136963, 2.3236634731292725, 2.445486545562744, 2.1378986835479736, 2.0340464115142822, 2.040062427520752, 2.0400304794311523, 2.041623830795288, 1.7865393161773682, 1.8101558685302734, 1.8286504745483398, 1.7708073854446411, 1.7202074527740479, 1.5892993211746216, 1.6476539373397827, 1.4595661163330078, 1.4856775999069214, 1.679437518119812, 1.718468427658081, 1.4834654331207275, 1.6132344007492065]
gate_output_loss[2] = [0.6061899065971375, 0.38449662923812866, 0.3431500494480133, 0.33242708444595337, 0.32096317410469055, 0.3115159869194031, 0.3073860704898834, 0.30093345046043396, 0.28960075974464417, 0.2940171957015991, 0.28007015585899353, 0.2720547616481781, 0.27502167224884033, 0.2698465883731842, 0.2778068780899048, 0.26531898975372314, 0.2548551857471466, 0.2556588649749756, 0.2502520978450775, 0.24992302060127258, 0.23926500976085663, 0.24178586900234222, 0.2362235188484192, 0.23419861495494843, 0.23513776063919067, 0.22634842991828918, 0.22848965227603912, 0.22016869485378265, 0.22108082473278046, 0.2278844267129898, 0.21649637818336487, 0.219828799366951, 0.2070809304714203, 0.21784073114395142, 0.20681393146514893, 0.21235860884189606, 0.20547102391719818, 0.20131328701972961]
val_gate_output_loss[2] = [0.33698391914367676, 0.2510632574558258, 0.2398560792207718, 0.2829183042049408, 0.24537798762321472, 0.2097320556640625, 0.27059686183929443, 0.27290764451026917, 0.22342945635318756, 0.21239793300628662, 0.2419193685054779, 0.22681911289691925, 0.22892995178699493, 0.21403133869171143, 0.2176712602376938, 0.243948295712471, 0.2503370940685272, 0.29239529371261597, 0.23194620013237, 0.21898698806762695, 0.1953805387020111, 0.22376248240470886, 0.27117565274238586, 0.22185558080673218, 0.22663618624210358, 0.20448274910449982, 0.22404251992702484, 0.23343876004219055, 0.22559167444705963, 0.19745241105556488, 0.2288578599691391, 0.20975087583065033, 0.21985779702663422, 0.20988455414772034, 0.21379169821739197, 0.21740929782390594, 0.19077041745185852, 0.207682266831398]
reduced_sum_loss[2] = [0.5783485770225525, 0.4840082824230194, 0.4472179412841797, 0.4298681616783142, 0.41308119893074036, 0.4009804129600525, 0.3968966007232666, 0.3937240540981293, 0.3843501806259155, 0.3861764073371887, 0.3733372688293457, 0.372469961643219, 0.37037187814712524, 0.3674163222312927, 0.3694703280925751, 0.36121276021003723, 0.3566738963127136, 0.35664236545562744, 0.355279803276062, 0.35558950901031494, 0.3464408814907074, 0.34701433777809143, 0.34536680579185486, 0.3431621193885803, 0.34443777799606323, 0.3359764814376831, 0.33754798769950867, 0.3364759385585785, 0.3337542414665222, 0.33366650342941284, 0.3302541673183441, 0.32884150743484497, 0.32834121584892273, 0.3245537579059601, 0.32255008816719055, 0.3262096047401428, 0.3228028416633606, 0.32145577669143677]
val_reduced_sum_loss[2] = [0.7996866703033447, 0.5979005098342896, 0.5009783506393433, 0.4881119132041931, 0.47979021072387695, 0.47164973616600037, 0.45840418338775635, 0.4484763443470001, 0.4618990421295166, 0.4374538064002991, 0.4441024363040924, 0.45286324620246887, 0.44212135672569275, 0.429999977350235, 0.4684044122695923, 0.43979212641716003, 0.4377768933773041, 0.4441404640674591, 0.42256054282188416, 0.42698633670806885, 0.41199633479118347, 0.4181124269962311, 0.4487338364124298, 0.41700196266174316, 0.4186739921569824, 0.4066128134727478, 0.4068385660648346, 0.40386709570884705, 0.41573604941368103, 0.4093465805053711, 0.4156050980091095, 0.3930872976779938, 0.39528489112854004, 0.40253397822380066, 0.404653936624527, 0.3903304934501648, 0.402633935213089, 0.4032737612724304]
gate_output_accuracy[2] = [0.8053662776947021, 0.8762210607528687, 0.8879846334457397, 0.8890876173973083, 0.8909435272216797, 0.8954417705535889, 0.8957391381263733, 0.8946361541748047, 0.9008944034576416, 0.8991152048110962, 0.9051048755645752, 0.9061455726623535, 0.9048123955726624, 0.909085214138031, 0.9073876142501831, 0.9082508087158203, 0.9136602282524109, 0.9108883738517761, 0.9128977060317993, 0.9132094383239746, 0.9176597595214844, 0.9166238903999329, 0.9182208180427551, 0.9202398061752319, 0.9197506308555603, 0.921649694442749, 0.9201198816299438, 0.9267905354499817, 0.9244455099105835, 0.9205898642539978, 0.9253518581390381, 0.923270583152771, 0.9288958311080933, 0.9232034683227539, 0.9266467094421387, 0.9255916476249695, 0.928051769733429, 0.9292219281196594]
val_gate_output_accuracy[2] = [0.8863309621810913, 0.9168514609336853, 0.9151756167411804, 0.8962336182594299, 0.9146677851676941, 0.9251967668533325, 0.8991789817810059, 0.9020228385925293, 0.9259077310562134, 0.9271265268325806, 0.9128226637840271, 0.9217604994773865, 0.9182395339012146, 0.9267710447311401, 0.9208633303642273, 0.9129411578178406, 0.9097418785095215, 0.8973000645637512, 0.922522246837616, 0.9252136945724487, 0.9304105043411255, 0.9292932748794556, 0.8941176533699036, 0.9169530272483826, 0.9163267016410828, 0.9252136945724487, 0.9208633303642273, 0.913296639919281, 0.9222514033317566, 0.9244858026504517, 0.9183072447776794, 0.9310368299484253, 0.9242826700210571, 0.9249597787857056, 0.9198645949363708, 0.920998752117157, 0.9344223737716675, 0.9223529696464539]
reduced_sum_mae[2] = [0.5296410322189331, 0.4781467318534851, 0.4590555727481842, 0.44950202107429504, 0.44094979763031006, 0.4333209693431854, 0.43101051449775696, 0.42817026376724243, 0.42411041259765625, 0.42289358377456665, 0.4177585244178772, 0.4155600666999817, 0.41468217968940735, 0.41219329833984375, 0.41338247060775757, 0.4092509150505066, 0.40644052624702454, 0.40608274936676025, 0.40575626492500305, 0.4059622883796692, 0.40110740065574646, 0.40046289563179016, 0.39972373843193054, 0.398625910282135, 0.3996529281139374, 0.39444640278816223, 0.3957940936088562, 0.39495548605918884, 0.3932721018791199, 0.3935491442680359, 0.3916548490524292, 0.3897506594657898, 0.38968729972839355, 0.3884966969490051, 0.38732054829597473, 0.38786017894744873, 0.3858281672000885, 0.3853500485420227]
val_reduced_sum_mae[2] = [0.6670109033584595, 0.5564783215522766, 0.48772260546684265, 0.4817316234111786, 0.4786852300167084, 0.4745793640613556, 0.46449992060661316, 0.45380908250808716, 0.4624825716018677, 0.4504352807998657, 0.4495150148868561, 0.4585355818271637, 0.45120808482170105, 0.44656145572662354, 0.4656534790992737, 0.4479800760746002, 0.44631820917129517, 0.453255295753479, 0.4373367428779602, 0.43864521384239197, 0.4326285123825073, 0.4384286403656006, 0.45374834537506104, 0.43528974056243896, 0.43512800335884094, 0.4281873404979706, 0.42746803164482117, 0.42738887667655945, 0.43736252188682556, 0.4309014678001404, 0.43662527203559875, 0.42070260643959045, 0.4230547547340393, 0.42808908224105835, 0.43106573820114136, 0.4211615025997162, 0.42638227343559265, 0.4279983937740326]
# 74/74 [==============================] - 0s 6ms/step - loss: 1.6132 - gate_output_loss: 0.2077 - reduced_sum_loss: 0.4033 - gate_output_accuracy: 0.9224 - reduced_sum_mae: 0.4280
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== MoE ===========
# loss                : 2.4907
# gate_output_loss    : 1.0775
# reduced_sum_loss     : 0.4413
# gate_output_accuracy: 0.7891
# reduced_sum_mae      : 0.4753
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-23_16:17:48/model_MoE.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-23_16:17:48/model_MoE.png

####################################
#################################### 4
####################################

# Epoch 00071: LearningRateScheduler reducing learning rate to 0.0002287679245496101.
# 261/261 [==============================] - 4s 14ms/step - loss: 0.7388 - gate_output_loss: 0.1546 - reduced_sum_loss: 0.2864 - gate_output_accuracy: 0.9444 - reduced_sum_mae: 0.3653 - val_loss: 0.8211 - val_gate_output_loss: 0.2636 - val_reduced_sum_loss: 0.3785 - val_gate_output_accuracy: 0.9048 - val_reduced_sum_mae: 0.4102
# [on_epoch_end] epoch: 70 , loss: 0.7341939806938171 , val_loss : 0.8211320042610168
# Epoch 00071: val_loss did not improve from 0.79453
loss[3] = [37.9295539855957, 4.7545647621154785, 4.296685218811035, 4.0116095542907715, 3.6611733436584473, 3.3694968223571777, 3.2348272800445557, 3.15518856048584, 3.0821115970611572, 3.029048204421997, 2.813781261444092, 2.748837947845459, 2.6998465061187744, 2.6031594276428223, 2.510617971420288, 2.299847364425659, 2.300374746322632, 2.31105899810791, 2.3077640533447266, 2.259460926055908, 2.0702881813049316, 2.0003645420074463, 2.015331983566284, 2.059113025665283, 1.951835036277771, 1.8795078992843628, 1.820329189300537, 1.8455281257629395, 1.815367341041565, 1.7599453926086426, 1.6259607076644897, 1.6745216846466064, 1.659548044204712, 1.6063686609268188, 1.6279042959213257, 1.447888731956482, 1.3673841953277588, 1.4737613201141357, 1.4395971298217773, 1.385061502456665, 1.3298752307891846, 1.3051286935806274, 1.240186333656311, 1.2504934072494507, 1.2645717859268188, 1.159888505935669, 1.1765990257263184, 1.1207239627838135, 1.1685014963150024, 1.1329926252365112, 1.0890581607818604, 1.0726561546325684, 1.0320175886154175, 1.0539554357528687, 1.0448824167251587, 0.933776319026947, 1.0274362564086914, 0.9824188351631165, 0.9897392392158508, 0.9564331769943237, 0.8609113693237305, 0.8422123193740845, 0.8832710385322571, 0.8809629082679749, 0.9087657928466797, 0.8231132626533508, 0.7794440388679504, 0.8397527933120728, 0.7996919751167297, 0.7945436835289001, 0.7341939806938171]
val_loss[3] = [4.928283214569092, 4.507894039154053, 3.990041732788086, 3.8605692386627197, 3.463351249694824, 2.9778735637664795, 3.237074851989746, 3.1289076805114746, 2.751832962036133, 2.9136834144592285, 2.6911604404449463, 2.6403915882110596, 2.7709226608276367, 2.5368142127990723, 2.418480157852173, 2.371722459793091, 2.7474169731140137, 2.1244800090789795, 2.212613105773926, 2.0237374305725098, 1.9456013441085815, 1.9781237840652466, 2.0086348056793213, 1.870376467704773, 1.9634994268417358, 1.7359756231307983, 1.8344544172286987, 1.7954174280166626, 1.829785943031311, 1.8880720138549805, 1.5862630605697632, 1.6092208623886108, 1.5953141450881958, 1.5673633813858032, 1.6026684045791626, 1.4958711862564087, 1.3901177644729614, 1.4702545404434204, 1.4501456022262573, 1.459293246269226, 1.4361709356307983, 1.3386884927749634, 1.2566211223602295, 1.2245051860809326, 1.2428454160690308, 1.2217873334884644, 1.2782557010650635, 1.1261205673217773, 1.3435815572738647, 1.1208531856536865, 1.197034478187561, 1.1844693422317505, 1.0868582725524902, 1.1365619897842407, 1.0067964792251587, 1.0445983409881592, 1.0387146472930908, 1.1130297183990479, 0.9465579986572266, 1.0210398435592651, 0.9059688448905945, 0.8949798345565796, 0.9734535813331604, 0.933096170425415, 0.937218964099884, 0.794526219367981, 0.9519623517990112, 0.8975340723991394, 0.9391809701919556, 0.8847330808639526, 0.8211320042610168]
gate_output_loss[3] = [0.6185982823371887, 0.3800501227378845, 0.34900814294815063, 0.3331446647644043, 0.3154875636100769, 0.30088526010513306, 0.29863956570625305, 0.29607534408569336, 0.2907488942146301, 0.2850969731807709, 0.27712008357048035, 0.2812037467956543, 0.2706642150878906, 0.2761230170726776, 0.2665766477584839, 0.2558101713657379, 0.25292348861694336, 0.25127238035202026, 0.2536797523498535, 0.24676506221294403, 0.2408541589975357, 0.23878172039985657, 0.23670507967472076, 0.2395438551902771, 0.23060889542102814, 0.23256757855415344, 0.23184840381145477, 0.23016610741615295, 0.22381000220775604, 0.21522048115730286, 0.21664837002754211, 0.21869739890098572, 0.21213005483150482, 0.21305310726165771, 0.22215358912944794, 0.20261624455451965, 0.20038318634033203, 0.2097819596529007, 0.201321080327034, 0.20173536241054535, 0.20185914635658264, 0.19775649905204773, 0.19068901240825653, 0.19148525595664978, 0.19037005305290222, 0.1842609941959381, 0.1868894398212433, 0.1787196695804596, 0.18701285123825073, 0.17846821248531342, 0.18642719089984894, 0.17973215878009796, 0.1778780072927475, 0.17931954562664032, 0.17899133265018463, 0.16792571544647217, 0.18463745713233948, 0.172856405377388, 0.17683617770671844, 0.16851739585399628, 0.1636042445898056, 0.15992522239685059, 0.1653149574995041, 0.16725866496562958, 0.16883817315101624, 0.16326269507408142, 0.15272127091884613, 0.16513831913471222, 0.15767483413219452, 0.15731976926326752, 0.1524622142314911]
val_gate_output_loss[3] = [0.3503527343273163, 0.2520296573638916, 0.2826775312423706, 0.2690950036048889, 0.22771863639354706, 0.2430451214313507, 0.2706534266471863, 0.26744523644447327, 0.2681390345096588, 0.2752971351146698, 0.23685331642627716, 0.19944660365581512, 0.2234124094247818, 0.23273660242557526, 0.2575720548629761, 0.21773511171340942, 0.22866202890872955, 0.23168198764324188, 0.23262399435043335, 0.23310238122940063, 0.2487829327583313, 0.21192510426044464, 0.23847375810146332, 0.18677106499671936, 0.22686532139778137, 0.22761479020118713, 0.22889795899391174, 0.22885876893997192, 0.24065633118152618, 0.258536696434021, 0.21609842777252197, 0.2118121087551117, 0.20143169164657593, 0.19418862462043762, 0.2298859804868698, 0.2256821244955063, 0.21475982666015625, 0.2113533914089203, 0.22023452818393707, 0.2248302698135376, 0.2185027152299881, 0.20811617374420166, 0.22097459435462952, 0.2169683575630188, 0.2320701777935028, 0.24503710865974426, 0.19087935984134674, 0.21037250757217407, 0.24541430175304413, 0.24899505078792572, 0.27435731887817383, 0.24507030844688416, 0.23652257025241852, 0.21212971210479736, 0.2026328295469284, 0.21520546078681946, 0.21886548399925232, 0.25853851437568665, 0.21148885786533356, 0.21484194695949554, 0.2262207716703415, 0.24329455196857452, 0.22232449054718018, 0.23820701241493225, 0.22135847806930542, 0.2030060589313507, 0.24026800692081451, 0.23208671808242798, 0.21936802566051483, 0.24179762601852417, 0.26361748576164246]
reduced_sum_loss[3] = [0.5745813846588135, 0.4819781184196472, 0.45142585039138794, 0.43866246938705444, 0.4202975928783417, 0.4134007692337036, 0.40836605429649353, 0.40285834670066833, 0.3947853147983551, 0.3953731060028076, 0.3869660794734955, 0.386262446641922, 0.382609486579895, 0.37472084164619446, 0.3718130886554718, 0.3707769513130188, 0.3640512526035309, 0.36536088585853577, 0.36410996317863464, 0.3571152687072754, 0.3556442856788635, 0.34851789474487305, 0.3491288423538208, 0.349345326423645, 0.346351683139801, 0.3447780907154083, 0.34517592191696167, 0.34461739659309387, 0.3389798700809479, 0.33592450618743896, 0.331364244222641, 0.33604738116264343, 0.3344500958919525, 0.32925352454185486, 0.32996752858161926, 0.3256509304046631, 0.3228641152381897, 0.32629454135894775, 0.32189062237739563, 0.3211709260940552, 0.3234941363334656, 0.32247549295425415, 0.3169203996658325, 0.31616342067718506, 0.3151295781135559, 0.3128340542316437, 0.31239041686058044, 0.3094954788684845, 0.31308698654174805, 0.30865123867988586, 0.3097033202648163, 0.31238406896591187, 0.3065286874771118, 0.30738750100135803, 0.30625659227371216, 0.2997586727142334, 0.30390870571136475, 0.304545521736145, 0.305300235748291, 0.30099329352378845, 0.29860132932662964, 0.2945343554019928, 0.30154937505722046, 0.29712072014808655, 0.29866862297058105, 0.29228267073631287, 0.29459792375564575, 0.2942105829715729, 0.2919786870479584, 0.2941848337650299, 0.28972524404525757]
val_reduced_sum_loss[3] = [0.8190039396286011, 0.6010494828224182, 0.5650008320808411, 0.5502213835716248, 0.5057365298271179, 0.49397629499435425, 0.4877375364303589, 0.462068110704422, 0.49231085181236267, 0.4582129120826721, 0.447287380695343, 0.4583888351917267, 0.47445547580718994, 0.44599366188049316, 0.46388083696365356, 0.4375949501991272, 0.43710869550704956, 0.45099690556526184, 0.4341978132724762, 0.4171227216720581, 0.4277082681655884, 0.41894933581352234, 0.4399819076061249, 0.4153416156768799, 0.42713189125061035, 0.4369020462036133, 0.4224158525466919, 0.40758153796195984, 0.41966360807418823, 0.42227423191070557, 0.40736791491508484, 0.408687949180603, 0.39870208501815796, 0.41493290662765503, 0.3946264684200287, 0.4098952114582062, 0.41044536232948303, 0.40701889991760254, 0.410024493932724, 0.413343608379364, 0.40734341740608215, 0.3877045214176178, 0.40430372953414917, 0.4062682092189789, 0.40134888887405396, 0.39495334029197693, 0.40112096071243286, 0.4016052484512329, 0.40464136004447937, 0.40510159730911255, 0.38978415727615356, 0.3950645923614502, 0.4047222137451172, 0.3856307566165924, 0.3903198540210724, 0.3872431218624115, 0.38667237758636475, 0.40697094798088074, 0.3890437185764313, 0.3929438591003418, 0.39740699529647827, 0.38423123955726624, 0.3953878581523895, 0.40175843238830566, 0.38458916544914246, 0.385535329580307, 0.3876039981842041, 0.3925086557865143, 0.3875105679035187, 0.38774728775024414, 0.3785109221935272]
gate_output_accuracy[3] = [0.798916220664978, 0.8758518099784851, 0.8823977708816528, 0.8858170509338379, 0.8936290740966797, 0.8945354223251343, 0.8961227536201477, 0.8972976803779602, 0.9015705585479736, 0.9017240405082703, 0.9048363566398621, 0.9031770825386047, 0.9065148234367371, 0.9048075675964355, 0.9103608727455139, 0.9121208190917969, 0.9141014218330383, 0.9121783971786499, 0.9128593802452087, 0.9153818488121033, 0.9181345105171204, 0.9171513915061951, 0.9178803563117981, 0.9167965650558472, 0.9195396304130554, 0.9203165173530579, 0.920249342918396, 0.9213619232177734, 0.9219805598258972, 0.924752414226532, 0.925754725933075, 0.9240474700927734, 0.9255245327949524, 0.9255532622337341, 0.9208440184593201, 0.9296007752418518, 0.9294808506965637, 0.9262006878852844, 0.9296966791152954, 0.9286080598831177, 0.9286512136459351, 0.9305694699287415, 0.9341470003128052, 0.9330775737762451, 0.9332742094993591, 0.9340654611587524, 0.9332646131515503, 0.9377436637878418, 0.9343484044075012, 0.9375710487365723, 0.9343867897987366, 0.9360747933387756, 0.9381560683250427, 0.935978889465332, 0.9356000423431396, 0.941824734210968, 0.9351924061775208, 0.9393213987350464, 0.9371298551559448, 0.9401366710662842, 0.9428701400756836, 0.9421076774597168, 0.9405634999275208, 0.9416089057922363, 0.9397146701812744, 0.9416041374206543, 0.9445102214813232, 0.941292405128479, 0.9443376064300537, 0.9437956809997559, 0.945598840713501]
val_gate_output_accuracy[3] = [0.8696572184562683, 0.9170038104057312, 0.9011425971984863, 0.8988573551177979, 0.920033872127533, 0.9128057360649109, 0.9096403121948242, 0.9033770561218262, 0.9118916392326355, 0.8996191024780273, 0.929885745048523, 0.9318662881851196, 0.9316800832748413, 0.91915363073349, 0.9094202518463135, 0.9229623079299927, 0.9248582124710083, 0.9200000166893005, 0.916022002696991, 0.9133474230766296, 0.9104189872741699, 0.925399899482727, 0.9150401949882507, 0.9330343008041382, 0.9233177900314331, 0.9232839345932007, 0.9168006777763367, 0.9194414019584656, 0.9115530848503113, 0.9140414595603943, 0.9280914068222046, 0.9296149015426636, 0.929885745048523, 0.9271265268325806, 0.9098434448242188, 0.9169191718101501, 0.91915363073349, 0.9225561022758484, 0.9236394166946411, 0.9248243570327759, 0.9239102602005005, 0.9292424917221069, 0.9193229079246521, 0.9216758608818054, 0.9182395339012146, 0.9151079058647156, 0.9325772523880005, 0.9234870672225952, 0.9136013388633728, 0.910588264465332, 0.900550127029419, 0.9062716960906982, 0.9161912798881531, 0.9227930307388306, 0.9245365858078003, 0.9199323058128357, 0.9236394166946411, 0.9045450687408447, 0.9230300188064575, 0.9254845380783081, 0.916986882686615, 0.9142107367515564, 0.9212526679039001, 0.9166314005851746, 0.9196106791496277, 0.9286669492721558, 0.915378749370575, 0.9191367030143738, 0.9176639914512634, 0.9144477248191833, 0.9047989845275879]
reduced_sum_mae[3] = [0.5294333100318909, 0.47766804695129395, 0.4607934355735779, 0.45296910405158997, 0.4438265562057495, 0.4385789632797241, 0.4352624714374542, 0.4326005280017853, 0.4289778769016266, 0.42855948209762573, 0.42393219470977783, 0.4233759343624115, 0.42083293199539185, 0.41808971762657166, 0.41586169600486755, 0.4142378866672516, 0.4112806022167206, 0.41118869185447693, 0.4110739231109619, 0.4075344204902649, 0.4067602753639221, 0.4028854966163635, 0.4029480814933777, 0.4033738076686859, 0.4005436599254608, 0.39978522062301636, 0.39975807070732117, 0.39864659309387207, 0.3964736759662628, 0.39536252617836, 0.3918553292751312, 0.39493483304977417, 0.39359939098358154, 0.39136531949043274, 0.39188510179519653, 0.3886531889438629, 0.38706791400909424, 0.388310045003891, 0.38735494017601013, 0.3863345980644226, 0.3870413899421692, 0.38528281450271606, 0.3838890492916107, 0.383194237947464, 0.3824623227119446, 0.38125213980674744, 0.38069722056388855, 0.37908482551574707, 0.38112229108810425, 0.3786832094192505, 0.3789916932582855, 0.3801781237125397, 0.37692058086395264, 0.3792059123516083, 0.3774643838405609, 0.372935950756073, 0.3763417899608612, 0.37545546889305115, 0.37703830003738403, 0.37359267473220825, 0.3721840977668762, 0.3699988126754761, 0.37401506304740906, 0.3713397979736328, 0.3728615343570709, 0.36847051978111267, 0.37000545859336853, 0.3696576654911041, 0.3683324158191681, 0.37060627341270447, 0.3664964437484741]
val_reduced_sum_mae[3] = [0.6775307059288025, 0.5602840781211853, 0.5265527367591858, 0.5187650322914124, 0.4961665868759155, 0.48241135478019714, 0.4825183153152466, 0.46618545055389404, 0.48143652081489563, 0.4590931236743927, 0.4553350806236267, 0.460510790348053, 0.47330886125564575, 0.458516925573349, 0.4697883129119873, 0.45035767555236816, 0.4509698450565338, 0.4617796540260315, 0.4532715678215027, 0.43838971853256226, 0.4473089575767517, 0.43919289112091064, 0.4518803358078003, 0.43570777773857117, 0.44316279888153076, 0.4487496316432953, 0.4387197494506836, 0.4318110942840576, 0.44130027294158936, 0.43926841020584106, 0.4291015863418579, 0.42992904782295227, 0.42534932494163513, 0.43399134278297424, 0.42175427079200745, 0.4297691583633423, 0.4322521686553955, 0.4282016456127167, 0.4339393377304077, 0.43477606773376465, 0.4305490553379059, 0.419579416513443, 0.4288550913333893, 0.42934709787368774, 0.42616528272628784, 0.4209587574005127, 0.4250629246234894, 0.42890286445617676, 0.4277007579803467, 0.43076092004776, 0.4194106161594391, 0.4245139956474304, 0.42916008830070496, 0.41783058643341064, 0.4198344051837921, 0.4183805584907532, 0.4172230362892151, 0.42828840017318726, 0.41797953844070435, 0.4214361906051636, 0.42342063784599304, 0.4141572117805481, 0.4232056438922882, 0.4297908842563629, 0.4171537160873413, 0.41857269406318665, 0.41790521144866943, 0.4197689890861511, 0.4156407415866852, 0.4134654402732849, 0.41023412346839905]
# 74/74 [==============================] - 1s 7ms/step - loss: 0.8211 - gate_output_loss: 0.2636 - reduced_sum_loss: 0.3785 - gate_output_accuracy: 0.9048 - reduced_sum_mae: 0.4102
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== MoE ===========
# loss                : 1.7770
# gate_output_loss    : 1.2113
# reduced_sum_loss     : 0.4195
# gate_output_accuracy: 0.7728
# reduced_sum_mae      : 0.4627
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-23_16:24:59/model_MoE.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-23_16:24:59/model_MoE.png


####################################
#################################### 5
####################################

# Epoch 00047: LearningRateScheduler reducing learning rate to 0.0003874204890000001.
# 261/261 [==============================] - 3s 13ms/step - loss: 1.1363 - gate_output_loss: 0.1816 - reduced_sum_loss: 0.3136 - gate_output_accuracy: 0.9365 - reduced_sum_mae: 0.3798 - val_loss: 1.2863 - val_gate_output_loss: 0.1942 - val_reduced_sum_loss: 0.3827 - val_gate_output_accuracy: 0.9303 - val_reduced_sum_mae: 0.4126
# [on_epoch_end] epoch: 46 , loss: 1.151475191116333 , val_loss : 1.2862509489059448
# Epoch 00047: val_loss did not improve from 1.27089
loss[4] = [38.038021087646484, 4.796234130859375, 4.27998161315918, 3.9255149364471436, 3.722308874130249, 3.324991464614868, 3.199651002883911, 3.1577651500701904, 3.1307730674743652, 3.0607807636260986, 2.846735715866089, 2.7088165283203125, 2.7320210933685303, 2.6545941829681396, 2.5869176387786865, 2.3624074459075928, 2.3259103298187256, 2.4498002529144287, 2.3495242595672607, 2.2776119709014893, 2.112499237060547, 2.072197914123535, 2.052382469177246, 2.0328664779663086, 2.094627857208252, 1.8935856819152832, 1.8327183723449707, 1.8062949180603027, 1.7526021003723145, 1.8166438341140747, 1.6119513511657715, 1.68117094039917, 1.5418177843093872, 1.5893158912658691, 1.5593153238296509, 1.4356393814086914, 1.3954309225082397, 1.4374703168869019, 1.4504808187484741, 1.4276764392852783, 1.3178788423538208, 1.291785717010498, 1.3250327110290527, 1.237938642501831, 1.3385369777679443, 1.1849408149719238, 1.151475191116333]
val_loss[4] = [5.103795528411865, 4.3088908195495605, 3.9264159202575684, 3.855978012084961, 3.768221616744995, 3.241230010986328, 2.97163724899292, 3.0177969932556152, 3.2331013679504395, 2.8107597827911377, 3.067321300506592, 2.52364444732666, 2.6312830448150635, 2.6500813961029053, 2.82551908493042, 2.372469902038574, 2.6345670223236084, 2.3923356533050537, 2.4622409343719482, 2.7228949069976807, 2.056936502456665, 2.4799790382385254, 2.13533878326416, 2.1409342288970947, 1.9093642234802246, 1.7262630462646484, 1.7489008903503418, 1.7670879364013672, 1.881325125694275, 1.694830060005188, 1.6509898900985718, 1.7154786586761475, 1.5160400867462158, 1.6309585571289062, 1.4485608339309692, 1.5805182456970215, 1.5182346105575562, 1.4802086353302002, 1.6338098049163818, 1.3888955116271973, 1.3498241901397705, 1.2792315483093262, 1.3313145637512207, 1.310085654258728, 1.2804536819458008, 1.2708885669708252, 1.2862509489059448]
gate_output_loss[4] = [0.6198787093162537, 0.38714519143104553, 0.34299197793006897, 0.32759889960289, 0.3241191506385803, 0.3040269613265991, 0.298869252204895, 0.30346253514289856, 0.28814834356307983, 0.2917507588863373, 0.278790682554245, 0.27946940064430237, 0.28013041615486145, 0.2697090208530426, 0.26349252462387085, 0.2636013329029083, 0.25600603222846985, 0.2625526785850525, 0.2532329857349396, 0.25003910064697266, 0.24187971651554108, 0.24220165610313416, 0.2396325170993805, 0.23113270103931427, 0.23797467350959778, 0.2378459870815277, 0.22284270823001862, 0.2224283069372177, 0.22399428486824036, 0.22061017155647278, 0.21691399812698364, 0.21888990700244904, 0.2123102992773056, 0.21182487905025482, 0.2110975980758667, 0.2082633674144745, 0.20287427306175232, 0.20327286422252655, 0.20396490395069122, 0.19740088284015656, 0.19661583006381989, 0.1990637183189392, 0.1999855637550354, 0.1870349943637848, 0.2008117437362671, 0.19387702643871307, 0.18156084418296814]
val_gate_output_loss[4] = [0.37229645252227783, 0.291405588388443, 0.2753000855445862, 0.2481769323348999, 0.28901633620262146, 0.23336413502693176, 0.23365680873394012, 0.26830700039863586, 0.2502603530883789, 0.2212122231721878, 0.2770927846431732, 0.2363223433494568, 0.23588186502456665, 0.19880789518356323, 0.29600733518600464, 0.2720550000667572, 0.28329557180404663, 0.19801770150661469, 0.22128920257091522, 0.32599952816963196, 0.22845029830932617, 0.263588547706604, 0.26445889472961426, 0.20897918939590454, 0.2100733518600464, 0.2301303595304489, 0.2415250539779663, 0.22228200733661652, 0.20559357106685638, 0.23645319044589996, 0.22686122357845306, 0.2150082141160965, 0.19185960292816162, 0.2206740379333496, 0.20383383333683014, 0.19300754368305206, 0.20583513379096985, 0.24516251683235168, 0.23399432003498077, 0.20373594760894775, 0.19111540913581848, 0.19754643738269806, 0.25146785378456116, 0.19635924696922302, 0.20205871760845184, 0.22821931540966034, 0.19420260190963745]
reduced_sum_loss[4] = [0.5792137980461121, 0.47963589429855347, 0.4454140365123749, 0.42847132682800293, 0.41374680399894714, 0.4023199677467346, 0.4008551836013794, 0.3946301341056824, 0.39528799057006836, 0.3865908980369568, 0.38415345549583435, 0.37629786133766174, 0.37997549772262573, 0.37595313787460327, 0.37151044607162476, 0.3635803759098053, 0.36162737011909485, 0.3645014762878418, 0.3570975661277771, 0.35772666335105896, 0.35297879576683044, 0.35057756304740906, 0.3510122001171112, 0.34723079204559326, 0.34282994270324707, 0.3418138027191162, 0.3403407037258148, 0.3407900333404541, 0.33396250009536743, 0.3397132456302643, 0.33084622025489807, 0.3358174264431, 0.3295673727989197, 0.32798412442207336, 0.3301999866962433, 0.323655366897583, 0.3243790864944458, 0.3213500678539276, 0.32511311769485474, 0.32448092103004456, 0.3199092149734497, 0.3190265893936157, 0.3189781606197357, 0.3173028230667114, 0.31731337308883667, 0.3128086030483246, 0.3123931288719177]
val_reduced_sum_loss[4] = [0.81819087266922, 0.5792454481124878, 0.5300189852714539, 0.48015260696411133, 0.4858725965023041, 0.46959587931632996, 0.45666131377220154, 0.4505060315132141, 0.49037110805511475, 0.4288123846054077, 0.44634026288986206, 0.44259151816368103, 0.44681546092033386, 0.44001197814941406, 0.46235719323158264, 0.4283899962902069, 0.4184316396713257, 0.4302670359611511, 0.41568782925605774, 0.4312528371810913, 0.4005013406276703, 0.4257921874523163, 0.4157206118106842, 0.42548927664756775, 0.4058316946029663, 0.39808711409568787, 0.40068528056144714, 0.39680659770965576, 0.3895520865917206, 0.3910273611545563, 0.3868492543697357, 0.39234161376953125, 0.401056170463562, 0.40943780541419983, 0.3876388967037201, 0.3862500488758087, 0.4086002707481384, 0.40349963307380676, 0.4142526686191559, 0.38811978697776794, 0.39510130882263184, 0.38942739367485046, 0.4021570086479187, 0.39643561840057373, 0.39190560579299927, 0.3822881281375885, 0.3827143609523773]
gate_output_accuracy[4] = [0.8022826910018921, 0.8758757710456848, 0.8870590925216675, 0.8881428837776184, 0.8919074535369873, 0.8965303897857666, 0.8986548185348511, 0.8948519229888916, 0.9006689786911011, 0.8996523022651672, 0.9042081236839294, 0.90443354845047, 0.9041697382926941, 0.9069032669067383, 0.9089173674583435, 0.9106917381286621, 0.909416139125824, 0.9085529446601868, 0.9108116626739502, 0.9118858575820923, 0.9159908890724182, 0.915070116519928, 0.9175686240196228, 0.9175782203674316, 0.9170458912849426, 0.9152283668518066, 0.9208824038505554, 0.9220908880233765, 0.9224169850349426, 0.9219086170196533, 0.9246900677680969, 0.9250785112380981, 0.9257259368896484, 0.9254717826843262, 0.9263110160827637, 0.9278935194015503, 0.9299460649490356, 0.929653525352478, 0.9277256727218628, 0.9306797981262207, 0.9333269596099854, 0.9298309683799744, 0.9286800026893616, 0.9325740337371826, 0.9304543733596802, 0.9317683577537537, 0.9358494281768799]
val_gate_output_accuracy[4] = [0.8618366718292236, 0.8963690400123596, 0.9041218757629395, 0.9095726013183594, 0.9023613929748535, 0.9212357401847839, 0.9208294749259949, 0.8927972912788391, 0.9081845283508301, 0.9228438138961792, 0.8931527733802795, 0.9136859774589539, 0.9175624251365662, 0.9240964651107788, 0.8946593403816223, 0.900871753692627, 0.8985865712165833, 0.9224037528038025, 0.9233516454696655, 0.8808633089065552, 0.9156834483146667, 0.91209477186203, 0.910588264465332, 0.919796884059906, 0.9253321886062622, 0.9105713367462158, 0.9158527255058289, 0.9259923696517944, 0.9258400201797485, 0.9137875437736511, 0.9195768237113953, 0.9233177900314331, 0.9302750825881958, 0.9211341738700867, 0.9251290559768677, 0.9278713464736938, 0.9233347177505493, 0.9111129641532898, 0.9108421206474304, 0.923385500907898, 0.9249428510665894, 0.9208464026451111, 0.9082691669464111, 0.9285145998001099, 0.9277020692825317, 0.9220144152641296, 0.930292010307312]
reduced_sum_mae[4] = [0.5309745669364929, 0.4775283634662628, 0.458220511674881, 0.4478440582752228, 0.44015809893608093, 0.433766633272171, 0.4326491951942444, 0.4294764995574951, 0.4281655251979828, 0.42521408200263977, 0.42236679792404175, 0.41870948672294617, 0.41975951194763184, 0.41732701659202576, 0.41501957178115845, 0.41101738810539246, 0.40988650918006897, 0.410674124956131, 0.40787842869758606, 0.40772804617881775, 0.404573917388916, 0.403698593378067, 0.40334251523017883, 0.4006553888320923, 0.3987267315387726, 0.39737045764923096, 0.3964743912220001, 0.39720502495765686, 0.39350584149360657, 0.395815372467041, 0.3910643458366394, 0.3924897313117981, 0.39098381996154785, 0.3902597725391388, 0.39022761583328247, 0.3867172300815582, 0.38733649253845215, 0.38603878021240234, 0.3878421485424042, 0.38654911518096924, 0.3841453790664673, 0.38353946805000305, 0.38364776968955994, 0.38366571068763733, 0.38321271538734436, 0.3804423213005066, 0.37957754731178284]
val_reduced_sum_mae[4] = [0.6760208606719971, 0.5464091300964355, 0.5065019726753235, 0.4774421155452728, 0.4749562740325928, 0.4685998857021332, 0.4605259895324707, 0.4575765132904053, 0.4827765226364136, 0.4434655010700226, 0.4547381103038788, 0.4500821530818939, 0.455854207277298, 0.4515712857246399, 0.4610699713230133, 0.4399811327457428, 0.43885281682014465, 0.44458481669425964, 0.43549278378486633, 0.44525110721588135, 0.426026314496994, 0.4433153569698334, 0.4385208487510681, 0.4436715841293335, 0.43267959356307983, 0.427558571100235, 0.42567336559295654, 0.4228498935699463, 0.4172694683074951, 0.42257410287857056, 0.41596099734306335, 0.4170379042625427, 0.42705124616622925, 0.42918097972869873, 0.4159225523471832, 0.41492053866386414, 0.43020740151405334, 0.4263226091861725, 0.4296073615550995, 0.4164794087409973, 0.4198939800262451, 0.413960337638855, 0.4248715937137604, 0.4215472340583801, 0.41691896319389343, 0.41265803575515747, 0.4126307964324951]
# 74/74 [==============================] - 0s 6ms/step - loss: 1.2863 - gate_output_loss: 0.1942 - reduced_sum_loss: 0.3827 - gate_output_accuracy: 0.9303 - reduced_sum_mae: 0.4126
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== MoE ===========
# loss                : 2.0531
# gate_output_loss    : 0.9522
# reduced_sum_loss     : 0.4271
# gate_output_accuracy: 0.8104
# reduced_sum_mae      : 0.4635
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-23_16:32:42/model_MoE.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-23_16:32:42/model_MoE.png

####################################
#################################### 6
####################################

# Epoch 00053: LearningRateScheduler reducing learning rate to 0.0003486784401000001.
# 261/261 [==============================] - 4s 14ms/step - loss: 1.0294 - gate_output_loss: 0.1709 - reduced_sum_loss: 0.3011 - gate_output_accuracy: 0.9408 - reduced_sum_mae: 0.3753 - val_loss: 1.2101 - val_gate_output_loss: 0.2620 - val_reduced_sum_loss: 0.4167 - val_gate_output_accuracy: 0.9013 - val_reduced_sum_mae: 0.4338
# [on_epoch_end] epoch: 52 , loss: 1.04456627368927 , val_loss : 1.2100718021392822
# Epoch 00053: val_loss did not improve from 1.12312
loss[5] = [38.007076263427734, 4.653234004974365, 4.290151119232178, 3.98469614982605, 3.814194917678833, 3.3358609676361084, 3.2248594760894775, 3.14481782913208, 3.1722412109375, 3.0344126224517822, 2.8205533027648926, 2.7290146350860596, 2.6445870399475098, 2.6739940643310547, 2.6116645336151123, 2.361013650894165, 2.4212231636047363, 2.3051979541778564, 2.267153739929199, 2.2158210277557373, 2.0973262786865234, 2.021498918533325, 2.032611846923828, 1.944420576095581, 2.0049357414245605, 1.8773618936538696, 1.8956156969070435, 1.766128420829773, 1.762080192565918, 1.8480606079101562, 1.589657187461853, 1.6016592979431152, 1.5937182903289795, 1.602831482887268, 1.6227182149887085, 1.521715521812439, 1.4374037981033325, 1.4559394121170044, 1.4016129970550537, 1.41341233253479, 1.3104289770126343, 1.285750389099121, 1.2767884731292725, 1.2495378255844116, 1.2750838994979858, 1.1589056253433228, 1.1441993713378906, 1.1771342754364014, 1.1259838342666626, 1.168647050857544, 1.0707422494888306, 1.0517252683639526, 1.04456627368927]
val_loss[5] = [4.669712066650391, 4.593083381652832, 4.1380181312561035, 3.5902252197265625, 3.749368190765381, 2.7565934658050537, 3.015017509460449, 3.0896904468536377, 2.845466375350952, 3.089043140411377, 2.640653371810913, 2.5855677127838135, 2.4392082691192627, 3.0616555213928223, 2.3796803951263428, 2.39831805229187, 2.405543088912964, 2.365044593811035, 2.1107921600341797, 2.209839344024658, 1.9291419982910156, 1.9844125509262085, 1.9855087995529175, 1.8486099243164062, 1.8717026710510254, 1.8455452919006348, 1.8352469205856323, 1.8075151443481445, 1.8005417585372925, 1.7950427532196045, 1.6951014995574951, 1.552516222000122, 1.6817786693572998, 1.6103780269622803, 1.6260700225830078, 1.3800541162490845, 1.5021907091140747, 1.4585367441177368, 1.3257085084915161, 1.3487114906311035, 1.2483571767807007, 1.255172610282898, 1.308363676071167, 1.2272565364837646, 1.297190546989441, 1.2455780506134033, 1.2664706707000732, 1.12311851978302, 1.2113207578659058, 1.1498894691467285, 1.1715941429138184, 1.1469900608062744, 1.2100718021392822]
gate_output_loss[5] = [0.6187411546707153, 0.3864503800868988, 0.3374824821949005, 0.3315966725349426, 0.3228802978992462, 0.29831773042678833, 0.30243849754333496, 0.2972980737686157, 0.3007364273071289, 0.29258233308792114, 0.284523606300354, 0.2739100754261017, 0.2676180303096771, 0.2765789031982422, 0.27408143877983093, 0.25501134991645813, 0.2598798871040344, 0.25322315096855164, 0.25332942605018616, 0.24898673593997955, 0.23514796793460846, 0.23542971909046173, 0.23939721286296844, 0.23420658707618713, 0.23309186100959778, 0.22561988234519958, 0.23301059007644653, 0.22286880016326904, 0.22773748636245728, 0.22872908413410187, 0.21341228485107422, 0.21530957520008087, 0.21309776604175568, 0.21336792409420013, 0.21707233786582947, 0.2059718370437622, 0.20570319890975952, 0.20738698542118073, 0.20734480023384094, 0.20648732781410217, 0.1959005743265152, 0.19924114644527435, 0.18826308846473694, 0.19406408071517944, 0.1959579437971115, 0.18525435030460358, 0.18607179820537567, 0.18832959234714508, 0.1838737428188324, 0.18981213867664337, 0.18618565797805786, 0.18309156596660614, 0.17678116261959076]
val_gate_output_loss[5] = [0.36624592542648315, 0.2962700426578522, 0.2819979190826416, 0.2385406792163849, 0.21188271045684814, 0.22999149560928345, 0.20593048632144928, 0.2886427938938141, 0.25559908151626587, 0.2526334822177887, 0.2179509848356247, 0.2196488380432129, 0.21087703108787537, 0.24689994752407074, 0.21279893815517426, 0.2308650016784668, 0.23178212344646454, 0.23511230945587158, 0.24920988082885742, 0.22860965132713318, 0.22520951926708221, 0.2183138132095337, 0.19162045419216156, 0.19825033843517303, 0.21320340037345886, 0.2629168927669525, 0.25017860531806946, 0.25474750995635986, 0.19832153618335724, 0.19909103214740753, 0.19989727437496185, 0.21103985607624054, 0.2049034833908081, 0.2207362949848175, 0.22183631360530853, 0.1944713145494461, 0.20639242231845856, 0.23040884733200073, 0.1985112577676773, 0.21614836156368256, 0.2222192883491516, 0.21266376972198486, 0.20839744806289673, 0.21425475180149078, 0.22857609391212463, 0.23902593553066254, 0.24893581867218018, 0.21970272064208984, 0.25929880142211914, 0.1880553662776947, 0.2577172517776489, 0.20805028080940247, 0.2619625926017761]
reduced_sum_loss[5] = [0.5858246088027954, 0.4781850576400757, 0.45226559042930603, 0.4330684542655945, 0.42517396807670593, 0.4060535728931427, 0.4011989235877991, 0.39214834570884705, 0.3939701318740845, 0.38771116733551025, 0.38515177369117737, 0.37499338388442993, 0.3715052008628845, 0.37147966027259827, 0.37159615755081177, 0.3632202744483948, 0.3614368140697479, 0.35539090633392334, 0.3568950593471527, 0.3527851998806, 0.351105660200119, 0.348985880613327, 0.3464677333831787, 0.34666886925697327, 0.344418466091156, 0.3378402292728424, 0.3431302607059479, 0.33902767300605774, 0.33490192890167236, 0.33926263451576233, 0.3325943946838379, 0.33091211318969727, 0.3292643129825592, 0.3273055851459503, 0.32864466309547424, 0.3291158378124237, 0.3266219198703766, 0.32258278131484985, 0.3209446966648102, 0.3216736614704132, 0.3152603805065155, 0.31634223461151123, 0.3150821030139923, 0.3129991292953491, 0.3117416203022003, 0.30693891644477844, 0.31147295236587524, 0.30732008814811707, 0.3064807653427124, 0.30799010396003723, 0.3030508756637573, 0.3041185736656189, 0.30429384112358093]
val_reduced_sum_loss[5] = [0.8320090770721436, 0.6047358512878418, 0.5076112747192383, 0.5457953214645386, 0.48813262581825256, 0.46501800417900085, 0.4427664279937744, 0.46672412753105164, 0.4470300078392029, 0.4754088521003723, 0.47971901297569275, 0.4276825487613678, 0.4346298277378082, 0.47862473130226135, 0.43235647678375244, 0.4356139898300171, 0.4423360228538513, 0.4395246207714081, 0.4169788360595703, 0.4284142255783081, 0.43197542428970337, 0.42319464683532715, 0.4200429320335388, 0.41650962829589844, 0.4206961691379547, 0.4334946572780609, 0.4074055552482605, 0.4200142025947571, 0.4075101613998413, 0.4146304130554199, 0.40445271134376526, 0.40108340978622437, 0.40843939781188965, 0.40241312980651855, 0.40327680110931396, 0.39899981021881104, 0.4094482660293579, 0.4050867259502411, 0.39003267884254456, 0.3970421552658081, 0.3926231265068054, 0.38950011134147644, 0.39175257086753845, 0.38803449273109436, 0.4001530110836029, 0.4041270315647125, 0.40507298707962036, 0.3948732614517212, 0.4044662415981293, 0.3850446045398712, 0.4009155333042145, 0.38696232438087463, 0.41674062609672546]
gate_output_accuracy[5] = [0.8029972314834595, 0.8771034479141235, 0.8882628083229065, 0.8886848092079163, 0.889106810092926, 0.8976909518241882, 0.8965975046157837, 0.8953938484191895, 0.8963721394538879, 0.9014266729354858, 0.902956485748291, 0.9056899547576904, 0.9087063670158386, 0.9056611657142639, 0.9058146476745605, 0.9131278991699219, 0.9101306796073914, 0.9124805331230164, 0.9128593802452087, 0.9125716090202332, 0.9187195897102356, 0.9177412986755371, 0.9181297421455383, 0.9189545512199402, 0.9202685356140137, 0.9209975004196167, 0.917755663394928, 0.9212995767593384, 0.9207720756530762, 0.9197986125946045, 0.9255053400993347, 0.9253278970718384, 0.9252511858940125, 0.9257355332374573, 0.9250305891036987, 0.9282244443893433, 0.9284833669662476, 0.9280374050140381, 0.9271262288093567, 0.9273228645324707, 0.9319074153900146, 0.931073009967804, 0.9335331320762634, 0.9315573573112488, 0.9324637055397034, 0.9348471164703369, 0.9344251155853271, 0.9337825179100037, 0.936981201171875, 0.9320992827415466, 0.9329864382743835, 0.9355472922325134, 0.9378491640090942]
val_gate_output_accuracy[5] = [0.8561489582061768, 0.9069488048553467, 0.8888362050056458, 0.9102158546447754, 0.9268556833267212, 0.9321202039718628, 0.9273127317428589, 0.8949640393257141, 0.9130935072898865, 0.9224376082420349, 0.925399899482727, 0.9239271879196167, 0.9245535135269165, 0.9204570651054382, 0.9270926713943481, 0.9172577261924744, 0.9227422475814819, 0.9246381521224976, 0.9147693514823914, 0.9151925444602966, 0.922826886177063, 0.918832004070282, 0.9305459260940552, 0.9306644201278687, 0.9274989366531372, 0.9109606146812439, 0.9087769985198975, 0.9170884490013123, 0.9258908033370972, 0.9343546628952026, 0.9224545359611511, 0.9264663457870483, 0.9225730299949646, 0.921963632106781, 0.9266525506973267, 0.9304612874984741, 0.928768515586853, 0.921083390712738, 0.9326449632644653, 0.9231992959976196, 0.9215742945671082, 0.9288531541824341, 0.9321202039718628, 0.9209479689598083, 0.924435019493103, 0.919475257396698, 0.9169530272483826, 0.9247735738754272, 0.9129919409751892, 0.9303935766220093, 0.9123825430870056, 0.928768515586853, 0.9013288021087646]
reduced_sum_mae[5] = [0.5330577492713928, 0.4781935214996338, 0.4619118571281433, 0.45121413469314575, 0.4453553259372711, 0.43652695417404175, 0.4339028596878052, 0.4288105368614197, 0.42841100692749023, 0.4241969585418701, 0.4231248199939728, 0.4182133674621582, 0.4166347086429596, 0.4153137505054474, 0.4148971438407898, 0.4112446904182434, 0.40913623571395874, 0.4065796136856079, 0.4065772593021393, 0.4052301049232483, 0.4023996591567993, 0.40222662687301636, 0.40033647418022156, 0.4008775055408478, 0.39912331104278564, 0.3954406976699829, 0.3986004889011383, 0.39705851674079895, 0.39448320865631104, 0.3954942226409912, 0.392035573720932, 0.3912276029586792, 0.3907260298728943, 0.3900298476219177, 0.3896104097366333, 0.38896235823631287, 0.3878685534000397, 0.3875630795955658, 0.38600486516952515, 0.38716429471969604, 0.38195544481277466, 0.38312864303588867, 0.38315024971961975, 0.3813325762748718, 0.380854070186615, 0.37847888469696045, 0.3792416453361511, 0.3783468008041382, 0.37822225689888, 0.3789178431034088, 0.37548959255218506, 0.3759263753890991, 0.3757103383541107]
val_reduced_sum_mae[5] = [0.6835569143295288, 0.5601712465286255, 0.4930957853794098, 0.5136721134185791, 0.48070773482322693, 0.46939149498939514, 0.4519163966178894, 0.4692230224609375, 0.45596757531166077, 0.48187536001205444, 0.47480884194374084, 0.44288259744644165, 0.44921770691871643, 0.48267820477485657, 0.44961363077163696, 0.45289936661720276, 0.45438429713249207, 0.45163941383361816, 0.435336172580719, 0.4454125761985779, 0.44342565536499023, 0.4425954818725586, 0.44089123606681824, 0.43722909688949585, 0.438461571931839, 0.4468507468700409, 0.43135979771614075, 0.4385676383972168, 0.43151187896728516, 0.4368286728858948, 0.4291362464427948, 0.4252893030643463, 0.42871764302253723, 0.4267938733100891, 0.4297703206539154, 0.42294666171073914, 0.4316297173500061, 0.42649605870246887, 0.4193641245365143, 0.4255106449127197, 0.41949260234832764, 0.4198553264141083, 0.4198581278324127, 0.417530357837677, 0.4256032407283783, 0.4265233874320984, 0.42728567123413086, 0.42030009627342224, 0.4300846457481384, 0.4155447483062744, 0.4265851378440857, 0.4193175137042999, 0.4337681531906128]
# 74/74 [==============================] - 1s 7ms/step - loss: 1.2101 - gate_output_loss: 0.2620 - reduced_sum_loss: 0.4167 - gate_output_accuracy: 0.9013 - reduced_sum_mae: 0.4338
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== MoE ===========
# loss                : 2.1175
# gate_output_loss    : 1.1482
# reduced_sum_loss     : 0.5228
# gate_output_accuracy: 0.7343
# reduced_sum_mae      : 0.5140
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-23_16:38:24/model_MoE.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-23_16:38:24/model_MoE.png

#
####################################
#################################### 7
####################################
# Epoch 00059: LearningRateScheduler reducing learning rate to 0.0003138105960900001.
# 261/261 [==============================] - 4s 14ms/step - loss: 0.9772 - gate_output_loss: 0.1733 - reduced_sum_loss: 0.2937 - gate_output_accuracy: 0.9402 - reduced_sum_mae: 0.3706 - val_loss: 1.0125 - val_gate_output_loss: 0.2125 - val_reduced_sum_loss: 0.4196 - val_gate_output_accuracy: 0.9256 - val_reduced_sum_mae: 0.4183
# [on_epoch_end] epoch: 58 , loss: 0.9562969207763672 , val_loss : 1.0124855041503906
# Epoch 00059: val_loss did not improve from 1.00424
loss[6] = [38.04853057861328, 4.720789909362793, 4.1948161125183105, 3.9228055477142334, 3.787166118621826, 3.283860921859741, 3.1301960945129395, 3.1035139560699463, 3.1198697090148926, 2.9932780265808105, 2.8156986236572266, 2.6660120487213135, 2.6008527278900146, 2.616189479827881, 2.4872887134552, 2.38824725151062, 2.369795322418213, 2.2721917629241943, 2.2945058345794678, 2.257568359375, 2.087862491607666, 2.1420271396636963, 2.0013771057128906, 2.039947271347046, 2.005509376525879, 1.7854639291763306, 1.8280375003814697, 1.7825957536697388, 1.7882087230682373, 1.7692654132843018, 1.7066973447799683, 1.6618239879608154, 1.627801775932312, 1.5804554224014282, 1.5324852466583252, 1.464576244354248, 1.451203465461731, 1.4358083009719849, 1.4239617586135864, 1.411669135093689, 1.3026944398880005, 1.3018229007720947, 1.3012622594833374, 1.2794748544692993, 1.295417070388794, 1.1329951286315918, 1.171094536781311, 1.156633734703064, 1.1611827611923218, 1.1738499402999878, 1.0408127307891846, 1.0528779029846191, 1.073060393333435, 1.0655517578125, 1.0459473133087158, 0.9855238795280457, 0.9538047909736633, 0.9764668345451355, 0.9562969207763672]
val_loss[6] = [5.154192924499512, 4.643989562988281, 3.9333255290985107, 3.9429168701171875, 3.573472738265991, 3.16530704498291, 3.209357976913452, 3.36887788772583, 2.879387617111206, 2.908595561981201, 2.527467966079712, 2.602490186691284, 2.6368329524993896, 2.5767428874969482, 2.5172958374023438, 2.6669986248016357, 2.2413170337677, 2.253049373626709, 2.2861180305480957, 2.3556439876556396, 2.4012553691864014, 2.200075149536133, 2.136249303817749, 1.986296534538269, 1.8663777112960815, 1.8790655136108398, 1.9301369190216064, 1.7344807386398315, 1.6904175281524658, 1.6531271934509277, 1.7368515729904175, 1.6660045385360718, 1.7080028057098389, 1.6078128814697266, 1.4543001651763916, 1.5196521282196045, 1.4014869928359985, 1.4673495292663574, 1.4066715240478516, 1.4117096662521362, 1.3042538166046143, 1.3271167278289795, 1.408576488494873, 1.2695426940917969, 1.3112858533859253, 1.2734318971633911, 1.2456165552139282, 1.131496787071228, 1.1729758977890015, 1.2262331247329712, 1.1040492057800293, 1.2486052513122559, 1.0973280668258667, 1.0042442083358765, 1.1427645683288574, 1.1138179302215576, 1.0357515811920166, 1.0931763648986816, 1.0124855041503906]
gate_output_loss[6] = [0.6240010261535645, 0.38922545313835144, 0.34570300579071045, 0.3270656168460846, 0.3183194100856781, 0.3038100302219391, 0.29386794567108154, 0.2900310158729553, 0.29872027039527893, 0.28961676359176636, 0.28495389223098755, 0.274080365896225, 0.2752460241317749, 0.2778873145580292, 0.263247549533844, 0.26717936992645264, 0.2599027752876282, 0.2527509033679962, 0.2515183389186859, 0.2525874972343445, 0.2379882037639618, 0.2475666105747223, 0.23924241960048676, 0.2344207614660263, 0.23490789532661438, 0.2253589630126953, 0.2318984568119049, 0.2243528962135315, 0.22434400022029877, 0.22129882872104645, 0.22968676686286926, 0.22360175848007202, 0.21889829635620117, 0.2153068631887436, 0.20937120914459229, 0.20816437900066376, 0.20983433723449707, 0.20831924676895142, 0.20440673828125, 0.19978678226470947, 0.19808782637119293, 0.19506144523620605, 0.1988438367843628, 0.19613030552864075, 0.1972336620092392, 0.18267828226089478, 0.18848225474357605, 0.19058769941329956, 0.18683254718780518, 0.18772007524967194, 0.1777895838022232, 0.18015368282794952, 0.17715400457382202, 0.1854572296142578, 0.17702680826187134, 0.17519432306289673, 0.17151375114917755, 0.17706197500228882, 0.17508664727210999]
val_gate_output_loss[6] = [0.34381920099258423, 0.283193975687027, 0.21766914427280426, 0.2577016353607178, 0.27852293848991394, 0.2571190595626831, 0.2323029488325119, 0.2692309617996216, 0.20556239783763885, 0.2281128615140915, 0.238181933760643, 0.2418081909418106, 0.27071020007133484, 0.24101202189922333, 0.2118363380432129, 0.26113077998161316, 0.22197990119457245, 0.24802231788635254, 0.26146000623703003, 0.21414828300476074, 0.25865569710731506, 0.23169384896755219, 0.244825541973114, 0.2132345587015152, 0.23179610073566437, 0.2396739274263382, 0.2165825366973877, 0.22958047688007355, 0.22527460753917694, 0.21652325987815857, 0.22492079436779022, 0.20563571155071259, 0.20226000249385834, 0.22889183461666107, 0.20988494157791138, 0.22479790449142456, 0.2109614461660385, 0.22456094622612, 0.21801598370075226, 0.20821505784988403, 0.22017362713813782, 0.24884115159511566, 0.20032043755054474, 0.2030428946018219, 0.20998495817184448, 0.21842926740646362, 0.19106537103652954, 0.2110021710395813, 0.21002501249313354, 0.2431759238243103, 0.20904019474983215, 0.28852519392967224, 0.21586978435516357, 0.2031482756137848, 0.22014211118221283, 0.224773108959198, 0.24051472544670105, 0.204402893781662, 0.21250508725643158]
reduced_sum_loss[6] = [0.5837525725364685, 0.4779030680656433, 0.4466255307197571, 0.4301535487174988, 0.424609512090683, 0.39996203780174255, 0.3978370130062103, 0.38879305124282837, 0.39339691400527954, 0.38821062445640564, 0.37892380356788635, 0.376103013753891, 0.3721698522567749, 0.36961254477500916, 0.37089940905570984, 0.360935240983963, 0.3636930584907532, 0.35625460743904114, 0.3543086647987366, 0.3561987280845642, 0.3525151014328003, 0.3509056866168976, 0.3475108742713928, 0.34671998023986816, 0.34511905908584595, 0.3404052257537842, 0.3403666615486145, 0.33818286657333374, 0.3370627164840698, 0.33515095710754395, 0.33647212386131287, 0.3321080207824707, 0.3349703848361969, 0.3298349678516388, 0.3262820243835449, 0.32406553626060486, 0.3249324560165405, 0.32401955127716064, 0.3215239644050598, 0.322355717420578, 0.3183034360408783, 0.3166331946849823, 0.3174363076686859, 0.3157496452331543, 0.3181374669075012, 0.31154075264930725, 0.3106401562690735, 0.30674970149993896, 0.31282058358192444, 0.30904310941696167, 0.3033508062362671, 0.30629733204841614, 0.3045140504837036, 0.301222026348114, 0.3018450438976288, 0.3010839819908142, 0.2976644039154053, 0.297985702753067, 0.29561594128608704]
val_reduced_sum_loss[6] = [0.8095428347587585, 0.590684711933136, 0.5312533378601074, 0.5158439874649048, 0.4944070875644684, 0.467732310295105, 0.4780505895614624, 0.4570162296295166, 0.44866544008255005, 0.4486463665962219, 0.4410798251628876, 0.4671928882598877, 0.4485132396221161, 0.48608827590942383, 0.5306782126426697, 0.47079208493232727, 0.4696015417575836, 0.45195600390434265, 0.4360004961490631, 0.46173667907714844, 0.4718562960624695, 0.49430954456329346, 0.45536375045776367, 0.4288007318973541, 0.4400733411312103, 0.43435096740722656, 0.4360862076282501, 0.42102494835853577, 0.45094308257102966, 0.4280094802379608, 0.4681209921836853, 0.4087819755077362, 0.4401771128177643, 0.45776939392089844, 0.4133341610431671, 0.4534023106098175, 0.41413477063179016, 0.4305703639984131, 0.4365169405937195, 0.429304838180542, 0.4354751706123352, 0.43743547797203064, 0.41304224729537964, 0.452466756105423, 0.4151248633861542, 0.4308313727378845, 0.44607415795326233, 0.4242492914199829, 0.4389036297798157, 0.4285166263580322, 0.4088144600391388, 0.42351698875427246, 0.46238818764686584, 0.41948437690734863, 0.4110577702522278, 0.4092808961868286, 0.489872545003891, 0.41859617829322815, 0.41961586475372314]
gate_output_accuracy[6] = [0.8022587299346924, 0.875583291053772, 0.8858554363250732, 0.8900707364082336, 0.8880277872085571, 0.8960316777229309, 0.8986020684242249, 0.8999640345573425, 0.893552303314209, 0.9009087681770325, 0.9026735424995422, 0.9060208797454834, 0.9050809144973755, 0.905243992805481, 0.910763680934906, 0.9076657295227051, 0.9114398956298828, 0.9131278991699219, 0.9119194149971008, 0.9132429957389832, 0.9176309704780579, 0.915271520614624, 0.917141854763031, 0.9189737439155579, 0.9175782203674316, 0.9225560426712036, 0.9200671315193176, 0.9214962124824524, 0.9210454225540161, 0.9235678911209106, 0.9197553992271423, 0.921726405620575, 0.9239276051521301, 0.9240906238555908, 0.9265220165252686, 0.9280374050140381, 0.9258266687393188, 0.9275290966033936, 0.928248405456543, 0.9303824305534363, 0.9306702017784119, 0.9312888383865356, 0.9316293001174927, 0.9326891303062439, 0.9314806461334229, 0.9362330436706543, 0.9336434602737427, 0.9337968826293945, 0.934161365032196, 0.934300422668457, 0.936923623085022, 0.9371730089187622, 0.9380649924278259, 0.9335619211196899, 0.9360747933387756, 0.9368277192115784, 0.9403764605522156, 0.937259316444397, 0.938606858253479]
val_gate_output_accuracy[6] = [0.8828269243240356, 0.9031908512115479, 0.9255183935165405, 0.910588264465332, 0.9084384441375732, 0.9082691669464111, 0.9216589331626892, 0.9111637473106384, 0.9289547204971313, 0.9165298342704773, 0.9183241724967957, 0.91642826795578, 0.8984003663063049, 0.9079475402832031, 0.918916642665863, 0.9041049480438232, 0.921642005443573, 0.9272788763046265, 0.8998560905456543, 0.926195502281189, 0.9105205535888672, 0.9204909205436707, 0.9161574244499207, 0.9271773099899292, 0.9160897135734558, 0.9161743521690369, 0.9192551970481873, 0.9150401949882507, 0.9179009795188904, 0.921963632106781, 0.9250274896621704, 0.9301227331161499, 0.929411768913269, 0.922285258769989, 0.9235547780990601, 0.9235209226608276, 0.925552248954773, 0.9178163409233093, 0.9230300188064575, 0.9273465871810913, 0.9265679121017456, 0.9079983234405518, 0.9280575513839722, 0.9270080327987671, 0.9244688749313354, 0.917951762676239, 0.9311553239822388, 0.9206094145774841, 0.93061363697052, 0.9147524237632751, 0.9217943549156189, 0.8969276547431946, 0.9276005029678345, 0.9295641183853149, 0.9212357401847839, 0.9165806174278259, 0.9155141711235046, 0.925552248954773, 0.925636887550354]
reduced_sum_mae[6] = [0.530727207660675, 0.4777693748474121, 0.4594837725162506, 0.44937461614608765, 0.44465991854667664, 0.43343082070350647, 0.431711345911026, 0.42783308029174805, 0.42792603373527527, 0.4248812198638916, 0.42061713337898254, 0.41887903213500977, 0.4165806770324707, 0.414650559425354, 0.4149189591407776, 0.4087444841861725, 0.41103458404541016, 0.40686047077178955, 0.40639570355415344, 0.40704435110092163, 0.40464603900909424, 0.40417250990867615, 0.40222620964050293, 0.40147730708122253, 0.40054115653038025, 0.3981103003025055, 0.3983628451824188, 0.39650431275367737, 0.39611706137657166, 0.39485421776771545, 0.39495018124580383, 0.3929636776447296, 0.39433547854423523, 0.3908199071884155, 0.39058175683021545, 0.38777071237564087, 0.3882169723510742, 0.38793110847473145, 0.3860567808151245, 0.3873526453971863, 0.3839154541492462, 0.3836876451969147, 0.3847191631793976, 0.3830999732017517, 0.3842398226261139, 0.3807401657104492, 0.3806482255458832, 0.37847796082496643, 0.38118764758110046, 0.37892231345176697, 0.3764744997024536, 0.37743663787841797, 0.3767906725406647, 0.3748147785663605, 0.3749523162841797, 0.3740280568599701, 0.37270301580429077, 0.3730825185775757, 0.372101366519928]
val_reduced_sum_mae[6] = [0.672380805015564, 0.5525580048561096, 0.512533962726593, 0.502398669719696, 0.48689648509025574, 0.47190847992897034, 0.4762548506259918, 0.4644428789615631, 0.46255922317504883, 0.4522400498390198, 0.45238369703292847, 0.4676779508590698, 0.45338234305381775, 0.46203359961509705, 0.4770285487174988, 0.4608207941055298, 0.45248091220855713, 0.44304439425468445, 0.4417315423488617, 0.4591606855392456, 0.45949044823646545, 0.4565597474575043, 0.44018375873565674, 0.4314787983894348, 0.4366430342197418, 0.4323289096355438, 0.4382272958755493, 0.43154001235961914, 0.43629419803619385, 0.4323998987674713, 0.4371660649776459, 0.42768383026123047, 0.43764549493789673, 0.43165791034698486, 0.4254917800426483, 0.4290318489074707, 0.4206455945968628, 0.42979106307029724, 0.4278205335140228, 0.42362165451049805, 0.42557185888290405, 0.42917710542678833, 0.4193057417869568, 0.4351031184196472, 0.42338502407073975, 0.42432481050491333, 0.42480847239494324, 0.42493948340415955, 0.4261363446712494, 0.4257892370223999, 0.42239463329315186, 0.4312148094177246, 0.42691656947135925, 0.4190782308578491, 0.42302098870277405, 0.4184088110923767, 0.4362598955631256, 0.4215987026691437, 0.4183048605918884]
# 74/74 [==============================] - 0s 6ms/step - loss: 1.0125 - gate_output_loss: 0.2125 - reduced_sum_loss: 0.4196 - gate_output_accuracy: 0.9256 - reduced_sum_mae: 0.4183
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== MoE ===========
# loss                : 1.9632
# gate_output_loss    : 1.1606
# reduced_sum_loss     : 0.4327
# gate_output_accuracy: 0.7871
# reduced_sum_mae      : 0.4658
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-23_16:44:29/model_MoE.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-23_16:44:29/model_MoE.png

####################################
#################################### 8
####################################

# Epoch 00026: LearningRateScheduler reducing learning rate to 0.00059049.
# 261/261 [==============================] - 4s 14ms/step - loss: 1.8626 - gate_output_loss: 0.2272 - reduced_sum_loss: 0.3494 - gate_output_accuracy: 0.9188 - reduced_sum_mae: 0.4020 - val_loss: 2.0418 - val_gate_output_loss: 0.2064 - val_reduced_sum_loss: 0.4161 - val_gate_output_accuracy: 0.9250 - val_reduced_sum_mae: 0.4348
# [on_epoch_end] epoch: 25 , loss: 1.8858774900436401 , val_loss : 2.041809320449829
# Epoch 00026: val_loss did not improve from 1.97722
loss[7] = [37.87070846557617, 4.80865478515625, 4.200458526611328, 3.834408760070801, 3.7331748008728027, 3.3755156993865967, 3.18290376663208, 3.1831955909729004, 3.1327035427093506, 3.012789011001587, 2.8155882358551025, 2.7625982761383057, 2.7020139694213867, 2.6412999629974365, 2.621952533721924, 2.49566388130188, 2.420602798461914, 2.2850959300994873, 2.3200461864471436, 2.3520307540893555, 2.1771998405456543, 2.039079189300537, 2.1161391735076904, 2.017962694168091, 2.0761260986328125, 1.8858774900436401]
val_loss[7] = [5.401401996612549, 4.407376289367676, 4.496959686279297, 3.9637982845306396, 3.6636416912078857, 3.830545425415039, 3.3688745498657227, 3.3435213565826416, 3.0548171997070312, 3.1404266357421875, 2.6175880432128906, 2.61305570602417, 2.873591423034668, 2.5623276233673096, 3.103848457336426, 2.543926239013672, 2.3496956825256348, 2.291823625564575, 2.2809226512908936, 2.3112170696258545, 1.9772201776504517, 2.044391632080078, 2.0635058879852295, 1.9893569946289062, 2.0187532901763916, 2.041809320449829]
gate_output_loss[7] = [0.6030886769294739, 0.3953701853752136, 0.3400499224662781, 0.31786176562309265, 0.31777697801589966, 0.31044989824295044, 0.2966398596763611, 0.3007516860961914, 0.2922040820121765, 0.2949759066104889, 0.2852167785167694, 0.2737840414047241, 0.27391186356544495, 0.2706887722015381, 0.26815086603164673, 0.26918360590934753, 0.2622002959251404, 0.25188490748405457, 0.25851383805274963, 0.24973838031291962, 0.2501559257507324, 0.24259857833385468, 0.2471775859594345, 0.22727999091148376, 0.24228663742542267, 0.2282794713973999]
val_gate_output_loss[7] = [0.35411372780799866, 0.23473434150218964, 0.2740471661090851, 0.2409759908914566, 0.24119365215301514, 0.270608514547348, 0.2509976923465729, 0.23986457288265228, 0.19641868770122528, 0.26278063654899597, 0.20261205732822418, 0.23960056900978088, 0.2128371000289917, 0.23112435638904572, 0.2891249358654022, 0.23783467710018158, 0.24645130336284637, 0.20924042165279388, 0.2237824648618698, 0.20084820687770844, 0.22026696801185608, 0.23392920196056366, 0.20300698280334473, 0.19214195013046265, 0.17898496985435486, 0.2063692808151245]
reduced_sum_loss[7] = [0.5760197043418884, 0.4829714298248291, 0.4497070014476776, 0.42578351497650146, 0.426553338766098, 0.4126506447792053, 0.4007582664489746, 0.39857059717178345, 0.39218613505363464, 0.3918670415878296, 0.38398289680480957, 0.3829679489135742, 0.3789791464805603, 0.3771798610687256, 0.37631869316101074, 0.37009111046791077, 0.3706432282924652, 0.3679674565792084, 0.3661232888698578, 0.3666639029979706, 0.35958361625671387, 0.3559914529323578, 0.35998642444610596, 0.3623574376106262, 0.3524908721446991, 0.345831960439682]
val_reduced_sum_loss[7] = [0.8110688924789429, 0.5789111852645874, 0.5576742887496948, 0.5419369339942932, 0.5150626301765442, 0.4923507571220398, 0.5099414587020874, 0.5020742416381836, 0.4798199534416199, 0.4596807360649109, 0.452108234167099, 0.43323054909706116, 0.4437861740589142, 0.42883339524269104, 0.43780386447906494, 0.4666708707809448, 0.4560626447200775, 0.4435080885887146, 0.42807331681251526, 0.47960057854652405, 0.42684972286224365, 0.4464944005012512, 0.4290817081928253, 0.4307750463485718, 0.4045177102088928, 0.4161358177661896]
gate_output_accuracy[7] = [0.806387722492218, 0.8746960759162903, 0.8868241310119629, 0.8932262063026428, 0.892204761505127, 0.8945689797401428, 0.8979594707489014, 0.8961755037307739, 0.899455726146698, 0.8996667265892029, 0.901608943939209, 0.9050665497779846, 0.9055748581886292, 0.905920147895813, 0.9084282517433167, 0.9076274037361145, 0.9119482040405273, 0.9131231307983398, 0.9115357995033264, 0.9128066301345825, 0.9130847454071045, 0.9162498712539673, 0.9134060740470886, 0.9225272536277771, 0.915803849697113, 0.9201774597167969]
val_gate_output_accuracy[7] = [0.8644604086875916, 0.9183241724967957, 0.9074904918670654, 0.9079983234405518, 0.9185442328453064, 0.9079813957214355, 0.9128734469413757, 0.9141938090324402, 0.9292932748794556, 0.9097080230712891, 0.9274312257766724, 0.9144815802574158, 0.9250105619430542, 0.9166821837425232, 0.9017689228057861, 0.9152771830558777, 0.9116546511650085, 0.929090142250061, 0.9166144728660583, 0.9296995401382446, 0.9279559850692749, 0.9172915816307068, 0.9301904439926147, 0.9309860467910767, 0.9355056881904602, 0.9249597787857056]
reduced_sum_mae[7] = [0.5286128520965576, 0.47720369696617126, 0.4598105251789093, 0.4477821886539459, 0.4450020492076874, 0.4376537501811981, 0.43151870369911194, 0.4310219883918762, 0.42770063877105713, 0.42670395970344543, 0.4234292805194855, 0.4222889244556427, 0.42010635137557983, 0.4179416000843048, 0.41758212447166443, 0.41479453444480896, 0.41443830728530884, 0.4125180244445801, 0.4120025932788849, 0.4110879600048065, 0.4088980257511139, 0.40703997015953064, 0.40798529982566833, 0.4083336591720581, 0.40450283885002136, 0.4006602466106415]
val_reduced_sum_mae[7] = [0.6732131242752075, 0.5455695390701294, 0.527082085609436, 0.5119533538818359, 0.5046268701553345, 0.4835536479949951, 0.4941234886646271, 0.49198001623153687, 0.4756399989128113, 0.46028563380241394, 0.45632660388946533, 0.4434502422809601, 0.44953012466430664, 0.4384476840496063, 0.44903016090393066, 0.4693697392940521, 0.46052250266075134, 0.4504499137401581, 0.43942496180534363, 0.47955045104026794, 0.43960675597190857, 0.44875848293304443, 0.4441872239112854, 0.4432290196418762, 0.4296496510505676, 0.43481379747390747]
# 74/74 [==============================] - 1s 7ms/step - loss: 2.0418 - gate_output_loss: 0.2064 - reduced_sum_loss: 0.4161 - gate_output_accuracy: 0.9250 - reduced_sum_mae: 0.4348
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== MoE ===========
# loss                : 2.9134
# gate_output_loss    : 1.0676
# reduced_sum_loss     : 0.4683
# gate_output_accuracy: 0.7924
# reduced_sum_mae      : 0.4915
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-23_16:52:44/model_MoE.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-23_16:52:44/model_MoE.png


####################################
#################################### 9
####################################

# Epoch 00046: LearningRateScheduler reducing learning rate to 0.0003874204890000001.
# 261/261 [==============================] - 4s 16ms/step - loss: 1.1504 - gate_output_loss: 0.1768 - reduced_sum_loss: 0.3172 - gate_output_accuracy: 0.9391 - reduced_sum_mae: 0.3830 - val_loss: 1.3116 - val_gate_output_loss: 0.2229 - val_reduced_sum_loss: 0.4166 - val_gate_output_accuracy: 0.9176 - val_reduced_sum_mae: 0.4338
# [on_epoch_end] epoch: 45 , loss: 1.1709377765655518 , val_loss : 1.3116430044174194
# Epoch 00046: val_loss did not improve from 1.18187
loss[8] = [37.93720626831055, 4.731651782989502, 4.2688398361206055, 3.9533755779266357, 3.7470784187316895, 3.3904874324798584, 3.207735538482666, 3.1667094230651855, 3.1662425994873047, 2.9648776054382324, 2.8693432807922363, 2.707350492477417, 2.644212245941162, 2.599724292755127, 2.6518843173980713, 2.4444375038146973, 2.323753833770752, 2.2610251903533936, 2.3415563106536865, 2.290361166000366, 2.101270914077759, 2.0690903663635254, 2.0611250400543213, 2.0831470489501953, 1.963182806968689, 1.8169585466384888, 1.8375147581100464, 1.8029117584228516, 1.7357794046401978, 1.8195490837097168, 1.6317964792251587, 1.6482032537460327, 1.5467901229858398, 1.592603325843811, 1.5765128135681152, 1.4447717666625977, 1.455764889717102, 1.4330456256866455, 1.4473286867141724, 1.418268084526062, 1.2698358297348022, 1.2740395069122314, 1.2411772012710571, 1.2428486347198486, 1.316543698310852, 1.1709377765655518]
val_loss[8] = [4.758012294769287, 4.560477256774902, 3.6861424446105957, 3.666529655456543, 3.6513895988464355, 2.992820978164673, 3.049086332321167, 2.8303890228271484, 2.8432719707489014, 2.807415008544922, 2.6082236766815186, 2.8711981773376465, 2.721950054168701, 2.6967968940734863, 2.697655439376831, 2.340683698654175, 2.255688190460205, 2.4647269248962402, 2.376967668533325, 2.3768343925476074, 2.0621178150177, 2.105084180831909, 2.100898265838623, 2.0580999851226807, 2.081857919692993, 1.8298574686050415, 1.8306117057800293, 1.6940369606018066, 1.595367193222046, 1.9519013166427612, 1.6702417135238647, 1.522196650505066, 1.5402017831802368, 1.4257935285568237, 1.6088039875030518, 1.4033176898956299, 1.3102530241012573, 1.4780511856079102, 1.4593229293823242, 1.6055724620819092, 1.1832526922225952, 1.2553609609603882, 1.2449371814727783, 1.2286230325698853, 1.181872010231018, 1.3116430044174194]
gate_output_loss[8] = [0.6202414631843567, 0.38522040843963623, 0.3470720648765564, 0.33500784635543823, 0.31849539279937744, 0.30848076939582825, 0.2978840172290802, 0.2981225252151489, 0.29558470845222473, 0.28327658772468567, 0.29179731011390686, 0.27408260107040405, 0.27202364802360535, 0.26651260256767273, 0.2683878540992737, 0.26754504442214966, 0.24780668318271637, 0.2531256377696991, 0.25276070833206177, 0.24715259671211243, 0.2431054413318634, 0.23473908007144928, 0.23943957686424255, 0.2394346445798874, 0.2289019227027893, 0.22482430934906006, 0.23022176325321198, 0.22357666492462158, 0.2210914045572281, 0.22909975051879883, 0.2151065617799759, 0.212087020277977, 0.21242080628871918, 0.21084080636501312, 0.21384364366531372, 0.20797625184059143, 0.20494964718818665, 0.20526862144470215, 0.20652498304843903, 0.20401132106781006, 0.19259041547775269, 0.19865697622299194, 0.19000206887722015, 0.19070157408714294, 0.19469894468784332, 0.18487830460071564]
val_gate_output_loss[8] = [0.3504473865032196, 0.3151904046535492, 0.26581135392189026, 0.2514946460723877, 0.2670622169971466, 0.3103036880493164, 0.2421346753835678, 0.22114191949367523, 0.24224716424942017, 0.22601331770420074, 0.23035313189029694, 0.20942319929599762, 0.25154340267181396, 0.23214128613471985, 0.27869662642478943, 0.27182966470718384, 0.23072458803653717, 0.22913716733455658, 0.24403196573257446, 0.2408580780029297, 0.25670114159584045, 0.22079995274543762, 0.1969066858291626, 0.22571028769016266, 0.21469669044017792, 0.22013679146766663, 0.2630923390388489, 0.276917964220047, 0.21073593199253082, 0.20808221399784088, 0.2116299420595169, 0.22811245918273926, 0.22584056854248047, 0.19540075957775116, 0.2220463901758194, 0.2015330046415329, 0.21471048891544342, 0.24617475271224976, 0.22720196843147278, 0.2265809178352356, 0.18778018653392792, 0.21764503419399261, 0.21473276615142822, 0.2103937864303589, 0.20040415227413177, 0.22293318808078766]
reduced_sum_loss[8] = [0.5804556012153625, 0.4860455393791199, 0.4450052082538605, 0.42951902747154236, 0.42381441593170166, 0.40565600991249084, 0.40091952681541443, 0.3950011730194092, 0.39610111713409424, 0.38617146015167236, 0.39030149579048157, 0.38207128643989563, 0.37539955973625183, 0.3739226162433624, 0.37452664971351624, 0.3638763427734375, 0.36220264434814453, 0.3572385013103485, 0.3668944835662842, 0.3570229113101959, 0.3559863269329071, 0.35533642768859863, 0.3547384440898895, 0.3530915379524231, 0.3487534821033478, 0.3429127633571625, 0.35052892565727234, 0.3446219265460968, 0.34051331877708435, 0.3451840579509735, 0.33458417654037476, 0.3384931981563568, 0.3321988880634308, 0.33596986532211304, 0.3346220552921295, 0.3301488757133484, 0.33035632967948914, 0.33095306158065796, 0.32999420166015625, 0.329889714717865, 0.320282906293869, 0.3213040828704834, 0.3228429853916168, 0.32052960991859436, 0.32149142026901245, 0.3202968239784241]
val_reduced_sum_loss[8] = [0.8188011646270752, 0.59665447473526, 0.5081406235694885, 0.5150233507156372, 0.4905119836330414, 0.46148234605789185, 0.48427245020866394, 0.46810662746429443, 0.4833931624889374, 0.4788687229156494, 0.44098666310310364, 0.47452324628829956, 0.4679722785949707, 0.44305452704429626, 0.4540030360221863, 0.4507022798061371, 0.4333115220069885, 0.43705785274505615, 0.4217316210269928, 0.4309159815311432, 0.4204190671443939, 0.4230537712574005, 0.4123532176017761, 0.4288693368434906, 0.41449010372161865, 0.40935489535331726, 0.4223567843437195, 0.4185873866081238, 0.39836397767066956, 0.409014493227005, 0.4067458510398865, 0.41895410418510437, 0.40963584184646606, 0.40355944633483887, 0.4287767708301544, 0.4105127155780792, 0.39565664529800415, 0.4115069508552551, 0.4050884544849396, 0.4176171123981476, 0.3881058096885681, 0.4222913980484009, 0.38158443570137024, 0.39302676916122437, 0.391257107257843, 0.41661614179611206]
gate_output_accuracy[8] = [0.7980386018753052, 0.876791775226593, 0.8848627209663391, 0.8862438797950745, 0.8919170498847961, 0.894079864025116, 0.8959836959838867, 0.8974319696426392, 0.8973168730735779, 0.900409996509552, 0.8990528583526611, 0.9046732783317566, 0.9058146476745605, 0.9059345126152039, 0.9078575968742371, 0.9083275198936462, 0.9146481156349182, 0.9113103747367859, 0.9113775491714478, 0.9169260263442993, 0.9152235984802246, 0.919295072555542, 0.9171226620674133, 0.9163457751274109, 0.9198896884918213, 0.9225032925605774, 0.9182975888252258, 0.9226327538490295, 0.9244551062583923, 0.9216640591621399, 0.9237021803855896, 0.9263924956321716, 0.9266418814659119, 0.9283635020256042, 0.9250065684318542, 0.9270063638687134, 0.9279175400733948, 0.9275914430618286, 0.9297541975975037, 0.9291260242462158, 0.9338064789772034, 0.9308524131774902, 0.934832751750946, 0.9325260519981384, 0.9315957427024841, 0.9364104866981506]
val_gate_output_accuracy[8] = [0.8815234899520874, 0.88365638256073, 0.9104697704315186, 0.925958514213562, 0.8981803059577942, 0.9006855487823486, 0.914176881313324, 0.9274989366531372, 0.9121624827384949, 0.9200169444084167, 0.9224883913993835, 0.9226576089859009, 0.9118577837944031, 0.9217604994773865, 0.9124333262443542, 0.9079475402832031, 0.9284130334854126, 0.9206432700157166, 0.920677125453949, 0.9129073023796082, 0.9099619388580322, 0.9235547780990601, 0.9320186376571655, 0.9265679121017456, 0.9271773099899292, 0.921726644039154, 0.8997037410736084, 0.9035801887512207, 0.9263817071914673, 0.9309521913528442, 0.9296149015426636, 0.9194583296775818, 0.9282437562942505, 0.9309014081954956, 0.9224206805229187, 0.9358273148536682, 0.9159542918205261, 0.9085400104522705, 0.920355498790741, 0.9263986349105835, 0.934066891670227, 0.9241472482681274, 0.9256876707077026, 0.9313923120498657, 0.9267710447311401, 0.9176132082939148]
reduced_sum_mae[8] = [0.5308693647384644, 0.47880443930625916, 0.45879676938056946, 0.4496745765209198, 0.443787544965744, 0.4353065490722656, 0.43160301446914673, 0.4282456338405609, 0.427900493144989, 0.4234636127948761, 0.423189640045166, 0.4198337197303772, 0.4166276156902313, 0.4160879850387573, 0.4156714677810669, 0.4099865257740021, 0.40906864404678345, 0.40798091888427734, 0.4100736677646637, 0.40604859590530396, 0.4042457938194275, 0.40444570779800415, 0.4048425257205963, 0.40234339237213135, 0.4015957713127136, 0.39851924777030945, 0.4009944200515747, 0.39953985810279846, 0.3973444700241089, 0.39848488569259644, 0.3927595615386963, 0.3956572115421295, 0.39282166957855225, 0.3928993046283722, 0.39277195930480957, 0.39095303416252136, 0.39066118001937866, 0.3906450569629669, 0.3893812894821167, 0.38988202810287476, 0.3846534192562103, 0.38584402203559875, 0.38607099652290344, 0.3845074474811554, 0.3854193091392517, 0.38428995013237]
val_reduced_sum_mae[8] = [0.6762011051177979, 0.5577254891395569, 0.49250954389572144, 0.49982184171676636, 0.487852543592453, 0.46597886085510254, 0.4793929159641266, 0.47070521116256714, 0.47055405378341675, 0.477425217628479, 0.44718843698501587, 0.47436198592185974, 0.47100162506103516, 0.4493327736854553, 0.4575890004634857, 0.4550316631793976, 0.443684458732605, 0.4490213096141815, 0.4357531666755676, 0.441376268863678, 0.43757230043411255, 0.433551162481308, 0.4333145022392273, 0.4407517910003662, 0.4327884018421173, 0.4303304851055145, 0.4353685677051544, 0.4326778054237366, 0.4227293133735657, 0.4280987083911896, 0.4290623068809509, 0.4360685348510742, 0.4290393888950348, 0.4275398254394531, 0.44277483224868774, 0.43104109168052673, 0.42309167981147766, 0.43028655648231506, 0.42858269810676575, 0.43307411670684814, 0.4174644351005554, 0.43765366077423096, 0.4122737944126129, 0.42008113861083984, 0.4232187271118164, 0.4338383078575134]
# 74/74 [==============================] - 1s 7ms/step - loss: 1.3116 - gate_output_loss: 0.2229 - reduced_sum_loss: 0.4166 - gate_output_accuracy: 0.9176 - reduced_sum_mae: 0.4338
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== MoE ===========
# loss                : 2.1283
# gate_output_loss    : 1.0281
# reduced_sum_loss     : 0.4739
# gate_output_accuracy: 0.7891
# reduced_sum_mae      : 0.4912
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-23_16:57:11/model_MoE.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-23_16:57:11/model_MoE.png

####################################
#################################### 10
####################################
#
# Epoch 00086: LearningRateScheduler reducing learning rate to 0.00016677181699666576.
# 261/261 [==============================] - 5s 17ms/step - loss: 0.6281 - gate_output_loss: 0.1422 - reduced_sum_loss: 0.2780 - gate_output_accuracy: 0.9491 - reduced_sum_mae: 0.3613 - val_loss: 0.7048 - val_gate_output_loss: 0.2291 - val_reduced_sum_loss: 0.3789 - val_gate_output_accuracy: 0.9213 - val_reduced_sum_mae: 0.4107
# [on_epoch_end] epoch: 85 , loss: 0.6053327918052673 , val_loss : 0.7048330903053284
# Epoch 00086: val_loss did not improve from 0.70012
loss[9] = [37.84657287597656, 4.775252342224121, 4.176816463470459, 4.027523994445801, 3.6488037109375, 3.3145227432250977, 3.297240734100342, 3.16988468170166, 3.0869948863983154, 3.004361391067505, 2.747326374053955, 2.9315340518951416, 2.748973846435547, 2.6481432914733887, 2.6526167392730713, 2.455291986465454, 2.352731466293335, 2.357297658920288, 2.293914318084717, 2.3286852836608887, 2.07956862449646, 2.080077886581421, 2.0357825756073, 2.057309627532959, 2.035604476928711, 1.847406029701233, 1.8815537691116333, 1.837471842765808, 1.7354400157928467, 1.8384901285171509, 1.6507917642593384, 1.666582465171814, 1.5871678590774536, 1.5689502954483032, 1.566938042640686, 1.494957447052002, 1.4626710414886475, 1.4544179439544678, 1.4847699403762817, 1.412077784538269, 1.3717801570892334, 1.3607860803604126, 1.2553834915161133, 1.288006067276001, 1.2882179021835327, 1.1710922718048096, 1.162866234779358, 1.135443925857544, 1.1702768802642822, 1.1657713651657104, 1.0372480154037476, 1.0741000175476074, 1.0487385988235474, 0.9929713606834412, 1.0341774225234985, 0.95741206407547, 0.9969877600669861, 0.9521732330322266, 0.9537898302078247, 0.9525326490402222, 0.8878971338272095, 0.9043745994567871, 0.8698087334632874, 0.8807775378227234, 0.8592990040779114, 0.8340997695922852, 0.79410719871521, 0.7901483178138733, 0.8019537329673767, 0.8037313222885132, 0.7443650960922241, 0.7370052337646484, 0.7157055139541626, 0.7758468985557556, 0.7497341632843018, 0.7064804434776306, 0.6661127805709839, 0.6643943190574646, 0.6683127284049988, 0.6779663562774658, 0.6337165236473083, 0.6211829781532288, 0.6399859189987183, 0.6331294178962708, 0.6325598955154419, 0.6053327918052673]
val_loss[9] = [4.703993797302246, 4.521327495574951, 4.321165084838867, 3.9789364337921143, 3.37626576423645, 3.6424334049224854, 3.235814332962036, 3.1758339405059814, 2.7959842681884766, 2.922605514526367, 3.090569496154785, 2.6690683364868164, 2.7705328464508057, 2.861768960952759, 2.5973153114318848, 2.3644795417785645, 2.4187204837799072, 2.51049542427063, 2.449622869491577, 2.1774682998657227, 2.232957363128662, 1.8932411670684814, 1.9258413314819336, 2.0419113636016846, 1.9922049045562744, 1.8393405675888062, 1.7874354124069214, 1.7671623229980469, 1.812230110168457, 1.7896209955215454, 1.6292465925216675, 1.5519884824752808, 1.5483750104904175, 1.5457783937454224, 1.6823137998580933, 1.5763882398605347, 1.4899097681045532, 1.4326568841934204, 1.3383034467697144, 1.3853520154953003, 1.320115327835083, 1.3551784753799438, 1.3330169916152954, 1.4157220125198364, 1.201206088066101, 1.1065114736557007, 1.1863977909088135, 1.1263355016708374, 1.1715351343154907, 1.2469587326049805, 1.0683152675628662, 1.2793290615081787, 1.0121656656265259, 1.1228581666946411, 1.0882889032363892, 1.0020185708999634, 1.0359647274017334, 1.0171327590942383, 0.987204372882843, 1.0396239757537842, 0.9257153272628784, 0.9403096437454224, 0.8603054881095886, 0.9181762337684631, 0.9074892997741699, 0.925199568271637, 0.8970469236373901, 0.8194504380226135, 0.8392672538757324, 0.9125933051109314, 0.7927126884460449, 0.8419304490089417, 0.7977871894836426, 0.8791703581809998, 0.8326742649078369, 0.7477638125419617, 0.7869454026222229, 0.8066723346710205, 0.7934363484382629, 0.784629762172699, 0.7019782662391663, 0.7001237869262695, 0.756502628326416, 0.7228761315345764, 0.7895742058753967, 0.7048330903053284]
gate_output_loss[9] = [0.6134593486785889, 0.3928471803665161, 0.33653953671455383, 0.3341900706291199, 0.31429803371429443, 0.3038316071033478, 0.3004579544067383, 0.30102741718292236, 0.29055628180503845, 0.2919089198112488, 0.2761152684688568, 0.28634458780288696, 0.2791023850440979, 0.26584357023239136, 0.2750745117664337, 0.2620966136455536, 0.2497321516275406, 0.2593154013156891, 0.24880270659923553, 0.24845638871192932, 0.23574787378311157, 0.2400965392589569, 0.23844915628433228, 0.23940691351890564, 0.22837930917739868, 0.23175427317619324, 0.22878828644752502, 0.2255571037530899, 0.21930311620235443, 0.2240486592054367, 0.21936702728271484, 0.21809418499469757, 0.21412767469882965, 0.2133897989988327, 0.21074290573596954, 0.20872612297534943, 0.20909760892391205, 0.20437827706336975, 0.2075721025466919, 0.20221421122550964, 0.2013154774904251, 0.20675812661647797, 0.19163593649864197, 0.19582389295101166, 0.1961096227169037, 0.18976671993732452, 0.18612715601921082, 0.18511752784252167, 0.18763640522956848, 0.19279496371746063, 0.17643952369689941, 0.182148739695549, 0.18163925409317017, 0.17544294893741608, 0.1796608716249466, 0.1726018637418747, 0.1756604015827179, 0.17093494534492493, 0.17298182845115662, 0.17393988370895386, 0.170138418674469, 0.17156071960926056, 0.1650301069021225, 0.16965831816196442, 0.16700556874275208, 0.16794665157794952, 0.1587093323469162, 0.15876536071300507, 0.16053830087184906, 0.15819697082042694, 0.1552550494670868, 0.1545938104391098, 0.15195375680923462, 0.1607406735420227, 0.1582648903131485, 0.15246044099330902, 0.14493189752101898, 0.14285293221473694, 0.1413290947675705, 0.148030087351799, 0.1423587203025818, 0.1410549283027649, 0.14702428877353668, 0.14588606357574463, 0.14431220293045044, 0.1398315578699112]
val_gate_output_loss[9] = [0.38542693853378296, 0.23117902874946594, 0.2709757089614868, 0.27416595816612244, 0.24310317635536194, 0.3171927034854889, 0.2558704614639282, 0.21717196702957153, 0.23954258859157562, 0.2592563331127167, 0.2617243230342865, 0.23088867962360382, 0.24954849481582642, 0.27058860659599304, 0.2408241182565689, 0.26261940598487854, 0.22801023721694946, 0.2031424641609192, 0.2750698924064636, 0.2433139830827713, 0.23046082258224487, 0.18535353243350983, 0.19387421011924744, 0.23736952245235443, 0.24119223654270172, 0.20971907675266266, 0.1888219118118286, 0.2395765483379364, 0.26674097776412964, 0.2002991884946823, 0.2212209552526474, 0.1989617943763733, 0.2658817768096924, 0.2198309600353241, 0.1883108764886856, 0.213458850979805, 0.24406349658966064, 0.22485093772411346, 0.2064538449048996, 0.21253758668899536, 0.22886066138744354, 0.18586555123329163, 0.2082553207874298, 0.24828119575977325, 0.18365556001663208, 0.20645815134048462, 0.18779969215393066, 0.20689372718334198, 0.20903372764587402, 0.21043328940868378, 0.1793983429670334, 0.22909289598464966, 0.20016644895076752, 0.2653733789920807, 0.2173321396112442, 0.2313976287841797, 0.21378681063652039, 0.23696699738502502, 0.1997314691543579, 0.22691549360752106, 0.2159896194934845, 0.19498072564601898, 0.20126141607761383, 0.23144546151161194, 0.22144964337348938, 0.23664329946041107, 0.22983422875404358, 0.20007045567035675, 0.19893676042556763, 0.18896041810512543, 0.24037423729896545, 0.21821333467960358, 0.21818561851978302, 0.22419460117816925, 0.24849152565002441, 0.19942981004714966, 0.22574186325073242, 0.2467188686132431, 0.24667412042617798, 0.24379625916481018, 0.20568688213825226, 0.21202313899993896, 0.22840693593025208, 0.23242680728435516, 0.21383504569530487, 0.22907961905002594]
reduced_sum_loss[9] = [0.5753219127655029, 0.4814225137233734, 0.44592776894569397, 0.4304916262626648, 0.4151584208011627, 0.40254324674606323, 0.3975932002067566, 0.3938058018684387, 0.3917577266693115, 0.38552185893058777, 0.3776034414768219, 0.37893450260162354, 0.38272425532341003, 0.3671778440475464, 0.36769527196884155, 0.3645883798599243, 0.3649885058403015, 0.3634309768676758, 0.3537691533565521, 0.35737311840057373, 0.3487575948238373, 0.3481569290161133, 0.34808349609375, 0.3474099338054657, 0.34711331129074097, 0.34146878123283386, 0.33664199709892273, 0.33933138847351074, 0.33633363246917725, 0.33624982833862305, 0.33336400985717773, 0.3296905755996704, 0.32957723736763, 0.3280610144138336, 0.3271583616733551, 0.3233892023563385, 0.3229512572288513, 0.3202318251132965, 0.32496604323387146, 0.31749433279037476, 0.3218019902706146, 0.3202642500400543, 0.3148958384990692, 0.31361255049705505, 0.3161396384239197, 0.307003915309906, 0.3115162253379822, 0.3082782030105591, 0.3082338571548462, 0.30836743116378784, 0.3026323914527893, 0.3044995963573456, 0.3048487901687622, 0.301608145236969, 0.30346083641052246, 0.2983928918838501, 0.29815909266471863, 0.30125194787979126, 0.3005865812301636, 0.29593345522880554, 0.296123206615448, 0.2971615493297577, 0.29662269353866577, 0.2947944402694702, 0.29623955488204956, 0.2931500971317291, 0.28912675380706787, 0.290069580078125, 0.2903202772140503, 0.29346662759780884, 0.28738102316856384, 0.2875344455242157, 0.2859382629394531, 0.2901693284511566, 0.28982898592948914, 0.28531453013420105, 0.28360965847969055, 0.2842816412448883, 0.28103888034820557, 0.2836964726448059, 0.28108927607536316, 0.28027328848838806, 0.27975425124168396, 0.2794255018234253, 0.27897027134895325, 0.27828270196914673]
val_reduced_sum_loss[9] = [0.8324170112609863, 0.6151474714279175, 0.5495526790618896, 0.5118127465248108, 0.48393428325653076, 0.5633767247200012, 0.460041880607605, 0.4591115117073059, 0.46491241455078125, 0.4849209189414978, 0.467643141746521, 0.48011407256126404, 0.42941680550575256, 0.4477095901966095, 0.449083149433136, 0.4288732409477234, 0.44065937399864197, 0.4419228434562683, 0.4465157985687256, 0.4401555359363556, 0.43476301431655884, 0.4217842221260071, 0.42862290143966675, 0.4447377920150757, 0.4258861839771271, 0.4098638892173767, 0.4355278015136719, 0.41346368193626404, 0.4027617871761322, 0.4162519574165344, 0.41851940751075745, 0.39404597878456116, 0.4066052734851837, 0.4080943465232849, 0.4254763722419739, 0.42820367217063904, 0.416921466588974, 0.40763768553733826, 0.3850139379501343, 0.3945537507534027, 0.3834623694419861, 0.3972201943397522, 0.3909732699394226, 0.39587274193763733, 0.3886058032512665, 0.3855606019496918, 0.392392635345459, 0.38650044798851013, 0.4027094542980194, 0.38775956630706787, 0.39790958166122437, 0.41342270374298096, 0.38859865069389343, 0.4076073467731476, 0.38933080434799194, 0.40876147150993347, 0.3992445468902588, 0.3923114836215973, 0.38035839796066284, 0.3899145722389221, 0.3787877857685089, 0.3843158185482025, 0.3756982982158661, 0.3929964005947113, 0.3816160261631012, 0.37945666909217834, 0.3746519684791565, 0.3806205689907074, 0.3794316053390503, 0.3867124021053314, 0.37646254897117615, 0.3866957426071167, 0.40035587549209595, 0.3772702217102051, 0.3749532997608185, 0.3752118945121765, 0.3826688230037689, 0.3709752857685089, 0.3923121988773346, 0.3767726719379425, 0.3694291412830353, 0.3794596791267395, 0.3671840727329254, 0.3745017945766449, 0.3831520080566406, 0.3789081871509552]
gate_output_accuracy[9] = [0.8021196722984314, 0.8731471300125122, 0.887226939201355, 0.8880853652954102, 0.8933029770851135, 0.8962522745132446, 0.8972641229629517, 0.895628809928894, 0.9001030921936035, 0.9003908634185791, 0.9051384925842285, 0.9037525653839111, 0.9031339287757874, 0.9093537926673889, 0.9049466252326965, 0.9101594686508179, 0.9142692685127258, 0.9093441963195801, 0.9133341312408447, 0.9138616323471069, 0.9189785122871399, 0.9172425270080566, 0.9182687997817993, 0.9158230423927307, 0.92111736536026, 0.9191943407058716, 0.9211797118186951, 0.9216784834861755, 0.9231027364730835, 0.919635534286499, 0.9235295653343201, 0.923409640789032, 0.925562858581543, 0.9257307052612305, 0.9261287450790405, 0.9261479377746582, 0.9264644384384155, 0.9290252923965454, 0.9274571537971497, 0.9304975271224976, 0.9291643500328064, 0.9272269606590271, 0.9306557774543762, 0.9289054274559021, 0.9307277202606201, 0.9338352680206299, 0.9356671571731567, 0.9346025586128235, 0.9345929622650146, 0.9312264919281006, 0.9395660161972046, 0.9352259635925293, 0.9353650808334351, 0.9383671283721924, 0.9366310834884644, 0.9393693804740906, 0.937993049621582, 0.9397434592247009, 0.9381656646728516, 0.9393118619918823, 0.940755307674408, 0.9397050738334656, 0.9422467350959778, 0.9386356472969055, 0.9414554834365845, 0.9408272504806519, 0.9428269863128662, 0.9434936046600342, 0.9429565072059631, 0.9442129135131836, 0.944927453994751, 0.9454789757728577, 0.9452152252197266, 0.9425153136253357, 0.9441553950309753, 0.9450089931488037, 0.9482939839363098, 0.9477232694625854, 0.949833333492279, 0.948624849319458, 0.9493442177772522, 0.950303316116333, 0.9475938081741333, 0.949099600315094, 0.9491236209869385, 0.9504759907722473]
val_gate_output_accuracy[9] = [0.8703681826591492, 0.9226745367050171, 0.9093525409698486, 0.9108759760856628, 0.9137367606163025, 0.8786288499832153, 0.9167329668998718, 0.9181379675865173, 0.9131950736045837, 0.9084384441375732, 0.9014642238616943, 0.9164790511131287, 0.9105713367462158, 0.9038171768188477, 0.918595016002655, 0.9042572975158691, 0.9249259233474731, 0.9315615892410278, 0.891104519367218, 0.9091324806213379, 0.9207279086112976, 0.9342700242996216, 0.9296995401382446, 0.9153956770896912, 0.9125179648399353, 0.9220144152641296, 0.9334574937820435, 0.9246042966842651, 0.9000422954559326, 0.9217604994773865, 0.9176132082939148, 0.9296318292617798, 0.9063732624053955, 0.9258230924606323, 0.9294794797897339, 0.9204232096672058, 0.9124671816825867, 0.9159204363822937, 0.9296149015426636, 0.9177486300468445, 0.9148709177970886, 0.9323910474777222, 0.9246889352798462, 0.9089970588684082, 0.9347439408302307, 0.9241811037063599, 0.932780385017395, 0.9269911050796509, 0.927718997001648, 0.9248243570327759, 0.9296149015426636, 0.9154464602470398, 0.9269741773605347, 0.9039695262908936, 0.9189504981040955, 0.9152433276176453, 0.923791766166687, 0.9124671816825867, 0.9289885759353638, 0.9199492335319519, 0.9188658595085144, 0.9276174306869507, 0.9267033338546753, 0.9151079058647156, 0.9226745367050171, 0.9175962805747986, 0.9198984503746033, 0.9266186952590942, 0.9263817071914673, 0.9330681562423706, 0.9146000742912292, 0.9246042966842651, 0.9214558005332947, 0.9188658595085144, 0.9075920581817627, 0.931256890296936, 0.9245027303695679, 0.9129242300987244, 0.914904773235321, 0.9154464602470398, 0.9223529696464539, 0.9246381521224976, 0.9218282103538513, 0.9172577261924744, 0.9282099008560181, 0.9212695956230164]
reduced_sum_mae[9] = [0.5292769074440002, 0.477962851524353, 0.45936962962150574, 0.4507907032966614, 0.4410475790500641, 0.4347451627254486, 0.4323886036872864, 0.4286024868488312, 0.42747801542282104, 0.42374157905578613, 0.4199654161930084, 0.4195159375667572, 0.42009711265563965, 0.41371282935142517, 0.4139270484447479, 0.41077423095703125, 0.41124770045280457, 0.41011470556259155, 0.40570735931396484, 0.40657928586006165, 0.4022970199584961, 0.4024104177951813, 0.40144017338752747, 0.4019714295864105, 0.400522381067276, 0.39633333683013916, 0.3961315453052521, 0.3969712555408478, 0.3946221172809601, 0.39487224817276, 0.39341336488723755, 0.3920249044895172, 0.39182430505752563, 0.3903341293334961, 0.38986316323280334, 0.3870235085487366, 0.3876243829727173, 0.38606274127960205, 0.3880120813846588, 0.383746474981308, 0.3854936361312866, 0.3855374753475189, 0.38316887617111206, 0.38215479254722595, 0.383385568857193, 0.3782101273536682, 0.3809302747249603, 0.3789648413658142, 0.3796101212501526, 0.3793894350528717, 0.3751448392868042, 0.37568774819374084, 0.37766847014427185, 0.37426096200942993, 0.37644368410110474, 0.37189561128616333, 0.3731140196323395, 0.37479692697525024, 0.37427014112472534, 0.37266165018081665, 0.3718098998069763, 0.3721746802330017, 0.37217673659324646, 0.37093016505241394, 0.3719307780265808, 0.3693866431713104, 0.36707228422164917, 0.3677810728549957, 0.36809059977531433, 0.36953625082969666, 0.3669363558292389, 0.3658761978149414, 0.3657742738723755, 0.3664885461330414, 0.3674831688404083, 0.36435529589653015, 0.36467382311820984, 0.36428695917129517, 0.3623778223991394, 0.3650361895561218, 0.3621426522731781, 0.3618226647377014, 0.3618270456790924, 0.36075958609580994, 0.361502468585968, 0.3609044551849365]
val_reduced_sum_mae[9] = [0.6831594109535217, 0.5652225017547607, 0.5218994617462158, 0.49753642082214355, 0.4771510064601898, 0.5237795114517212, 0.4635011851787567, 0.4657929241657257, 0.46767741441726685, 0.47602716088294983, 0.4630650281906128, 0.4820358455181122, 0.4446965157985687, 0.45420950651168823, 0.46071144938468933, 0.4456384479999542, 0.45880597829818726, 0.45939815044403076, 0.4553544223308563, 0.4529860317707062, 0.4490325152873993, 0.4385543167591095, 0.44786959886550903, 0.45347410440444946, 0.4428088665008545, 0.43178653717041016, 0.45170143246650696, 0.4357662796974182, 0.42565712332725525, 0.43694281578063965, 0.43676257133483887, 0.42485904693603516, 0.43027085065841675, 0.4299527108669281, 0.4431457221508026, 0.4436860978603363, 0.43752098083496094, 0.42970582842826843, 0.4171692430973053, 0.4234671890735626, 0.41521039605140686, 0.4237287640571594, 0.41762498021125793, 0.42096248269081116, 0.41674697399139404, 0.41466596722602844, 0.41849857568740845, 0.4159446060657501, 0.43116891384124756, 0.41855812072753906, 0.41979071497917175, 0.4382801055908203, 0.4182852506637573, 0.429364949464798, 0.4157778024673462, 0.4302274286746979, 0.4228004515171051, 0.4167673587799072, 0.41205501556396484, 0.4167507588863373, 0.4125128984451294, 0.4162580668926239, 0.4089963436126709, 0.4190419018268585, 0.4132843017578125, 0.4116136431694031, 0.406389057636261, 0.4081411361694336, 0.41095587611198425, 0.4154967963695526, 0.4093303680419922, 0.4149380028247833, 0.4225529432296753, 0.40861040353775024, 0.4065054655075073, 0.40602877736091614, 0.4114454388618469, 0.40410125255584717, 0.42218905687332153, 0.40677332878112793, 0.4050208628177643, 0.41297805309295654, 0.4020858407020569, 0.4074823558330536, 0.41370636224746704, 0.4107162356376648]
# 74/74 [==============================] - 1s 6ms/step - loss: 0.7048 - gate_output_loss: 0.2291 - reduced_sum_loss: 0.3789 - gate_output_accuracy: 0.9213 - reduced_sum_mae: 0.4107
# no test dataset, generating
# ds: <BatchDataset shapes: (None, None, 148), types: tf.float32>
# type(ds): <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>
# type(input_data): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_1:0", shape=(3,), dtype=int32)
# type(experts_labels): <class 'tensorflow.python.framework.ops.Tensor'>, shape: Tensor("Shape_2:0", shape=(3,), dtype=int32)
# ==============================
# ======== Test Metrics ========
# ==============================
# =========== MoE ===========
# loss                : 1.8064
# gate_output_loss    : 1.3190
# reduced_sum_loss     : 0.4372
# gate_output_accuracy: 0.7502
# reduced_sum_mae      : 0.4741
# ==============================
# Model is saved as: __untrack/models/RAL/2022-02-23_17:04:50/model_MoE.h5
# Model architecture is saved as: __untrack/models/RAL/2022-02-23_17:04:50/model_MoE.png

#############################################################################################
#############################################################################################
#############################################################################################
min_length = 100
for i in range(len(loss)):
    if len(loss[i]) < min_length:
        min_length = len(loss[i])

print(min_length)

plot_gmoe = True
plot_lstm = True

font_size = 16
alpha_val= 0.3
x_lim= 40

if __name__ == "__main__":

    # GMoE
    loss = DataFrame(loss)
    val_loss = DataFrame(val_loss)

    gate_output_loss = DataFrame(gate_output_loss)
    val_gate_output_loss = DataFrame(val_gate_output_loss)

    reduced_sum_loss = DataFrame(reduced_sum_loss)
    val_reduced_sum_loss = DataFrame(val_reduced_sum_loss)

    gate_output_accuracy = DataFrame(gate_output_accuracy)
    val_gate_output_accuracy = DataFrame(val_gate_output_accuracy)

    reduced_sum_mae = DataFrame(reduced_sum_mae)
    val_reduced_sum_mae = DataFrame(val_reduced_sum_mae)

    # LSTM
    loss_lstm = DataFrame(loss_lstm)
    val_loss_lstm = DataFrame(val_loss_lstm)

    gate_output_loss_lstm = DataFrame(gate_output_loss_lstm)
    val_gate_output_loss_lstm = DataFrame(val_gate_output_loss_lstm)

    reduced_sum_loss_lstm = DataFrame(reduced_sum_loss_lstm)
    val_reduced_sum_loss_lstm = DataFrame(val_reduced_sum_loss_lstm)

    gate_output_accuracy_lstm = DataFrame(gate_output_accuracy_lstm)
    val_gate_output_accuracy_lstm = DataFrame(val_gate_output_accuracy_lstm)

    reduced_sum_mae_lstm = DataFrame(reduced_sum_mae_lstm)
    val_reduced_sum_mae_lstm = DataFrame(val_reduced_sum_mae_lstm)

    # GMoE
    mean_loss = loss.mean(axis=0)
    mean_val_loss = val_loss.mean(axis=0)
    mean_gate_output_loss = gate_output_loss.mean(axis=0)
    mean_val_gate_output_loss = val_gate_output_loss.mean(axis=0)
    mean_reduced_sum_loss = reduced_sum_loss.mean(axis=0)
    mean_val_reduced_sum_loss = val_reduced_sum_loss.mean(axis=0)
    mean_gate_output_accuracy = gate_output_accuracy.mean(axis=0)
    mean_val_gate_output_accuracy = val_gate_output_accuracy.mean(axis=0)
    mean_reduced_sum_mae = reduced_sum_mae.mean(axis=0)
    mean_val_reduced_sum_mae = val_reduced_sum_mae.mean(axis=0)

    # LSTM
    mean_loss_lstm = loss_lstm.mean(axis=0)
    mean_val_loss_lstm = val_loss_lstm.mean(axis=0)
    mean_gate_output_loss_lstm = gate_output_loss_lstm.mean(axis=0)
    mean_val_gate_output_loss_lstm = val_gate_output_loss_lstm.mean(axis=0)
    mean_reduced_sum_loss_lstm = reduced_sum_loss_lstm.mean(axis=0)
    mean_val_reduced_sum_loss_lstm = val_reduced_sum_loss_lstm.mean(axis=0)
    mean_gate_output_accuracy_lstm = gate_output_accuracy_lstm.mean(axis=0)
    mean_val_gate_output_accuracy_lstm = val_gate_output_accuracy_lstm.mean(axis=0)
    mean_reduced_sum_mae_lstm = reduced_sum_mae_lstm.mean(axis=0)
    mean_val_reduced_sum_mae_lstm = val_reduced_sum_mae_lstm.mean(axis=0)

    # GMoE
    std_loss = loss.std(axis=0)
    std_val_loss = val_loss.std(axis=0)
    std_gate_output_loss = gate_output_loss.std(axis=0)
    std_val_gate_output_loss = val_gate_output_loss.std(axis=0)
    std_reduced_sum_loss = reduced_sum_loss.std(axis=0)
    std_val_reduced_sum_loss = val_reduced_sum_loss.std(axis=0)
    std_gate_output_accuracy = gate_output_accuracy.std(axis=0)
    std_val_gate_output_accuracy = val_gate_output_accuracy.std(axis=0)
    std_reduced_sum_mae = reduced_sum_mae.std(axis=0)
    std_val_reduced_sum_mae = val_reduced_sum_mae.std(axis=0)

    # LSTM
    std_loss_lstm = loss_lstm.std(axis=0)
    std_val_loss_lstm = val_loss_lstm.std(axis=0)
    std_gate_output_loss_lstm = gate_output_loss_lstm.std(axis=0)
    std_val_gate_output_loss_lstm = val_gate_output_loss_lstm.std(axis=0)
    std_reduced_sum_loss_lstm = reduced_sum_loss_lstm.std(axis=0)
    std_val_reduced_sum_loss_lstm = val_reduced_sum_loss_lstm.std(axis=0)
    std_gate_output_accuracy_lstm = gate_output_accuracy_lstm.std(axis=0)
    std_val_gate_output_accuracy_lstm = val_gate_output_accuracy_lstm.std(axis=0)
    std_reduced_sum_mae_lstm = reduced_sum_mae_lstm.std(axis=0)
    std_val_reduced_sum_mae_lstm = val_reduced_sum_mae_lstm.std(axis=0)

    epochs = range(len(mean_loss))
    epochs_lstm = range(len(mean_loss_lstm))


    # fig = plt.figure(figsize=(10, 7))
    # ax01 = fig.subplots()
    # ax01.grid(False)
    # ax01.set_xlabel("epoch", fontsize=font_size)
    # ax01.set_ylabel("loss", fontsize=font_size)

    # plt.plot(range(len(mean_loss)), mean_loss, 'k-')
    # plt.fill_between(range(len(mean_loss)), mean_loss - std_loss, mean_loss + std_loss, alpha=0.25)
    # plt.show()
    # ax01.set_ylim(1, 5)
    # ax01.set_xlim(0, 50)

    # plot 1: losses
    plot_loss = plt.figure(1, figsize=(6, 8))
    axs_loss = plot_loss.subplots(3)

    #  GmoE
    if plot_gmoe:
        axs_loss[0].plot(epochs, mean_loss)
        axs_loss[0].fill_between(epochs, mean_loss-std_loss, mean_loss+std_loss,  alpha=alpha_val)

        axs_loss[0].plot(epochs, mean_val_loss, '-')
        axs_loss[0].fill_between(epochs, mean_val_loss-std_val_loss, mean_val_loss+std_val_loss,  alpha=alpha_val)

    # LSTM
    if plot_lstm:
        axs_loss[0].plot(epochs_lstm, mean_loss_lstm, '--')
        axs_loss[0].fill_between(epochs_lstm, mean_loss_lstm-std_loss_lstm, mean_loss_lstm+std_loss_lstm,  alpha=alpha_val)

        axs_loss[0].plot(epochs_lstm, mean_val_loss_lstm, '--')
        axs_loss[0].fill_between(epochs_lstm, mean_val_loss_lstm-std_val_loss_lstm, mean_val_loss_lstm+std_val_loss_lstm, alpha=alpha_val)

    axs_loss[0].set_title('total loss', fontsize=font_size)

    if plot_gmoe and plot_lstm :
        axs_loss[0].legend(['GMoE train', 'GMoE val', 'LSTM train', 'LSTM val'], loc='upper left', fontsize=font_size)

    axs_loss[0].set_ylim(0.0, 8.0)
    axs_loss[0].set_xlim(0, x_lim)

    # GMoE
    if plot_gmoe:
        axs_loss[1].plot(epochs, mean_gate_output_loss, '-')
        axs_loss[1].fill_between(epochs, mean_gate_output_loss-std_gate_output_loss,
                                 mean_gate_output_loss+std_gate_output_loss, alpha=alpha_val)

        axs_loss[1].plot(epochs, mean_val_gate_output_loss, '-')
        axs_loss[1].fill_between(epochs, mean_val_gate_output_loss-std_val_gate_output_loss,
                                 mean_val_gate_output_loss+std_val_gate_output_loss,  alpha=alpha_val)

    # LSTM
    if plot_lstm:
        axs_loss[1].plot(epochs_lstm, mean_gate_output_loss_lstm, '--')
        axs_loss[1].fill_between(epochs_lstm, mean_gate_output_loss_lstm-std_gate_output_loss_lstm,
                                 mean_gate_output_loss_lstm+std_gate_output_loss_lstm, alpha=alpha_val)

        axs_loss[1].plot(epochs_lstm, mean_val_gate_output_loss_lstm, '--')
        axs_loss[1].fill_between(epochs_lstm, mean_val_gate_output_loss_lstm-std_val_gate_output_loss_lstm,
                                 mean_val_gate_output_loss_lstm+std_val_gate_output_loss_lstm, alpha=alpha_val)

    axs_loss[1].set_title('gate loss', fontsize=font_size)
    # axs_loss[1].legend(['train', 'validation'], loc='upper left', fontsize=font_size)
    axs_loss[1].set_xlim(0, x_lim)

    # GMoE
    if plot_gmoe:
        axs_loss[2].plot(epochs, mean_reduced_sum_loss, '-')
        axs_loss[2].fill_between(epochs, mean_reduced_sum_loss-std_reduced_sum_loss,
                                 mean_reduced_sum_loss+std_reduced_sum_loss, alpha=alpha_val)

        axs_loss[2].plot(epochs, mean_val_reduced_sum_loss, '-')
        axs_loss[2].fill_between(epochs, mean_val_reduced_sum_loss-std_val_reduced_sum_loss,
                                 mean_val_reduced_sum_loss+std_val_reduced_sum_loss, alpha=alpha_val)

    # LSTM
    if plot_lstm:
        axs_loss[2].plot(epochs_lstm, mean_reduced_sum_loss_lstm, '--')
        axs_loss[2].fill_between(epochs_lstm, mean_reduced_sum_loss_lstm-std_reduced_sum_loss_lstm,
                                 mean_reduced_sum_loss_lstm+std_reduced_sum_loss_lstm, alpha=alpha_val)

        axs_loss[2].plot(epochs_lstm, mean_val_reduced_sum_loss_lstm, '--')
        axs_loss[2].fill_between(epochs_lstm, mean_val_reduced_sum_loss_lstm-std_val_reduced_sum_loss_lstm,
                                 mean_val_reduced_sum_loss_lstm+std_val_reduced_sum_loss_lstm, alpha=alpha_val)

    axs_loss[2].set_title('moe loss', fontsize=font_size)
    # axs_loss[2].legend(['GMoE train', 'GMoE val', 'LSTM train', 'LSTM val'], loc='upper left', fontsize=font_size)
    axs_loss[2].set_xlim(0, x_lim)

    for ax in axs_loss.flat:
        ax.set_xlabel('epoch', fontsize=font_size)
        ax.set_ylabel('loss', fontsize=font_size)

    # Hide x labels and tick labels for top plots and y ticks for right plots.
    for ax in axs_loss.flat:
        ax.label_outer()

    plt.show()
    plt.tight_layout()

    # plot 2: accuracy and mae
    plot_metrics = plt.figure(2, figsize=(6, 8))
    axs_metrics = plot_metrics.subplots(2)

    plt.figure(2, figsize=(12, 8))
    plot_metrics.clf()
    axs_metrics = plot_metrics.subplots(2)
    # GMoE
    if plot_gmoe:
        axs_metrics[0].plot(epochs, mean_gate_output_accuracy, '-')
        axs_metrics[0].fill_between(epochs, mean_gate_output_accuracy - std_gate_output_accuracy,
                                    mean_gate_output_accuracy + std_gate_output_accuracy, alpha=alpha_val)

        axs_metrics[0].plot(mean_val_gate_output_accuracy, '-')
        axs_metrics[0].fill_between(epochs, mean_val_gate_output_accuracy - std_val_gate_output_accuracy,
                                    mean_val_gate_output_accuracy + std_val_gate_output_accuracy, alpha=alpha_val)

    # LSTM
    if plot_lstm:
        axs_metrics[0].plot(epochs_lstm, mean_gate_output_accuracy_lstm, '--')
        axs_metrics[0].fill_between(epochs_lstm, mean_gate_output_accuracy_lstm - std_gate_output_accuracy_lstm,
                                    mean_gate_output_accuracy_lstm + std_gate_output_accuracy_lstm, alpha=alpha_val)

        axs_metrics[0].plot(mean_val_gate_output_accuracy_lstm, '--')
        axs_metrics[0].fill_between(epochs_lstm, mean_val_gate_output_accuracy_lstm - std_val_gate_output_accuracy_lstm,
                                    mean_val_gate_output_accuracy_lstm + std_val_gate_output_accuracy_lstm, alpha=alpha_val)

    axs_metrics[0].set_title('model accuracy', fontsize=font_size)
    axs_metrics[0].set_ylabel('accuracy', fontsize=font_size)
    # axs_metrics[0].legend(['train', 'validation'], loc='upper left', fontsize=font_size)
    axs_metrics[0].set_xlim(0, x_lim)

    # GMoE
    if plot_gmoe:
        axs_metrics[1].plot(mean_reduced_sum_mae, '-')
        axs_metrics[1].fill_between(epochs, mean_reduced_sum_mae - std_reduced_sum_mae,
                                    mean_reduced_sum_mae + std_reduced_sum_mae, alpha=alpha_val)

        axs_metrics[1].plot(mean_val_reduced_sum_mae, '-')
        axs_metrics[1].fill_between(epochs, mean_val_reduced_sum_mae - std_val_reduced_sum_mae,
                                    mean_val_reduced_sum_mae + std_val_reduced_sum_mae, alpha=alpha_val)
    # LSTM
    if plot_lstm:
        axs_metrics[1].plot(mean_reduced_sum_mae_lstm, '--')
        axs_metrics[1].fill_between(epochs_lstm, mean_reduced_sum_mae_lstm - std_reduced_sum_mae_lstm,
                                    mean_reduced_sum_mae_lstm + std_reduced_sum_mae_lstm, alpha=alpha_val)

        axs_metrics[1].plot(mean_val_reduced_sum_mae_lstm, '--')
        axs_metrics[1].fill_between(epochs_lstm, mean_val_reduced_sum_mae_lstm - std_val_reduced_sum_mae_lstm,
                                    mean_val_reduced_sum_mae_lstm + std_val_reduced_sum_mae_lstm, alpha=alpha_val)

    axs_metrics[1].set_title('model mae', fontsize=font_size)
    axs_metrics[1].set_xlabel('epoch', fontsize=font_size)
    axs_metrics[1].set_ylabel('mae', fontsize=font_size)
    # axs_metrics[1].legend(['train', 'validation'], loc='upper left', fontsize=font_size)
    axs_metrics[1].set_xlim(0, x_lim)

    for ax in axs_metrics.flat:
        ax.label_outer()

    plt.show()

    ## Test set checks
    test_loss_gmoe = [0] * samples
    test_gate_output_loss_gmoe = [0] * samples
    test_reduced_sum_loss_gmoe = [0] * samples
    test_gate_output_accuracy_gmoe = [0] * samples
    test_reduced_sum_mae_gmoe = [0] * samples

    test_loss_lstm = [0] * samples
    test_gate_output_loss_lstm = [0] * samples
    test_reduced_sum_loss_lstm = [0] * samples
    test_gate_output_accuracy_lstm = [0] * samples
    test_reduced_sum_mae_lstm = [0] * samples

    # =========== LSTM =========== 1
    test_loss_lstm[0] = 2.9050
    test_gate_output_loss_lstm[0] = 1.4837
    test_reduced_sum_loss_lstm[0] = 0.5157
    test_gate_output_accuracy_lstm[0] = 0.7040
    test_reduced_sum_mae_lstm[0] = 0.5202

    # =========== LSTM =========== 2
    test_loss_lstm[1] = 2.9507
    test_gate_output_loss_lstm[1] = 1.1682
    test_reduced_sum_loss_lstm[1] = 0.5538
    test_gate_output_accuracy_lstm[1] = 0.7417
    test_reduced_sum_mae_lstm[1] = 0.5385
    # ==============================

    # =========== LSTM =========== 3
    test_loss_lstm[2] = 2.1637
    test_gate_output_loss_lstm[2] = 1.0539
    test_reduced_sum_loss_lstm[2] = 0.4774
    test_gate_output_accuracy_lstm[2] = 0.7944
    test_reduced_sum_mae_lstm[2] = 0.4983
    # ==============================

    # =========== LSTM =========== 4
    test_loss_lstm[3] = 2.8482
    test_gate_output_loss_lstm[3] = 1.9115
    test_reduced_sum_loss_lstm[3] = 0.4950
    test_gate_output_accuracy_lstm[3] = 0.6603
    test_reduced_sum_mae_lstm[3] = 0.5072
    # ==============================

    # =========== LSTM =========== 5
    test_loss_lstm[4] = 2.5394
    test_gate_output_loss_lstm[4] = 1.5918
    test_reduced_sum_loss_lstm[4] = 0.5580
    test_gate_output_accuracy_lstm[4] = 0.7806
    test_reduced_sum_mae_lstm[4] = 0.5417
    # ==============================

    # =========== LSTM =========== 6
    test_loss_lstm[5] = 3.5152
    test_gate_output_loss_lstm[5] = 1.4211
    test_reduced_sum_loss_lstm[5] = 0.5608
    test_gate_output_accuracy_lstm[5] = 0.6501
    test_reduced_sum_mae_lstm[5] = 0.5419
    # ==============================

    # =========== LSTM =========== 7
    test_loss_lstm[6] = 3.0675
    test_gate_output_loss_lstm[6] = 1.7529
    test_reduced_sum_loss_lstm[6] = 0.5130
    test_gate_output_accuracy_lstm[6] = 0.7335
    test_reduced_sum_mae_lstm[6] = 0.5158
    # ==============================

    # =========== LSTM =========== 8
    test_loss_lstm[7] = 2.9655
    test_gate_output_loss_lstm[7] = 1.6359
    test_reduced_sum_loss_lstm[7] = 0.4859
    test_gate_output_accuracy_lstm[7] = 0.6845
    test_reduced_sum_mae_lstm[7] = 0.5014
    # ==============================

    # =========== LSTM =========== 9
    test_loss_lstm[8] = 2.0914
    test_gate_output_loss_lstm[8] = 1.4881
    test_reduced_sum_loss_lstm[8] = 0.4623
    test_gate_output_accuracy_lstm[8] = 0.7331
    test_reduced_sum_mae_lstm[8] = 0.4905
    # ==============================

    # =========== LSTM =========== 10
    test_loss_lstm[9] = 2.3449
    test_gate_output_loss_lstm[9] = 1.0443
    test_reduced_sum_loss_lstm[9] = 0.4801
    test_gate_output_accuracy_lstm[9] = 0.7593
    test_reduced_sum_mae_lstm[9] = 0.4962
    # ==============================

    ######################################

    # =========== MoE ===========
    test_loss_gmoe[0] = 2.2587
    test_gate_output_loss_gmoe[0] = 1.0074
    test_reduced_sum_loss_gmoe[0] = 0.5199
    test_gate_output_accuracy_gmoe[0] = 0.7848
    test_reduced_sum_mae_gmoe[0] = 0.5132
    # ============================== 1

    # =========== MoE ===========
    test_loss_gmoe[1] = 1.9825
    test_gate_output_loss_gmoe[1] = 1.1002
    test_reduced_sum_loss_gmoe[1] = 0.4602
    test_gate_output_accuracy_gmoe[1] = 0.8023
    test_reduced_sum_mae_gmoe[1] = 0.4810
    # ============================== 2

    # =========== MoE ===========
    test_loss_gmoe[2] = 2.4907
    test_gate_output_loss_gmoe[2] = 1.0775
    test_reduced_sum_loss_gmoe[2] = 0.4413
    test_gate_output_accuracy_gmoe[2] = 0.7891
    test_reduced_sum_mae_gmoe[2] = 0.4753
    # ============================== 3

    # =========== MoE ===========
    test_loss_gmoe[3] = 1.7770
    test_gate_output_loss_gmoe[3] = 1.2113
    test_reduced_sum_loss_gmoe[3] = 0.4195
    test_gate_output_accuracy_gmoe[3] = 0.7728
    test_reduced_sum_mae_gmoe[3] = 0.4627
    # ============================== 4

    # =========== MoE ===========
    test_loss_gmoe[4] = 2.0531
    test_gate_output_loss_gmoe[4] = 0.9522
    test_reduced_sum_loss_gmoe[4] = 0.4271
    test_gate_output_accuracy_gmoe[4] = 0.8104
    test_reduced_sum_mae_gmoe[4] = 0.4635
    # ============================== 5

    # =========== MoE ===========
    test_loss_gmoe[5] = 2.1175
    test_gate_output_loss_gmoe[5] = 1.1482
    test_reduced_sum_loss_gmoe[5] = 0.5228
    test_gate_output_accuracy_gmoe[5] = 0.7343
    test_reduced_sum_mae_gmoe[5] = 0.5140
    # ============================== 6

    # =========== MoE =========== 7
    test_loss_gmoe[6] = 1.9632
    test_gate_output_loss_gmoe[6] = 1.1606
    test_reduced_sum_loss_gmoe[6] = 0.4327
    test_gate_output_accuracy_gmoe[6] = 0.7871
    test_reduced_sum_mae_gmoe[6] = 0.4658
    # ==============================

    # =========== MoE ===========
    test_loss_gmoe[7] = 2.9134
    test_gate_output_loss_gmoe[7] = 1.0676
    test_reduced_sum_loss_gmoe[7] = 0.4683
    test_gate_output_accuracy_gmoe[7] = 0.7924
    test_reduced_sum_mae_gmoe[7] = 0.4915
    # ============================== 8

    # =========== MoE ===========
    test_loss_gmoe[8] = 2.1283
    test_gate_output_loss_gmoe[8] = 1.0281
    test_reduced_sum_loss_gmoe[8] = 0.4739
    test_gate_output_accuracy_gmoe[8] = 0.7891
    test_reduced_sum_mae_gmoe[8] = 0.4912
    # ============================== 9

    # =========== MoE ===========
    test_loss_gmoe[9] = 1.8064
    test_gate_output_loss_gmoe[9] = 1.3190
    test_reduced_sum_loss_gmoe[9] = 0.4372
    test_gate_output_accuracy_gmoe[9] = 0.7502
    test_reduced_sum_mae_gmoe[9] = 0.4741
    # ============================== 10
    # GMoE TEST Set
    test_loss_gmoe_mean = np.array(test_loss_gmoe).mean()
    test_loss_gmoe_std = np.array(test_loss_gmoe).std()

    test_gate_output_loss_gmoe_mean = np.array(test_gate_output_loss_gmoe).mean()
    test_gate_output_loss_gmoe_std = np.array(test_gate_output_loss_gmoe).std()

    test_reduced_sum_loss_gmoe_mean = np.array(test_reduced_sum_loss_gmoe).mean()
    test_reduced_sum_loss_gmoe_std = np.array(test_reduced_sum_loss_gmoe).std()

    test_gate_output_accuracy_gmoe_mean = np.array(test_gate_output_accuracy_gmoe).mean()
    test_gate_output_accuracy_gmoe_std = np.array(test_gate_output_accuracy_gmoe).std()

    test_reduced_sum_mae_gmoe_mean = np.array(test_reduced_sum_mae_gmoe).mean()
    test_reduced_sum_mae_gmoe_std = np.array(test_reduced_sum_mae_gmoe).std()

    # LSTM TEST Set
    test_loss_lstm_mean = np.array(test_loss_lstm).mean()
    test_loss_lstm_std = np.array(test_loss_lstm).std()

    test_gate_output_loss_lstm_mean = np.array(test_gate_output_loss_lstm).mean()
    test_gate_output_loss_lstm_std = np.array(test_gate_output_loss_lstm).std()

    test_reduced_sum_loss_lstm_mean = np.array(test_reduced_sum_loss_lstm).mean()
    test_reduced_sum_loss_lstm_std = np.array(test_reduced_sum_loss_lstm).std()

    test_gate_output_accuracy_lstm_mean = np.array(test_gate_output_accuracy_lstm).mean()
    test_gate_output_accuracy_lstm_std = np.array(test_gate_output_accuracy_lstm).std()

    test_reduced_sum_mae_lstm_mean = np.array(test_reduced_sum_mae_lstm).mean()
    test_reduced_sum_mae_lstm_std = np.array(test_reduced_sum_mae_lstm).std()

    print('==================================')

    print('GMoE test Set: loss, gate_loss, moe_loss, gate_accuracy, moe_mae')
    print('mean:',
          test_loss_gmoe_mean,
          test_gate_output_loss_gmoe_mean,
          test_reduced_sum_loss_gmoe_mean,
          test_gate_output_accuracy_gmoe_mean,
          test_reduced_sum_mae_gmoe_mean)

    print('std:',
          test_loss_gmoe_std,
          test_gate_output_loss_gmoe_std,
          test_reduced_sum_loss_gmoe_std,
          test_gate_output_accuracy_gmoe_std,
          test_reduced_sum_mae_gmoe_std)
    print('==================================')
    print('LSTM test Set: loss, gate_loss, moe_loss, gate_accuracy, moe_mae')
    print('mean:',
          test_loss_lstm_mean,
          test_gate_output_loss_lstm_mean,
          test_reduced_sum_loss_lstm_mean,
          test_gate_output_accuracy_lstm_mean,
          test_reduced_sum_mae_lstm_mean)

    print('std:',
          test_loss_lstm_std,
          test_gate_output_loss_lstm_std,
          test_reduced_sum_loss_lstm_std,
          test_gate_output_accuracy_lstm_std,
          test_reduced_sum_mae_lstm_std)

    print('==================================')


